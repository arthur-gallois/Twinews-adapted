{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rsync -avhuP -e \"ssh -p 2222\" student@212.129.44.40:/data/twinews-splits . # pwd: <company_name>-<computer_science_field_acronym>-<school_acronym>-<company_street_number>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNotebook = '__file__' not in locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.location import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.printer import *\n",
    "from databasetools.mongo import *\n",
    "from newstools.goodarticle.utils import *\n",
    "from nlptools.preprocessing import *\n",
    "from nlptools.news import parser as newsParser\n",
    "from machinelearning.iterator import *\n",
    "from twinews.utils import *\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machinelearning.bokehutils import *\n",
    "from bokeh.plotting import output_notebook, show\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(tmpDir('logs') + \"/twinews-splitting.log\") if isNotebook else Logger(\"twinews-splitting.log\")\n",
    "tt = TicToc(logger=logger)\n",
    "tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsCollection = getNewsCollection(logger=logger)\n",
    "usersCollection = getUsersCollection(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(newsCollection) > 0\n",
    "assert len(usersCollection) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.tic(\"Init done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding min and max dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = convertDate(newsCollection.findOne(sort=(\"minTimestamp\", pymongo.ASCENDING))['minTimestamp'], dateFormat=DATE_FORMAT.datetimeString)\n",
    "log(\"Overall min date: \" + convertDate(ts, dateFormat=DATE_FORMAT.datetimeString), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = convertDate(newsCollection.findOne(sort=(\"minTimestamp\", pymongo.DESCENDING))['minTimestamp'], dateFormat=DATE_FORMAT.datetimeString)\n",
    "log(\"Overall max date: \" + convertDate(ts, dateFormat=DATE_FORMAT.datetimeString), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = convertDate(newsCollection.findOne(sort=(\"maxTimestamp\", pymongo.ASCENDING))['maxTimestamp'], dateFormat=DATE_FORMAT.datetimeString)\n",
    "log(\"Overall min date when considering maxTimestamp: \" + convertDate(ts, dateFormat=DATE_FORMAT.datetimeString), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = convertDate(newsCollection.findOne(sort=(\"maxTimestamp\", pymongo.DESCENDING))['maxTimestamp'], dateFormat=DATE_FORMAT.datetimeString)\n",
    "log(\"Overall max date when considering maxTimestamp: \" + convertDate(ts, dateFormat=DATE_FORMAT.datetimeString), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncoderFunct(x):\n",
    "    return \">= \" + convertDate(x, dateFormat=DATE_FORMAT.datetimeString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = [e['minTimestamp'] for e in newsCollection.find(projection={\"minTimestamp\": True})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(barplot(timestamps, labelEncoderFunct=labelEncoderFunct, n=60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the start and end time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = \"2017-10-01\"\n",
    "endDate = \"2018-01-15\" #Â '2018-02-16' for the main train / test split and '2018-01-15' for the train / validation\n",
    "startTimestamp = convertDate(startDate, dateFormat=DATE_FORMAT.timestamp)\n",
    "endTimestamp = convertDate(endDate, dateFormat=DATE_FORMAT.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News count from the start date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = [e['minTimestamp'] for e in newsCollection.find({'minTimestamp': {'$gt': startTimestamp}}, projection={\"minTimestamp\": True})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(barplot(timestamps, labelEncoderFunct=labelEncoderFunct, n=60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining split functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newsSplit(startTs, splitTs, endTs, returnExtraNews=True, logger=None, verbose=True):\n",
    "    if isinstance(startTs, str):\n",
    "        startTs = convertDate(startTs, dateFormat=DATE_FORMAT.timestamp)\n",
    "    if isinstance(splitTs, str):\n",
    "        splitTs = convertDate(splitTs, dateFormat=DATE_FORMAT.timestamp)\n",
    "    if isinstance(endTs, str):\n",
    "        endTs = convertDate(endTs, dateFormat=DATE_FORMAT.timestamp)\n",
    "    newsCollection = getNewsCollection(logger=logger)\n",
    "    previousNews = set()\n",
    "    trainNews = set()\n",
    "    testNews = set()\n",
    "    afterNews = set()\n",
    "    pbar = ProgressBar(len(newsCollection), logger=logger, verbose=verbose, printRatio=0.3)\n",
    "    for news in newsCollection.find({}, projection={'minTimestamp': True, 'url': True}):\n",
    "        url = news['url']\n",
    "        ts = news['minTimestamp']\n",
    "        if ts < startTs:\n",
    "            previousNews.add(url)\n",
    "        elif ts >= startTs and ts < splitTs:\n",
    "            trainNews.add(url)\n",
    "        elif ts >= splitTs and ts <= endTs:\n",
    "            testNews.add(url)\n",
    "        else:\n",
    "            afterNews.add(url)\n",
    "        pbar.tic()\n",
    "    if returnExtraNews:\n",
    "        return previousNews, trainNews, testNews, afterNews\n",
    "    else:\n",
    "        return trainNews, testNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usersSplit(urlss, minUrls=None, logger=None, verbose=True):\n",
    "    \"\"\"\n",
    "        This function get a list of urls.\n",
    "        You need to specify  the minium of url per user for each list in minUrls.\n",
    "    \"\"\"\n",
    "    if minUrls is None:\n",
    "        minUrls = [0] * len(urlss)\n",
    "    assert len(urlss) == len(minUrls)\n",
    "    usersCollection = getUsersCollection(logger=logger)\n",
    "    bulks = []\n",
    "    pbar = ProgressBar(len(usersCollection) * len(urlss), logger=logger, verbose=verbose, printRatio=0.3)\n",
    "    for urls in urlss:\n",
    "        current = dict()\n",
    "        for user in usersCollection.find({}, projection={'timestamps': True, 'news': True, 'user_id': True}):\n",
    "            current[user['user_id']] = dict()\n",
    "            for i in range(len(user['news'])):\n",
    "                if user['news'][i] in urls:\n",
    "                    current[user['user_id']][user['news'][i]] = user['timestamps'][i]\n",
    "            pbar.tic()\n",
    "        bulks.append(current)\n",
    "    toDeleteUsers = set()\n",
    "    for i in range(len(bulks)):\n",
    "        theMin = minUrls[i]\n",
    "        users = bulks[i]\n",
    "        for userId in list(users.keys()):\n",
    "            if len(users[userId]) < theMin:\n",
    "                toDeleteUsers.add(userId)\n",
    "    remaining = len(usersCollection) - len(toDeleteUsers)\n",
    "    log(str(remaining) + \" users remaining on \" + str(len(usersCollection))\n",
    "                + \", so \" + str(truncateFloat(remaining / len(usersCollection) * 100, 2)) + \"%\", logger)\n",
    "    for i in range(len(bulks)):\n",
    "        for userId in toDeleteUsers:\n",
    "            del bulks[i][userId]\n",
    "    return bulks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count for a split at 2018-02-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theSplit = \"2018-02-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previousNews, trainNews, testNews, afterNews = newsSplit(startDate, theSplit, endDate, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainUsers, testUsers = usersSplit([trainNews, testNews], [0, 0], logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(barplot([len(n) for u, n in trainUsers.items()], title=\"Train counts for a split at \" + theSplit, n=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(barplot([len(n) for u, n in testUsers.items()], title=\"Test counts for a split at \" + theSplit, n=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count for a split at 2018-01-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theSplit = \"2018-01-15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previousNews, trainNews, testNews, afterNews = newsSplit(startDate, theSplit, endDate, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainUsers, testUsers = usersSplit([trainNews, testNews], [0, 0], logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(barplot([len(n) for u, n in trainUsers.items()], title=\"Train counts for a split at \" + theSplit, n=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(barplot([len(n) for u, n in testUsers.items()], title=\"Test counts for a split at \" + theSplit, n=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User deletion for split at 2018-02-01 and mins (3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theSplit = \"2018-02-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previousNews, trainNews, testNews, afterNews = newsSplit(startDate, theSplit, endDate, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainUsers, testUsers = usersSplit([trainNews, testNews], [3, 2], logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User deletion for split at 2018-01-15 and mins (3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theSplit = \"2018-01-15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previousNews, trainNews, testNews, afterNews = newsSplit(startDate, theSplit, endDate, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainUsers, testUsers = usersSplit([trainNews, testNews], [3, 2], logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User deletion for split at 2018-01-15 and mins (15, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theSplit = \"2018-01-15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previousNews, trainNews, testNews, afterNews = newsSplit(startDate, theSplit, endDate, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainUsers, testUsers = usersSplit([trainNews, testNews], [15, 5], logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User deletion for split at 2018-01-15 and mins (8, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theSplit = \"2018-01-15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previousNews, trainNews, testNews, afterNews = newsSplit(startDate, theSplit, endDate, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainUsers, testUsers = usersSplit([trainNews, testNews], [8, 2], logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the split and mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theSplit = \"2017-12-25\" #Â 2018-01-15 for version 1 and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins = [8, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previousNews, trainNews, testNews, afterNews = newsSplit(startDate, theSplit, endDate, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainUsers, testUsers = usersSplit([trainNews, testNews], mins, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranksLength = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testNewsList = list(testNews)\n",
    "candidates = dict()\n",
    "pbar = ProgressBar(len(testUsers), logger=logger, printRatio=0.01)\n",
    "for userId, news in testUsers.items():\n",
    "    news = set(news.keys())\n",
    "    while len(news) < ranksLength:\n",
    "        news.add(random.choice(testNewsList))\n",
    "    candidates[userId] = [news]\n",
    "    pbar.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bp(candidates, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing news from trainNews and testNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting urls:\n",
    "urls = set()\n",
    "for users in (trainUsers, testUsers):\n",
    "    for userId, news in users.items():\n",
    "        for n in news.keys():\n",
    "            urls.add(n)\n",
    "for userId, bulks in candidates.items():\n",
    "    for news in bulks:\n",
    "        for n in news:\n",
    "            urls.add(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-sampling news:\n",
    "trainNews = set([n for n in trainNews if n in urls])\n",
    "testNews = set([n for n in testNews if n in urls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp(trainNews, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp(trainUsers, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"We loose \" + str(len(previousNews)) + \" news because they are too old.\", logger)\n",
    "trainNewsCount = len(trainNews)\n",
    "log(\"We have \" + str(trainNewsCount) + \" news in train.\", logger)\n",
    "testNewsCount = len(testNews)\n",
    "log(\"We have \" + str(testNewsCount) + \" news in test.\", logger)\n",
    "totalNewsAvailable = len(newsCollection)\n",
    "log(\"Total available news in the dataset: \" + str(totalNewsAvailable), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"We loose \" + str(len(afterNews)) + \" news because they are after the end date.\", logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMeanNewsPerUser = truncateFloat(np.mean([len(n) for u, n in trainUsers.items()]), 2)\n",
    "log(\"Mean news count per user in train: \" + str(trainMeanNewsPerUser), logger)\n",
    "testMeanNewsPerUser = truncateFloat(np.mean([len(n) for u, n in testUsers.items()]), 2)\n",
    "log(\"Mean news count per user in test: \" + str(testMeanNewsPerUser), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMinNewsPerUser = min([len(n) for u, n in trainUsers.items()])\n",
    "log(\"Min news count per user in train: \" + str(trainMinNewsPerUser), logger)\n",
    "testMinNewsPerUser = min([len(n) for u, n in testUsers.items()])\n",
    "log(\"Min news count per user in test: \" + str(testMinNewsPerUser), logger)\n",
    "trainMaxNewsPerUser = max([len(n) for u, n in trainUsers.items()])\n",
    "log(\"Max news count per user in train: \" + str(trainMaxNewsPerUser), logger)\n",
    "testMaxNewsPerUser = max([len(n) for u, n in testUsers.items()])\n",
    "log(\"Max news count per user in test: \" + str(testMaxNewsPerUser), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersCount = len(trainUsers)\n",
    "log(\"Users count: \" + str(usersCount), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a new eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databasetools.mongo import MongoFS\n",
    "(user, password, host) = getMongoAuth(user='hayj')\n",
    "mfs = MongoFS(dbName=\"twinews-splits\", user=user, password=password, host=host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalMeta = dict()\n",
    "evalMeta['usersCount'] = usersCount\n",
    "evalMeta['trainNewsCount'] = trainNewsCount\n",
    "evalMeta['testNewsCount'] = testNewsCount\n",
    "evalMeta['totalNewsAvailable'] = totalNewsAvailable\n",
    "evalMeta['trainMeanNewsPerUser'] = trainMeanNewsPerUser\n",
    "evalMeta['testMeanNewsPerUser'] = testMeanNewsPerUser\n",
    "evalMeta['trainMinNewsPerUser'] = trainMinNewsPerUser\n",
    "evalMeta['testMinNewsPerUser'] = testMinNewsPerUser\n",
    "evalMeta['trainMaxNewsPerUser'] = trainMaxNewsPerUser\n",
    "evalMeta['testMaxNewsPerUser'] = testMaxNewsPerUser\n",
    "evalMeta['created'] = getDateSec()\n",
    "evalMeta['ranksLength'] = ranksLength\n",
    "evalMeta['splitDate'] = theSplit\n",
    "evalMeta['startDate'] = startDate\n",
    "evalMeta['endDate'] = endDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp(evalMeta, logger, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalData = dict()\n",
    "evalData['trainNews'] = trainNews\n",
    "evalData['testNews'] = testNews\n",
    "evalData['trainUsers'] = trainUsers\n",
    "evalData['testUsers'] = testUsers\n",
    "evalData['candidates'] = candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkEvalData(evalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mfs[version]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfs.insert(version, evalData, meta=evalMeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
