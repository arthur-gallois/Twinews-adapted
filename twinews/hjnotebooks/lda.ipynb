{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd misc-logs ; ./mv-old-logs.sh ; jupython --venv st-venv ~/notebooks/twinews/lda.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/lets-build-an-article-recommender-using-lda-f22d71b7143e\n",
    "# https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNotebook = '__file__' not in locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = isNotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.location import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.printer import *\n",
    "from databasetools.mongo import *\n",
    "from newstools.goodarticle.utils import *\n",
    "from nlptools.preprocessing import *\n",
    "from nlptools.news import parser as newsParser\n",
    "from machinelearning.iterator import *\n",
    "from twinews.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlptools.topicmodeling import *\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tictoc starts...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = Logger(tmpDir('logs') + \"/lda.log\") if isNotebook else Logger(\"lda.log\")\n",
    "tt = TicToc(logger=logger)\n",
    "tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \\\n",
    "{\n",
    "    'maxDocuments': 500 if TEST else 10000,\n",
    "    'useExtraNews': True if TEST else True, # None = unlimited, 0 = no extra news\n",
    "    'maxUsers': 20 if TEST else None, # Sub-sampling\n",
    "    'n_components': 100,\n",
    "    'lowercase': True,\n",
    "    # 'stop_words': 'english', # 'english' or None\n",
    "    'max_iter': 10 if TEST else 30,\n",
    "    'min_df': 1,\n",
    "    'max_df': 1.0,\n",
    "    # <https://www.quora.com/How-do-you-combine-LDA-and-tf-idf>\n",
    "    # <https://www.quora.com/Why-is-the-performance-improved-by-using-TFIDF-instead-of-bag-of-words-in-LDA-clustering>\n",
    "    'useTFIDF': False,\n",
    "    'useSklearn': True,\n",
    "    'doLemmatization': False if TEST else True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tic: 6.29s | message: Eval data loaded\n",
      "Unable to create index url in twinews news\n",
      "twinews news (version 1.0) initialised.\n",
      "--> tic: 9.93s | message: Extra news downloaded\n",
      "--> toc total duration: 16.22s | message: Got Twinews evaluation data\n",
      "{ candidates, created, extraNews, ranksLength, stats, testNews, testUsers, trainNews, trainUsers }\n",
      "{ testMaxNewsPerUser: 164, testMeanNewsPerUser: 10.67, testMinNewsPerUser: 2, testNewsCount: 138785, totalNewsAvailable: 570210, trainMaxNewsPerUser: 443, trainMeanNewsPerUser: 28.0, trainMinNewsPerUser: 8, trainNewsCount: 323572, usersCount: 21239 }\n"
     ]
    }
   ],
   "source": [
    "# Getting users and news\n",
    "evalData = getEvalData(1, maxExtraNews=config['maxDocuments'], maxUsers=config['maxUsers'], logger=logger)\n",
    "(trainUsers, testUsers, trainNews, testNews, candidates, extraNews) = \\\n",
    "(evalData['trainUsers'], evalData['testUsers'], evalData['trainNews'],\n",
    " evalData['testNews'], evalData['candidates'], evalData['extraNews'])\n",
    "bp(evalData.keys(), 5, logger)\n",
    "log(b(evalData['stats']), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraNewsList = shuffle(list(extraNews), seed=0)\n",
    "trainNewsList = shuffle(list(trainNews), seed=0)\n",
    "testNewsList = shuffle(list(testNews), seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500 urls for urlsForModel:\n",
      "[\n",
      "  http://bit.ly/2hRc6ws,\n",
      "  http://www.whec.com/news/rhinos-2018-season-jeopardy/4671231/,\n",
      "  ...,\n",
      "  http://www.cbc.ca/news/canada/nova-scotia/ocean-technology-the-future-of-atlantic-canada-s-economy-1,\n",
      "  https://patch.com/connecticut/fairfield/residents-urged-get-flu-shot-fairfield\n",
      "]\n",
      "19854 urls for urlsToVectorize:\n",
      "[\n",
      "  http://bit.ly/2hRc6ws,\n",
      "  http://www.whec.com/news/rhinos-2018-season-jeopardy/4671231/,\n",
      "  ...,\n",
      "  http://www.spokesman.com/stories/2018/jan/30/idaho-agency-oks-funding-for-priest-lake-improveme/,\n",
      "  https://www.nbcsandiego.com/news/local/Ramona-Snowboarder-Is-Olympic-Bound-471325214.html\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# We get urls for the LDA model:\n",
    "if config['useExtraNews']:\n",
    "    urlsForModel = extraNewsList + trainNewsList + testNewsList\n",
    "else:\n",
    "    urlsForModel = trainNewsList + testNewsList + extraNewsList\n",
    "urlsForModel = urlsForModel[:config['maxDocuments']]\n",
    "# We get urls to vectorize for the training and the inference:\n",
    "urlsToVectorize = copy.deepcopy(urlsForModel)\n",
    "for url in trainNewsList + testNewsList:\n",
    "    if url not in urlsToVectorize:\n",
    "        urlsToVectorize.append(url)\n",
    "# We get url to infere for the scoring:\n",
    "urlsToInfere = trainNewsList + testNewsList\n",
    "# Print all:\n",
    "log(str(len(urlsForModel)) + \" urls for urlsForModel:\\n\" + b(urlsForModel), logger=logger)\n",
    "log(str(len(urlsToVectorize)) + \" urls for urlsToVectorize:\\n\" + b(urlsToVectorize), logger=logger)\n",
    "log(str(len(urlsToInfere)) + \" urls for urlsToInfere:\\n\" + b(urlsToInfere), logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to create index url in twinews news\n",
      "twinews news (version 1.0) initialised.\n",
      "  0% [                    ]\n",
      "  9% [=                   ] (53.291s left)\n",
      " 19% [===                 ] (45.291s left)\n",
      " 29% [=====               ] (39.818s left)\n",
      " 39% [=======             ] (33.791s left)\n",
      " 49% [=========           ] (28.241s left)\n",
      " 59% [===========         ] (22.377s left)\n",
      " 69% [=============       ] (16.849s left)\n",
      " 79% [===============     ] (11.153s left)\n",
      " 89% [=================   ] (5.602s left)\n",
      " 99% [=================== ] (0.011s left)\n",
      "100% [====================] (total duration: 55.5s, mean duration: 0.002s)\n",
      "[\n",
      "  [ [ A, drip, ..., Folsom, . ], [ Today, __int_2__, ..., drought, . ], ..., [ Contact, him, at, __email__ ], [ Joe, Grindstaff, ..., Agency, . ] ],\n",
      "  [ [ \", There, ..., statement, . ], [ \", We, ..., Rhinos, . ], ..., [ Capelli, Stadium, ..., County, . ], [ Monroe, County, ..., parks, . ] ],\n",
      "  ...,\n",
      "  [ [ The, Idaho, ..., lakes, . ], [ The, upgrades, ..., River, . ], ..., [ The, water, ..., funds, . ], [ Butch, Otter, ..., year, . ] ],\n",
      "  [ [ NBC, __int_1__, ..., Russia, . ], [ Seamus, bleeds, ..., green, . ], ..., [ Then, on, ..., qualify, . ], [ estimates, his, ..., return, . ] ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# We get sentences:\n",
    "sentences = getNewsSentences(urlsToVectorize, logger=logger)\n",
    "bp(sentences, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ [ A, drip, ..., Agency, . ], [ \", There, ..., parks, . ], ..., [ The, Idaho, ..., year, . ], [ NBC, __int_1__, ..., return, . ] ]\n"
     ]
    }
   ],
   "source": [
    "# We flatten sentences:\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = flattenLists(sentences[i])\n",
    "docs = sentences\n",
    "bp(docs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ [ a, drip, ..., agency, . ], [ \", there, ..., parks, . ], ..., [ the, idaho, ..., year, . ], [ nbc, __int_1__, ..., return, . ] ]\n"
     ]
    }
   ],
   "source": [
    "# Lower case:\n",
    "if config['lowercase']:\n",
    "    for i in range(len(docs)):\n",
    "        for u in range(len(docs[i])):\n",
    "            docs[i][u] = docs[i][u].lower()\n",
    "bp(docs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% [                    ]\n",
      "  9% [=                   ] (2m 24.302s left)\n",
      " 19% [===                 ] (1m 46.946s left)\n",
      " 29% [=====               ] (1m 27.618s left)\n",
      " 39% [=======             ] (1m 11.063s left)\n",
      " 49% [=========           ] (57.753s left)\n",
      " 59% [===========         ] (45.142s left)\n",
      " 69% [=============       ] (33.33s left)\n",
      " 79% [===============     ] (21.969s left)\n",
      " 89% [=================   ] (10.855s left)\n",
      " 99% [=================== ] (0.021s left)\n",
      "100% [====================] (total duration: 1m 47.22s, mean duration: 0.005s)\n",
      "[ [ a, drip, ..., agency, . ], [ \", there, ..., park, . ], ..., [ the, idaho, ..., year, . ], [ nbc, __int_1__, ..., return, . ] ]\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization:\n",
    "if config['doLemmatization']:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    pbar = ProgressBar(len(docs), logger=logger, message=\"Lemmatization\")\n",
    "    for i in range(len(docs)):\n",
    "        for u in range(len(docs[i])):\n",
    "            docs[i][u] = lemmatizer.lemmatize(docs[i][u])\n",
    "        pbar.tic()\n",
    "bp(docs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infering topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['useSklearn']:\n",
    "    if config['useTFIDF']:\n",
    "        vectorizer = TfidfVectorizer\\\n",
    "        (\n",
    "            sublinear_tf=True,\n",
    "            tokenizer=lambda x: x,\n",
    "            preprocessor=lambda x: x,\n",
    "            # lowercase=True, # Doesn't work because we erased preprocessor\n",
    "            min_df=config['min_df'],\n",
    "            max_df=config['max_df'],\n",
    "        )\n",
    "    else:\n",
    "        vectorizer = CountVectorizer\\\n",
    "        (\n",
    "            tokenizer=lambda x: x,\n",
    "            preprocessor=lambda x: x,\n",
    "            # lowercase=True, # Doesn't work because we erased preprocessor\n",
    "            min_df=config['min_df'],\n",
    "            max_df=config['max_df'],\n",
    "        )\n",
    "    vectors = vectorizer.fit_transform(docs)\n",
    "    assert vectors.shape[0] == len(urlsToVectorize)\n",
    "    vectorsForModel = vectors[:len(urlsForModel)]\n",
    "    assert vectorsForModel.shape[0] == config['maxDocuments']\n",
    "    i = 0\n",
    "    for url in urlsToVectorize:\n",
    "        if url == trainNewsList[0]:\n",
    "            break\n",
    "        i += 1\n",
    "    assert i == len(extraNews) or i == 0\n",
    "    vectorsForInference = vectors[i:i + len(trainNews) + len(testNews)]\n",
    "    assert vectorsForInference.shape[0] == len(trainNews) + len(testNews)\n",
    "    learning_method = 'online'\n",
    "    learning_offset = 1.0\n",
    "    lda = LatentDirichletAllocation\\\n",
    "    (\n",
    "        n_components=config['n_components'],\n",
    "        max_iter=config['max_iter'],\n",
    "        learning_method=learning_method,\n",
    "        learning_offset=learning_offset,\n",
    "        random_state=0,\n",
    "        n_jobs=cpuCount(),\n",
    "    )\n",
    "    lda.fit(vectorsForModel)\n",
    "    inferedVectors = lda.transform(vectorsForInference)\n",
    "    assert inferedVectors.shape[0] == len(trainNews) + len(testNews)\n",
    "    assert inferedVectors[0].shape[0] == config['n_components']\n",
    "    topics = []\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        wordProb = []\n",
    "        for i in range(len(topic)):\n",
    "            prob = topic[i]\n",
    "            word = feature_names[i]\n",
    "            wordProb.append((word, prob))\n",
    "        wordProb = sortBy(wordProb, desc=True, index=1)[:100]\n",
    "        current = dict()\n",
    "        for word, prob in wordProb:\n",
    "            current[word] = prob\n",
    "        topics.append(current)\n",
    "else:\n",
    "    dictionary = gensim.corpora.Dictionary(docs)\n",
    "    dictionary.filter_extremes(no_below=config['min_df'])\n",
    "    bow = [dictionary.doc2bow(doc) for doc in docs]\n",
    "    if config['useTFIDF']:\n",
    "        tfidf = gensim.models.TfidfModel(bow)\n",
    "        bow = tfidf[bow]\n",
    "    assert len(bow) == len(urlsToVectorize)\n",
    "    bowForModel = bow[:len(urlsForModel)]\n",
    "    assert len(bowForModel) == config['maxDocuments']\n",
    "    i = 0\n",
    "    for url in urlsToVectorize:\n",
    "        if url == trainNewsList[0]:\n",
    "            break\n",
    "        i += 1\n",
    "    assert i == len(extraNews) or i == 0\n",
    "    bowForInference = bow[i:i + len(trainNews) + len(testNews)]\n",
    "    assert len(bowForInference) == len(trainNews) + len(testNews)\n",
    "    lda_model = gensim.models.LdaMulticore\\\n",
    "    (\n",
    "        bowForModel,\n",
    "        num_topics=config['n_components'],\n",
    "        id2word=dictionary,\n",
    "        iterations=config['max_iter'],\n",
    "        workers=cpuCount(),\n",
    "        passes=3,\n",
    "    )\n",
    "    inferedVectors = []\n",
    "    for current in bowForInference:\n",
    "        topicProbDistrib = lda_model[current]\n",
    "        currentVector = [0.0] * config['n_components']\n",
    "        for t, v in topicProbDistrib:\n",
    "            currentVector[t] = v\n",
    "        inferedVectors.append(np.array(currentVector))\n",
    "    assert len(inferedVectors) == len(trainNews) + len(testNews)\n",
    "    assert len(inferedVectors[0]) == config['n_components']\n",
    "    topics = []\n",
    "    for i in range(lda_model.num_topics):\n",
    "        current = dict()\n",
    "        for x in lda_model.get_topic_terms(i, topn=100):\n",
    "            current[dictionary[x[0]]] = x[1]\n",
    "        topics.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isNotebook:\n",
    "    dirPath = nosaveDir() + \"/lda-models\"\n",
    "    mkdir(dirPath)\n",
    "    serialize(lda, dirPath + \"/lda1.pickle\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a dict url --> topic vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\n",
      "  http://a.msn.com/00/en-ca/AAuP4NT?ocid=st: [9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 8.04699325e-01 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 1.92421385e-01\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 1.94389953e-03 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06\n",
      "   9.64320154e-06 9.64320154e-06 9.64320154e-06 9.64320154e-06],\n",
      "  http://a.msn.com/00/en-us/AAuRdZ6?ocid=st: [2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 1.23008538e-01 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 8.74966669e-01\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05\n",
      "   2.06611570e-05 2.06611570e-05 2.06611570e-05 2.06611570e-05],\n",
      "  http://a.msn.com/00/en-us/AAuSDKo?ocid=st: [2.14132762e-05 2.16274091e-03 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 7.79683850e-01 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.16076322e-01\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05\n",
      "   2.14132762e-05 2.14132762e-05 2.14132762e-05 2.14132762e-05],\n",
      "  http://a.msn.com/00/en-us/AAv6fui?ocid=st: [1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 6.71763414e-01 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 3.27866550e-01\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.88964370e-04 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06\n",
      "   1.86671645e-06 1.86671645e-06 1.86671645e-06 1.86671645e-06],\n",
      "  http://a.msn.com/00/en-us/AAva3us?ocid=st: [4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 6.76042074e-01 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 3.19399787e-01\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05\n",
      "   4.65116279e-05 4.65116279e-05 4.65116279e-05 4.65116279e-05],\n",
      "  ...,\n",
      "  https://yesmeansyesblog.wordpress.com/2009/11/24/predator-redux/: [5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 4.33938473e-01 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.65568073e-01\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06\n",
      "   5.03524673e-06 5.03524673e-06 5.03524673e-06 5.03524673e-06],\n",
      "  https://zdubbzattmom.wordpress.com/2018/01/29/zakks-manifesto-or-hitting-the-reset-button-in-2018/: [4.88758553e-06 4.93646140e-04 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 2.18272079e-01 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 7.80263671e-01\n",
      "   4.88758553e-06 4.88758553e-06 5.01395720e-04 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06\n",
      "   4.88758553e-06 4.88758553e-06 4.88758553e-06 4.88758553e-06],\n",
      "  https://zdubbzattmom.wordpress.com/2018/01/31/zakk-reviews-what-we-reckon-by-eryk-pruitt/: [9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 1.87771297e-01 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 8.11303302e-01\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06\n",
      "   9.44287063e-06 9.44287063e-06 9.44287063e-06 9.44287063e-06],\n",
      "  https://zdubbzattmom.wordpress.com/2018/02/07/zakk-reviews-martuk-the-holy-by-jonathan-winn/: [8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 2.27318538e-01 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 7.71812667e-01\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06\n",
      "   8.86524823e-06 8.86524823e-06 8.86524823e-06 8.86524823e-06],\n",
      "  https://zezeewithbooks.wordpress.com/2018/02/05/im-finally-hosting-a-giveaway/: [4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 1.09800415e-01 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 8.85901339e-01\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05\n",
      "   4.38596491e-05 4.38596491e-05 4.38596491e-05 4.38596491e-05]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "assert len(urlsToInfere) == len(inferedVectors)\n",
    "urlsVectors = dict()\n",
    "for i in range(len(urlsToInfere)):\n",
    "    urlsVectors[urlsToInfere[i]] = inferedVectors[i]\n",
    "bp(urlsVectors, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% [                    ]\n",
      "  9% [=                   ] (50.411s left)\n",
      " 19% [===                 ] (44.011s left)\n",
      " 29% [=====               ] (38.044s left)\n",
      " 39% [=======             ] (32.066s left)\n",
      " 49% [=========           ] (26.781s left)\n",
      " 59% [===========         ] (21.864s left)\n",
      " 69% [=============       ] (16.301s left)\n",
      " 79% [===============     ] (10.786s left)\n",
      " 89% [=================   ] (5.376s left)\n",
      " 99% [=================== ] (0.011s left)\n",
      "100% [====================] (total duration: 53.46s, mean duration: 0.002s)\n",
      "{\n",
      "  http://a.msn.com/00/en-ca/AAuP4NT?ocid=st: The Bank of Canada raised its benchmark interest rate to 1.25 per cent Wednesday and signalled that,,\n",
      "  http://a.msn.com/00/en-us/AAuRdZ6?ocid=st: Whether you're buying your first or tenth, Jay Leno has a word of warning: Don't let other people sw,\n",
      "  http://a.msn.com/00/en-us/AAuSDKo?ocid=st: Three weeks after picking up a controversial cargo in the U.K., a liquefied natural gas tanker made ,\n",
      "  http://a.msn.com/00/en-us/AAv6fui?ocid=st: Last March, Royal Dutch Shell said it was selling most of its stake in Canada's oil sands, a vast pr,\n",
      "  http://a.msn.com/00/en-us/AAva3us?ocid=st: Home Depot is awarding its hourly employees in the U.S. a one-time cash bonus of as much as $1,000 f,\n",
      "  ...,\n",
      "  https://yesmeansyesblog.wordpress.com/2009/11/24/predator-redux/: by Thomas\n",
      "Meet The Predators , which featured a 2002 study co-authored by psychology professor David,\n",
      "  https://zdubbzattmom.wordpress.com/2018/01/29/zakks-manifesto-or-hitting-the-reset-button-in-2018/: \"Ex Libris The Eyes of Madness, simple reviews from a simple reader...\"\n",
      "It is difficult getting thin,\n",
      "  https://zdubbzattmom.wordpress.com/2018/01/31/zakk-reviews-what-we-reckon-by-eryk-pruitt/: \"Ex Libris The Eyes of Madness, simple reviews from a simple reader...\"\n",
      "Zakk reviews What We Reckon ,\n",
      "  https://zdubbzattmom.wordpress.com/2018/02/07/zakk-reviews-martuk-the-holy-by-jonathan-winn/: \"Ex Libris The Eyes of Madness, simple reviews from a simple reader...\"\n",
      "Zakk reviews Martuk... the H,\n",
      "  https://zezeewithbooks.wordpress.com/2018/02/05/im-finally-hosting-a-giveaway/: I'm feeling a bit shy about this because this is the first GIVEAWAY I'm hosting on here. It's been a\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "urlsTexts = dict()\n",
    "allTexts = getNewsText(urlsToInfere, logger=logger)\n",
    "for i in range(len(urlsToInfere)):\n",
    "    urlsTexts[urlsToInfere[i]] = allTexts[i]\n",
    "bp(urlsTexts, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\n",
      "  http://bit.ly/2heH8Nm,\n",
      "  http://wapo.st/2zbVacE,\n",
      "  ...,\n",
      "  https://fb.me/9Chq3ugeZ,\n",
      "  https://www.nbcnews.com/news/us-news/trump-s-history-breaking-decorum-remarks-race-ethnicity-n837181\n",
      "]\n",
      "[[2.80898876e-05 2.80898876e-05 2.80898876e-05 ... 2.80898876e-05\n",
      "  2.80898876e-05 2.80898876e-05]\n",
      " [5.31349628e-06 5.31349628e-06 5.31349628e-06 ... 5.31349628e-06\n",
      "  5.31349628e-06 5.31349628e-06]\n",
      " [3.38983051e-05 3.38983051e-05 3.38983051e-05 ... 3.38983051e-05\n",
      "  3.38983051e-05 3.38983051e-05]\n",
      " ...\n",
      " [2.71002710e-05 2.71002710e-05 2.71002710e-05 ... 2.71002710e-05\n",
      "  2.71002710e-05 2.71002710e-05]\n",
      " [1.00806452e-05 1.00806452e-05 1.00806452e-05 ... 1.00806452e-05\n",
      "  1.00806452e-05 1.00806452e-05]\n",
      " [8.65051903e-06 8.65051903e-06 8.65051903e-06 ... 8.65051903e-06\n",
      "  8.65051903e-06 8.65051903e-06]]\n",
      "[\n",
      "  https://www.naplesnews.com/story/sports/high-school/girls-basketball/2018/02/08/prep-girls-basketbal,\n",
      "  https://buff.ly/2EnN3sV,\n",
      "  ...,\n",
      "  https://mississippitoday.org/2018/01/30/who-gets-state-dollars-to-help-pay-for-college-in-mississipp,\n",
      "  https://www.forbes.com/sites/amberjohnson-jimludema/2018/01/18/how-do-you-develop-leaders-on-a-budge\n",
      "]\n",
      "[[1.90476190e-05 1.90476190e-05 1.90476190e-05 ... 1.90476190e-05\n",
      "  1.90476190e-05 1.90476190e-05]\n",
      " [2.38095238e-05 2.38095238e-05 2.38095238e-05 ... 2.38095238e-05\n",
      "  2.38095238e-05 2.38095238e-05]\n",
      " [9.55109838e-06 9.55109838e-06 9.55109838e-06 ... 9.55109838e-06\n",
      "  9.55109838e-06 9.55109838e-06]\n",
      " ...\n",
      " [3.87596899e-05 3.87596899e-05 3.87596899e-05 ... 3.87596899e-05\n",
      "  3.87596899e-05 3.87596899e-05]\n",
      " [6.26174076e-06 6.26174076e-06 6.26174076e-06 ... 6.26174076e-06\n",
      "  6.26174076e-06 6.26174076e-06]\n",
      " [7.91765637e-06 7.91765637e-06 7.91765637e-06 ... 7.91765637e-06\n",
      "  7.91765637e-06 7.91765637e-06]]\n"
     ]
    }
   ],
   "source": [
    "userId = list(trainUsers.keys())[1]\n",
    "xvectors = []\n",
    "xurls = []\n",
    "for url in trainUsers[userId]:\n",
    "    xvectors.append(urlsVectors[url])\n",
    "    xurls.append(url)\n",
    "xvectors = np.array(xvectors)\n",
    "bp(xurls, logger)\n",
    "bp(xvectors, logger)\n",
    "yvectors = []\n",
    "yurls = []\n",
    "for url in candidates[userId][0]:\n",
    "    yvectors.append(urlsVectors[url])\n",
    "    yurls.append(url)\n",
    "yvectors = np.array(yvectors)\n",
    "bp(yurls, logger)\n",
    "bp(yvectors, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = cosine_similarity(xvectors, yvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO faire une proportion de top pour faire la moyenne de similarité d'un candidat\n",
    "# Donc soit la variable prends un ratio par rapport au nombre de train, soit un nombre de train..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for i in range(10):\n",
    "        trainIndex = random.choice(list(range(len(xurls))))\n",
    "        testIndex = random.choice(list(range(len(yurls))))\n",
    "        trainUrl = xurls[trainIndex]\n",
    "        testUrl = yurls[testIndex]\n",
    "        trainText = urlsTexts[trainUrl]\n",
    "        testText = urlsTexts[testUrl]\n",
    "        sim = sims[trainIndex][testIndex]\n",
    "        if len(trainText) < 2000 and len(testText) < 2000 and (sim < 0.2 or sim > 0.8):\n",
    "            log(sim, logger)\n",
    "            log(\"\\n\", logger)\n",
    "            log(trainUrl, logger)\n",
    "            log(trainText, logger)\n",
    "            log(\"\\n\", logger)\n",
    "            log(testUrl, logger)\n",
    "            log(testText, logger)\n",
    "            log(\"\\n\" * 2 + '-' * 20 + \"\\n\" * 2, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    currentSims = []\n",
    "    for u in range(len(yurls)):\n",
    "        currentSims.append((yurls[u], urlsTexts[yurls[u]], sims[i][u]))\n",
    "    topSim = sortBy(currentSims, index=2, desc=True)[:3]\n",
    "    topDissim = sortBy(currentSims, index=2, desc=False)[:3]\n",
    "    trainUrl = xurls[i]\n",
    "    trainText = urlsTexts[trainUrl]\n",
    "    log(trainUrl, logger)\n",
    "    log(trainText, logger)\n",
    "    log(\"\\n\", logger)\n",
    "    log(\"MOST SIMILARS\", logger)\n",
    "    log(\"\\n\", logger)\n",
    "    for url, text, sim in topSim:\n",
    "        log(sim, logger)\n",
    "        log(url, logger)\n",
    "        log(text, logger)\n",
    "        log(\"\\n\", logger)\n",
    "    log(\"MOST DISSIMILARS\", logger)\n",
    "    log(\"\\n\", logger)\n",
    "    for url, text, sim in topDissim:\n",
    "        log(sim, logger)\n",
    "        log(url, logger)\n",
    "        log(text, logger)\n",
    "        log(\"\\n\", logger)\n",
    "    log(\"\\n\", logger)\n",
    "    log(\"\\n\" * 2 + '-' * 20 + \"\\n\" * 2, logger)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
