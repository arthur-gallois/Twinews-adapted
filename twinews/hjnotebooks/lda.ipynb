{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/lets-build-an-article-recommender-using-lda-f22d71b7143e\n",
    "# https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNotebook = '__file__' not in locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = isNotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.location import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.printer import *\n",
    "from databasetools.mongo import *\n",
    "from newstools.goodarticle.utils import *\n",
    "from nlptools.preprocessing import *\n",
    "from nlptools.news import parser as newsParser\n",
    "from machinelearning.iterator import *\n",
    "from twinews.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlptools.topicmodeling import *\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tictoc starts...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = Logger(tmpDir('logs') + \"/lda.log\") if isNotebook else Logger(\"lda.log\")\n",
    "tt = TicToc(logger=logger)\n",
    "tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \\\n",
    "{\n",
    "    'maxDocuments': 500 if TEST else None,\n",
    "    'useExtraNews': True if TEST else False, # None = unlimited, 0 = no extra news\n",
    "    'maxUsers': 20 if TEST else None, # Sub-sampling\n",
    "    'n_components': 100,\n",
    "    'lowercase': True,\n",
    "    # 'stop_words': 'english', # 'english' or None\n",
    "    'max_iter': 2 if TEST else 30,\n",
    "    'min_df': 10,\n",
    "    'max_df': 0.8,\n",
    "    # <https://www.quora.com/How-do-you-combine-LDA-and-tf-idf>\n",
    "    # <https://www.quora.com/Why-is-the-performance-improved-by-using-TFIDF-instead-of-bag-of-words-in-LDA-clustering>\n",
    "    'useTFIDF': True,\n",
    "    'useSklearn': True,\n",
    "    'doLemmatization': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tic: 6.36s | message: Eval data loaded\n",
      "Unable to create index url in twinews news\n",
      "twinews news (version 1.0) initialised.\n",
      "--> tic: 8.36s | message: Extra news downloaded\n",
      "--> toc total duration: 14.73s | message: Got Twinews evaluation data\n",
      "{ candidates, created, extraNews, ranksLength, stats, testNews, testUsers, trainNews, trainUsers }\n",
      "{ testMaxNewsPerUser: 164, testMeanNewsPerUser: 10.67, testMinNewsPerUser: 2, testNewsCount: 138785, totalNewsAvailable: 570210, trainMaxNewsPerUser: 443, trainMeanNewsPerUser: 28.0, trainMinNewsPerUser: 8, trainNewsCount: 323572, usersCount: 21239 }\n"
     ]
    }
   ],
   "source": [
    "# Getting users and news\n",
    "evalData = getEvalData(1, maxExtraNews=config['maxDocuments'], maxUsers=config['maxUsers'], logger=logger)\n",
    "(trainUsers, testUsers, trainNews, testNews, candidates, extraNews) = \\\n",
    "(evalData['trainUsers'], evalData['testUsers'], evalData['trainNews'],\n",
    " evalData['testNews'], evalData['candidates'], evalData['extraNews'])\n",
    "bp(evalData.keys(), 5, logger)\n",
    "log(b(evalData['stats']), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraNewsList = list(extraNews)\n",
    "trainNewsList = list(trainNews)\n",
    "testNewsList = list(testNews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500 urls for urlsForModel:\n",
      "[\n",
      "  http://www.huffingtonpost.com/entry/little-havana-sits-in-darkness_us_59b9c341e4b086432b0433ff,\n",
      "  http://knowledge.wharton.upenn.edu/article/jeremy-siegel-whats-ahead-u-s-economy-2018/,\n",
      "  ...,\n",
      "  http://www.huffingtonpost.com/entry/white-house-sidewalk-closed_us_58f884a4e4b0cb086d7e3c43,\n",
      "  https://goo.gl/CUvP3R\n",
      "]\n",
      "19854 urls for urlsToVectorize:\n",
      "[\n",
      "  http://www.huffingtonpost.com/entry/little-havana-sits-in-darkness_us_59b9c341e4b086432b0433ff,\n",
      "  http://knowledge.wharton.upenn.edu/article/jeremy-siegel-whats-ahead-u-s-economy-2018/,\n",
      "  ...,\n",
      "  https://biochem.wisc.edu/news/2017/news-biochemistry-youth-apprenticeship-2017-07-27,\n",
      "  http://www.islandpacket.com/news/local/community/beaufort-news/article196262139.html\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# We get urls for the LDA model:\n",
    "if config['useExtraNews']:\n",
    "    urlsForModel = extraNewsList + trainNewsList + testNewsList\n",
    "else:\n",
    "    urlsForModel = trainNewsList + testNewsList + extraNewsList\n",
    "urlsForModel = urlsForModel[:config['maxDocuments']]\n",
    "# We get urls to vectorize for the training and the inference:\n",
    "urlsToVectorize = copy.deepcopy(urlsForModel)\n",
    "for url in list(trainNews) + list(testNews):\n",
    "    if url not in urlsToVectorize:\n",
    "        urlsToVectorize.append(url)\n",
    "# Print all:\n",
    "log(str(len(urlsForModel)) + \" urls for urlsForModel:\\n\" + b(urlsForModel), logger=logger)\n",
    "log(str(len(urlsToVectorize)) + \" urls for urlsToVectorize:\\n\" + b(urlsToVectorize), logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to create index url in twinews news\n",
      "twinews news (version 1.0) initialised.\n",
      "  0% [                    ]\n",
      "  9% [=                   ] (51.671s left)\n",
      " 19% [===                 ] (43.931s left)\n",
      " 29% [=====               ] (38.791s left)\n",
      " 39% [=======             ] (33.131s left)\n",
      " 49% [=========           ] (27.411s left)\n",
      " 59% [===========         ] (21.704s left)\n",
      " 69% [=============       ] (16.318s left)\n",
      " 79% [===============     ] (10.808s left)\n",
      " 89% [=================   ] (5.458s left)\n",
      " 99% [=================== ] (0.01s left)\n",
      "100% [====================] (total duration: 54.34s, mean duration: 0.002s)\n",
      "[\n",
      "  [ [ MIAMI, Hurricane, ..., day, . ], [ By, Tuesday, ..., return, . ], ..., [ But, they, ..., anxious, . ], [ You, can, ..., eyes, . ] ],\n",
      "  [ [ It, was, ..., hour, . ], [ According, to, ..., in, __int_4__ ], ..., [ I, think, ..., center, . ], [ Those, will, ..., investors, . ] ],\n",
      "  ...,\n",
      "  [ [ Jenna, Amro, ..., Madison, . ], [ She, can, ..., school, . ], ..., [ \", Having, ..., says, . ], [ \", So, ..., Wisconsin, . ] ],\n",
      "  [ [ Order, Reprint, ..., Capt, . ], [ Bob, Bromage, ..., night, . ], ..., [ Our, journalism, ..., produce, . ], [ If, you, ..., today, . ] ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# We get sentences:\n",
    "sentences = getNewsSentences(urlsToVectorize, logger=logger)\n",
    "bp(sentences, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ [ MIAMI, Hurricane, ..., eyes, . ], [ It, was, ..., investors, . ], ..., [ Jenna, Amro, ..., Wisconsin, . ], [ Order, Reprint, ..., today, . ] ]\n"
     ]
    }
   ],
   "source": [
    "# We flatten sentences:\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = flattenLists(sentences[i])\n",
    "docs = sentences\n",
    "bp(docs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ [ miami, hurricane, ..., eyes, . ], [ it, was, ..., investors, . ], ..., [ jenna, amro, ..., wisconsin, . ], [ order, reprint, ..., today, . ] ]\n"
     ]
    }
   ],
   "source": [
    "# Lower case:\n",
    "if config['lowercase']:\n",
    "    for i in range(len(docs)):\n",
    "        for u in range(len(docs[i])):\n",
    "            docs[i][u] = docs[i][u].lower()\n",
    "bp(docs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ [ miami, hurricane, ..., eye, . ], [ it, wa, ..., investor, . ], ..., [ jenna, amro, ..., wisconsin, . ], [ order, reprint, ..., today, . ] ]\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization:\n",
    "if config['doLemmatization']:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for i in range(len(docs)):\n",
    "        for u in range(len(docs[i])):\n",
    "            docs[i][u] = lemmatizer.lemmatize(docs[i][u])\n",
    "bp(docs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infering topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['useSklearn']:\n",
    "    if config['useTFIDF']:\n",
    "        vectorizer = TfidfVectorizer\\\n",
    "        (\n",
    "            sublinear_tf=True,\n",
    "            tokenizer=lambda x: x,\n",
    "            preprocessor=lambda x: x,\n",
    "            # lowercase=True, # Doesn't work because we erased preprocessor\n",
    "            min_df=config['min_df'],\n",
    "            max_df=config['max_df'],\n",
    "        )\n",
    "    else:\n",
    "        vectorizer = CountVectorizer\\\n",
    "        (\n",
    "            tokenizer=lambda x: x,\n",
    "            preprocessor=lambda x: x,\n",
    "            # lowercase=True, # Doesn't work because we erased preprocessor\n",
    "            min_df=config['min_df'],\n",
    "            max_df=config['max_df'],\n",
    "        )\n",
    "    vectors = vectorizer.fit_transform(docs)\n",
    "    assert vectors.shape[0] == len(urlsToVectorize)\n",
    "    vectorsForModel = vectors[:len(urlsForModel)]\n",
    "    assert vectorsForModel.shape[0] == config['maxDocuments']\n",
    "    i = 0\n",
    "    for url in urlsToVectorize:\n",
    "        if url == trainNewsList[0]:\n",
    "            break\n",
    "        i += 1\n",
    "    assert i == len(extraNews) or i == 0\n",
    "    vectorsForInference = vectors[i:i + len(trainNews) + len(testNews)]\n",
    "    assert vectorsForInference.shape[0] == len(trainNews) + len(testNews)\n",
    "    learning_method = 'online'\n",
    "    learning_offset = 1.0\n",
    "    lda = LatentDirichletAllocation\\\n",
    "    (\n",
    "        n_components=config['n_components'],\n",
    "        max_iter=config['max_iter'],\n",
    "        learning_method=learning_method,\n",
    "        learning_offset=learning_offset,\n",
    "        random_state=0,\n",
    "        n_jobs=cpuCount(),\n",
    "    )\n",
    "    lda.fit(vectorsForModel)\n",
    "    inferedVectors = lda.transform(vectorsForInference)\n",
    "    assert inferedVectors.shape[0] == len(trainNews) + len(testNews)\n",
    "    assert inferedVectors[0].shape[0] == config['n_components']\n",
    "else:\n",
    "    dictionary = gensim.corpora.Dictionary(docs)\n",
    "    dictionary.filter_extremes(no_below=config['min_df'])\n",
    "    bow = [dictionary.doc2bow(doc) for doc in docs]\n",
    "    if config['useTFIDF']:\n",
    "        tfidf = gensim.models.TfidfModel(bow)\n",
    "        bow = tfidf[bow]\n",
    "    assert len(bow) == len(urlsToVectorize)\n",
    "    bowForModel = bow[:len(urlsForModel)]\n",
    "    assert len(bowForModel) == config['maxDocuments']\n",
    "    i = 0\n",
    "    for url in urlsToVectorize:\n",
    "        if url == trainNewsList[0]:\n",
    "            break\n",
    "        i += 1\n",
    "    assert i == len(extraNews) or i == 0\n",
    "    bowForInference = bow[i:i + len(trainNews) + len(testNews)]\n",
    "    assert len(bowForInference) == len(trainNews) + len(testNews)\n",
    "    lda_model = gensim.models.LdaMulticore(bowForModel, num_topics=config['n_components'],\n",
    "                    id2word=dictionary, passes=config['max_iter'], workers=cpuCount())\n",
    "    inferedVectors = []\n",
    "    for current in bowForInference:\n",
    "        topicProbDistrib = lda_model[current]\n",
    "        currentVector = [0.0] * config['n_components']\n",
    "        for t, v in topicProbDistrib:\n",
    "            currentVector[t] = v\n",
    "        inferedVectors.append(np.array(currentVector))\n",
    "    assert len(inferedVectors) == len(trainNews) + len(testNews)\n",
    "    assert len(inferedVectors[0]) == config['n_components']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a dict url --> topic vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlsForInf = trainNewsList + testNewsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(urlsForInf) == len(inferedVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlsVectors = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(urlsForInf)):\n",
    "    urlsVectors[urlsForInf[i]] = inferedVectors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\n",
      "  http://a.msn.com/00/en-ca/AAuP4NT?ocid=st: [6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 9.32710769e-01 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 7.84656610e-03\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04\n",
      "   6.06557809e-04 6.06557809e-04 6.06557809e-04 6.06557809e-04],\n",
      "  http://a.msn.com/00/en-us/AAuRdZ6?ocid=st: [7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 9.22646973e-01 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04\n",
      "   7.81343709e-04 7.81343709e-04 7.81343709e-04 7.81343709e-04],\n",
      "  http://a.msn.com/00/en-us/AAuSDKo?ocid=st: [7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 8.70336982e-01 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 4.42115879e-02\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   8.17284710e-03 7.96686423e-04 7.96686423e-04 7.96686423e-04\n",
      "   7.96686423e-04 7.96686423e-04 7.96686423e-04 7.96686423e-04],\n",
      "  http://a.msn.com/00/en-us/AAv6fui?ocid=st: [3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 9.27553046e-01 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 4.20134605e-02\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04\n",
      "   3.10545847e-04 3.10545847e-04 3.10545847e-04 3.10545847e-04],\n",
      "  http://a.msn.com/00/en-us/AAva3us?ocid=st: [0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.89340168 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675 0.00107675 0.00107675\n",
      "   0.00107675 0.00107675 0.00107675 0.00107675],\n",
      "  ...,\n",
      "  https://yesmeansyesblog.wordpress.com/2009/11/24/predator-redux/: [4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 9.44868874e-01 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.30998378e-03\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.52777674e-03 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   1.95790420e-03 4.61827726e-04 4.61827726e-04 4.61827726e-04\n",
      "   4.61827726e-04 4.61827726e-04 4.61827726e-04 4.61827726e-04],\n",
      "  https://zdubbzattmom.wordpress.com/2018/01/29/zakks-manifesto-or-hitting-the-reset-button-in-2018/: [4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 9.45756485e-01 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 1.03409653e-02\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04\n",
      "   4.47985205e-04 4.47985205e-04 4.47985205e-04 4.47985205e-04],\n",
      "  https://zdubbzattmom.wordpress.com/2018/01/31/zakk-reviews-what-we-reckon-by-eryk-pruitt/: [5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 9.21351600e-01 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 1.76214456e-02\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   8.35434420e-03 5.43016597e-04 5.43016597e-04 5.43016597e-04\n",
      "   5.43016597e-04 5.43016597e-04 5.43016597e-04 5.43016597e-04],\n",
      "  https://zdubbzattmom.wordpress.com/2018/02/07/zakk-reviews-martuk-the-holy-by-jonathan-winn/: [5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 6.58480607e-03 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 9.19356230e-01 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 2.08481523e-02\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   1.83428845e-03 5.35172121e-04 5.35172121e-04 5.35172121e-04\n",
      "   5.35172121e-04 5.35172121e-04 5.35172121e-04 5.35172121e-04],\n",
      "  https://zezeewithbooks.wordpress.com/2018/02/05/im-finally-hosting-a-giveaway/: [0.00107063 0.00107063 0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063 0.87723911 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.0178389  0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063 0.00107063 0.00107063\n",
      "   0.00107063 0.00107063 0.00107063 0.00107063]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "bp(urlsVectors, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
