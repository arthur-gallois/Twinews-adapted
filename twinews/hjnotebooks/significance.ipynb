{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twinews import config as twinewsConf\n",
    "twinewsConf.mongoLocation = 'octods'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.location import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.printer import *\n",
    "from datastructuretools.cache import *\n",
    "from twinews.utils import *\n",
    "from twinews.evaluation.utils import *\n",
    "from twinews.models.ranking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataviztools import bokehutils\n",
    "from bokeh.plotting import output_notebook, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(bokehutils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE IMPORTANTE\n",
    "# Si on a un \"CorruptGridFile: no chunk #0\" après un restore, faire :\n",
    "# pruneRankings('combin-d0fd0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing stats on rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twinewsRankings = getTwinewsRankings()\n",
    "splitVersion = 1\n",
    "models = set()\n",
    "for row in twinewsRankings.collection.find({\"meta.splitVersion\": splitVersion, 'meta.maxUsers': None}):\n",
    "    if row['meta']['model'] != 'combin':\n",
    "        models.add(row['meta']['model'])\n",
    "models.remove('worst')\n",
    "models.remove('ideal')\n",
    "models.remove('random')\n",
    "keys = set()\n",
    "for model in models:\n",
    "    keys.add(twinewsRankings.collection.find_one({'meta.model': model,\n",
    "                                                  \"meta.splitVersion\": splitVersion,\n",
    "                                                  'meta.maxUsers': None})['id'])\n",
    "# keys.add(\"combin-8f846\")\n",
    "# keys.add(\"combin-efad4\")\n",
    "keys = sorted(list(keys))\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in twinewsRankings.keys():\n",
    "    meta = twinewsRankings.getMeta(key)\n",
    "    if 'models' in meta and 'doc2vec-e013a' in meta['models'] and 'dbert-ft-7847a' in meta['models']:\n",
    "        print(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * bm25-933f7\n",
    " * tfidf-4a1dc\n",
    " * bm25-933f7 + dbert-ft-7847a = combin-8f846\n",
    " * dbert-ft-7847a + tfidf-4a1dc = combin-6ecf3\n",
    " * bm25-933f7 + doc2vec-e013a = combin-6fad8\n",
    " * dbert-ft-7847a + doc2vec-e013a = combin-d0fd0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twinewsRankings.collection.find_one({'id': 'combin-8f846', 'length': {'$gt': 100}})\n",
    "# twinewsRankings.getMeta('combin-7baab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTwinewsScores().findOne({'metric': 'ndcg', 'id': 'combin-d0fd0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankingsCache = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twinews.evaluation import metrics\n",
    "metricFunct = metrics.ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twinewsScores = getTwinewsScores()\n",
    "evalData = getEvalData(splitVersion, logger=logger, maxExtraNews=0)\n",
    "candidates = evalData['candidates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    # return m, m-h, m+h, h\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in \\\n",
    "[\n",
    "    # 'bm25-933f7',\n",
    "    # 'combin-8f846',\n",
    "    'combin-6fad8',\n",
    "    'combin-d0fd0'\n",
    "]:\n",
    "    log(\"Getting rankings of \" + model, logger)\n",
    "    if model in rankingsCache:\n",
    "        rankings = rankingsCache[model]\n",
    "    else:\n",
    "        rankings = twinewsRankings[model]\n",
    "        rankingsCache[model] = rankings\n",
    "    checkRankings(rankings, candidates, maxUsers=None)\n",
    "    # We convert all in a list of rel vectors:\n",
    "    rels = []\n",
    "    for userId in rankings:\n",
    "        for ranking in rankings[userId]:\n",
    "            if isinstance(ranking[0], tuple):\n",
    "                ranking = [e[0] for e in ranking]\n",
    "            rel = rankingToRelevanceVector(ranking, set(evalData['testUsers'][userId].keys()))\n",
    "            rels.append(rel)\n",
    "    # We compute all scores:\n",
    "    log(\"Computing scores of \" + model, logger)\n",
    "    scores = []\n",
    "    for rel in rels:\n",
    "        scores.append(metricFunct(rel))\n",
    "    bp(scores, logger)\n",
    "    log(\"Scores count: \" + str(len(scores)), logger)\n",
    "    # We mean all scrores:\n",
    "    score = float(np.mean(scores))\n",
    "    log(\"Mean score is \" + str(score), logger)\n",
    "    # Confidence interval\n",
    "    log(\"mean_confidence_interval of scores:\", logger)\n",
    "    log(\"\\t-->\" + str(mean_confidence_interval(scores)), logger)\n",
    "    # We split:\n",
    "    splits = split(scores, 30)\n",
    "    splits = splits[:-1]\n",
    "    log(\"Splits lengths:\", logger)\n",
    "    bp([len(e) for e in splits], 4, logger=logger)\n",
    "    means = []\n",
    "    for current in splits:\n",
    "        means.append(float(np.mean(current)))\n",
    "    log(\"Means:\", logger)\n",
    "    bp(means, 4, logger=logger)\n",
    "    log(\"mean_confidence_interval of means:\", logger)\n",
    "    log(\"\\t-->\" + str(mean_confidence_interval(means)), logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * 0.0034250413659661937\n",
    " * 0.003373019267614974\n",
    " * 0.0033745450496996477\n",
    " * 0.0033251230353648917"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
