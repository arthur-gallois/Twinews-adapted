{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNotebook = '__file__' not in locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.location import *\n",
    "from systemtools.printer import *\n",
    "from databasetools.mongo import *\n",
    "from newstools.goodarticle.utils import *\n",
    "from nlptools.preprocessing import *\n",
    "from nlptools.news import parser as newsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = True\n",
    "initialDatasetVersion = 1 if TEST else 3\n",
    "datasetVersion = \"1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRootPath = dataDir() + \"/Twinews/\" + \"twinews\" + str(initialDatasetVersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  /NoSave/Data/Twinews/twinews1/news/9news.com.bz2,\n",
      "  /NoSave/Data/Twinews/twinews1/news/10news.com.bz2,\n",
      "  ...,\n",
      "  /NoSave/Data/Twinews/twinews1/news/zdnet.com.bz2,\n",
      "  /NoSave/Data/Twinews/twinews1/news/zerohedge.com.bz2\n",
      "]\n",
      "dict_keys(['domain', 'lastUrlDomain', 'relevant', 'scrap', 'url', 'title', 'redirected', 'lastUrl'])\n",
      "dict_keys(['meta_data', 'publish_date', 'meta_description', 'meta_lang', 'title', 'authors', 'meta_favicon', 'tags', 'text'])\n"
     ]
    }
   ],
   "source": [
    "newsFiles = sortedGlob(dataRootPath + \"/news/*.bz2\")\n",
    "bp(newsFiles)\n",
    "bp(list(NDJson(random.choice(newsFiles)))[0].keys(), 5)\n",
    "bp(list(NDJson(random.choice(newsFiles)))[0]['scrap'].keys(), 5)\n",
    "if TEST:\n",
    "    newsFiles = newsFiles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ /NoSave/Data/Twinews/twinews1/users/part0.bz2, /NoSave/Data/Twinews/twinews1/users/part1.bz2 ]\n",
      "dict_keys(['tweet_count', 'location', 'bio', 'tweets', 'list_count', 'joindate_title', 'joindate_text', 'moment_count', 'notBotScore', 'verified', 'username', 'user_website', 'follower_count', 'following_count', 'favorite_count', 'user_id', 'datasetRelevanceScore', 'url', 'name', 'media_count', 'tweets_en_ratio', 'consecutive_old_tweets', 'avatar', 'news', 'user_twitter_website', 'date_limit'])\n"
     ]
    }
   ],
   "source": [
    "usersFiles = sortedGlob(dataRootPath + \"/users/*.bz2\")\n",
    "bp(usersFiles)\n",
    "bp(list(NDJson(random.choice(usersFiles)))[0].keys(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hjuser, hjpass, hjhost) = getTipiMongoAuth()\n",
    "(stuser, stpass, sthost) = getTipiStudentMongoAuth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongoCollectionKwargs = \\\n",
    "{\n",
    "    \"giveTimestamp\": False,\n",
    "    \"giveHostname\": False,\n",
    "    \"verbose\": True,\n",
    "    \"logger\": logger,\n",
    "    \"user\": hjuser,\n",
    "    \"password\": hjpass,\n",
    "    \"host\": hjhost,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twinews news (version 1.0) initialised.\n",
      "twinews users (version 1.0) initialised.\n"
     ]
    }
   ],
   "source": [
    "news = MongoCollection(\"twinews\", \"news\", version=datasetVersion,\n",
    "                        indexOn=[\"url\"],\n",
    "                       indexNotUniqueOn=[\"domain\", \"lastUrlDomain\", \"lastUrl\", \"isGoodArticle\"],\n",
    "                        **mongoCollectionKwargs)\n",
    "users = MongoCollection(\"twinews\", \"users\", version=datasetVersion, indexOn=[\"user_id\"],\n",
    "                        indexNotUniqueOn=[\"datasetRelevanceScore\", \"notBotScore\"],\n",
    "                        **mongoCollectionKwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.resetCollection(security=False)\n",
    "users.resetCollection(security=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(news) == 0\n",
    "assert len(users) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessNews(row, logger=None, verbose=True):\n",
    "    try:\n",
    "        if isinstance(row, str):\n",
    "            text = row\n",
    "        else:\n",
    "            if dictContains(row, \"scrap\"):\n",
    "                row = row['scrap']\n",
    "            if dictContains(row, \"text\"):\n",
    "                text = row['text']\n",
    "            else:\n",
    "                raise Exception(\"No text found in \" + b(row))\n",
    "        text = newsPreclean(text)\n",
    "        isGood = isGoodArticle(text)\n",
    "        rawText = text\n",
    "        (text, tokens) = newsParser.parseNews(rawText, logger=logger, verbose=verbose)\n",
    "        return (rawText, text, tokens, isGood)\n",
    "    except Exception as e:\n",
    "        logException(e, logger, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.svm.classes module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.svm. Anything that cannot be imported from sklearn.svm is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.21.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the GoogArticle model wich is a <class 'sklearn.svm._classes.LinearSVC'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% [==                  ] (45.899s left)\n",
      " 20% [====                ] (21.32s left)\n",
      " 30% [======              ] (13.16s left)\n",
      " 40% [========            ] (8.595s left)\n",
      " 50% [==========          ] (6.32s left)\n",
      " 60% [============        ] (4.813s left)\n",
      " 70% [==============      ] (6.351s left)\n",
      " 80% [================    ] (3.709s left)\n",
      " 90% [==================  ] (1.739s left)\n",
      "100% [====================] (total duration: 18.7s, mean duration: 1.869s)\n"
     ]
    }
   ],
   "source": [
    "for file in pb(shuffle(newsFiles), logger=logger):\n",
    "    for row in NDJson(file):\n",
    "        current = dictSelect(row, {'domain', 'lastUrlDomain', 'url', 'title', 'redirected', 'lastUrl'})\n",
    "        scrap = row['scrap']\n",
    "        current[\"title\"] = preprocess(current[\"title\"], doRemoveUrls=True, unescapeHtml=True,\n",
    "                              removeHtml=True, doQuoteNormalization=True,\n",
    "                              doReduceBlank=True, keepNewLines=False, logger=logger)\n",
    "        (rawText, text, tokens, isGood) = preprocessNews(scrap, logger=logger)\n",
    "        current[\"rawText\"] = rawText\n",
    "        current[\"text\"] = text\n",
    "        current[\"tokens\"] = tokens\n",
    "        current[\"isGoodArticle\"] = isGood\n",
    "        news.insert(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
