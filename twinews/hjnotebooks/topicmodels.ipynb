{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd misc-logs ; ./mv-old-logs.sh ; jupython --venv st-venv ~/notebooks/twinews/topicmodels.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/lets-build-an-article-recommender-using-lda-f22d71b7143e\n",
    "# https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNotebook = '__file__' not in locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = isNotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.location import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.printer import *\n",
    "from databasetools.mongo import *\n",
    "from newstools.goodarticle.utils import *\n",
    "from nlptools.preprocessing import *\n",
    "from nlptools.news import parser as newsParser\n",
    "from machinelearning.iterator import *\n",
    "from twinews.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlptools.topicmodeling import *\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
    "import gensim\n",
    "from math import log2\n",
    "from math import sqrt\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tictoc starts...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = Logger(tmpDir('logs') + \"/lda.log\") if isNotebook else Logger(\"lda.log\")\n",
    "tt = TicToc(logger=logger)\n",
    "tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \\\n",
    "{\n",
    "    'splitVersion': 2,\n",
    "    \n",
    "    'maxUsers': 20 if TEST else None, # Sub-sampling\n",
    "    'maxDocuments': 500 if TEST else 10000,\n",
    "    'useExtraNews': False if TEST else False, # None = unlimited, 0 = no extra news\n",
    "    'minDF': 1 / 500, # Remove words that have a document frequency ratio lower than 1 / 500\n",
    "    'maxDF': 300, # Remove top 300 voc elements\n",
    "    \n",
    "    'nbTopics': 30, # 30, 100\n",
    "    'lowercase': True,\n",
    "    'doLemmatization': False if TEST else True,\n",
    "    # <https://www.quora.com/How-do-you-combine-LDA-and-tf-idf>\n",
    "    # <https://www.quora.com/Why-is-the-performance-improved-by-using-TFIDF-instead-of-bag-of-words-in-LDA-clustering>\n",
    "    'useTFIDF': False,\n",
    "    \n",
    "    'maxIter': 20 if TEST else 30, # 30 for lda, 200 for nmf\n",
    "    \n",
    "    'nmfInit': 'nndsvd', # None, 'nndsvd'\n",
    "    'nmfL1Ratio': 0, # 0.0, 0.5, 1.0\n",
    "    'nmfAlpha': 0.1, # 0.0, 0.1\n",
    "    \n",
    "    'ldaLearningMethod': 'online',\n",
    "    'ldaLearningOffset': 1.0, # 1.0, 10.0\n",
    "    'ldaLearningDecay': 0.7, # 0.5, 0.7, 0.9, 1.0\n",
    "    \n",
    "    'model': 'gensim-lda', # gensim-lda, sklearn-lda, sklearn-nmf\n",
    "    'distance': 'euclidean', # 'cosine', 'euclidean', 'kl', 'js'\n",
    "    # The historyRef param is very important, it allow to choose, for a particular candidate,\n",
    "    # how many train history items will be used to calculate the similarity with\n",
    "    # the user history.\n",
    "    # Float are ratio on train history\n",
    "    # Integers are absolute number of train item in the history\n",
    "    # For example:\n",
    "    #  * 1.0 will allow to mean similarities of a candidate with all train history items\n",
    "    #  * 1 will allow to use only the most similar train item for the similarity of\n",
    "    #    the candidate with the history of the user\n",
    "    #  * 0.5 will allow to use the half of history for each candidates\n",
    "    #  * 3 to use 3 most similar items with the current candidate...\n",
    "    'historyRef': 1.0, # 1, 1.0, 0.5, 0.3, 3, 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'nmf' in config['model']:\n",
    "    modelName = \"nmf\"\n",
    "    newConfig = dict()\n",
    "    for key, value in config.items():\n",
    "        if not key.startswith('lda'):\n",
    "            newConfig[key] = value\n",
    "    config = newConfig\n",
    "    del config['useTFIDF']\n",
    "elif 'lda' in config['model']:\n",
    "    modelName = \"lda\"\n",
    "    newConfig = dict()\n",
    "    for key, value in config.items():\n",
    "        if not key.startswith('nmf'):\n",
    "            newConfig[key] = value\n",
    "    config = newConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tic: 3.92s | message: Eval data loaded\n",
      "twinews news (version 1.0) initialised.\n",
      "--> tic: 7.8s | message: Extra news downloaded\n",
      "--> toc total duration: 11.73s | message: Got Twinews evaluation data\n",
      "{ candidates, extraNews, meta, testNews, testUsers, trainNews, trainUsers }\n",
      "{ 'created': 2020.03.24-14.28.06, 'endDate': 2018-01-15, 'id': 2, 'ranksLength': 1000, 'splitDate': 2017-12-25, 'startDate': 2017-10-01, 'testMaxNewsPerUser': 97, 'testMeanNewsPerUser': 7.22, 'testMinNewsPerUser': 2, 'testNewsCount': 71781, 'totalNewsAvailable': 570210, 'trainMaxNewsPerUser': 379, 'trainMeanNewsPerUser': 26.48, 'trainMinNewsPerUser': 8, 'trainNewsCount': 237150, 'usersCount': 15905 }\n"
     ]
    }
   ],
   "source": [
    "# Getting users and news\n",
    "evalData = getEvalData(config['splitVersion'], maxExtraNews=config['maxDocuments'],\n",
    "                       maxUsers=config['maxUsers'], logger=logger)\n",
    "(trainUsers, testUsers, trainNews, testNews, candidates, extraNews) = \\\n",
    "(evalData['trainUsers'], evalData['testUsers'], evalData['trainNews'],\n",
    " evalData['testNews'], evalData['candidates'], evalData['extraNews'])\n",
    "bp(evalData.keys(), 5, logger)\n",
    "log(b(evalData['meta'], 5), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraNewsList = shuffle(list(extraNews), seed=0)\n",
    "trainNewsList = shuffle(list(trainNews), seed=0)\n",
    "testNewsList = shuffle(list(testNews), seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500 urls for urlsForModel:\n",
      "[\n",
      "  http://www.dailymail.co.uk/news/article-5108873/Joe-Barton-apologizes-leaked-nude-photo.html,\n",
      "  https://www.vanityfair.com/news/2017/12/trump-cant-believe-no-ones-thrown-a-parade-in-his-honor,\n",
      "  ...,\n",
      "  https://www.vox.com/policy-and-politics/2017/10/26/16554682/voxcare-childrens-health-insurance-progr,\n",
      "  https://www.nytimes.com/interactive/2017/12/08/us/puerto-rico-hurricane-maria-death-toll.html?ref=to\n",
      "]\n",
      "18009 urls for urlsToVectorize:\n",
      "[\n",
      "  http://www.dailymail.co.uk/news/article-5108873/Joe-Barton-apologizes-leaked-nude-photo.html,\n",
      "  https://www.vanityfair.com/news/2017/12/trump-cant-believe-no-ones-thrown-a-parade-in-his-honor,\n",
      "  ...,\n",
      "  http://detroit.cbslocal.com/2018/01/14/report-patriots-dc-matt-patricia-expected-to-be-named-lions-h,\n",
      "  https://www.huffingtonpost.com/entry/hartnett-white-confirm_us_5a39781fe4b06d1621b01f4b\n",
      "]\n",
      "18009 urls for urlsToInfere:\n",
      "[\n",
      "  http://www.dailymail.co.uk/news/article-5108873/Joe-Barton-apologizes-leaked-nude-photo.html,\n",
      "  https://www.vanityfair.com/news/2017/12/trump-cant-believe-no-ones-thrown-a-parade-in-his-honor,\n",
      "  ...,\n",
      "  http://detroit.cbslocal.com/2018/01/14/report-patriots-dc-matt-patricia-expected-to-be-named-lions-h,\n",
      "  https://www.huffingtonpost.com/entry/hartnett-white-confirm_us_5a39781fe4b06d1621b01f4b\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# We get urls for the LDA model:\n",
    "if config['useExtraNews']:\n",
    "    urlsForModel = extraNewsList + trainNewsList + testNewsList\n",
    "else:\n",
    "    urlsForModel = trainNewsList + testNewsList + extraNewsList\n",
    "urlsForModel = urlsForModel[:config['maxDocuments']]\n",
    "# We get urls to vectorize for the training and the inference:\n",
    "urlsToVectorize = copy.deepcopy(urlsForModel)\n",
    "for url in trainNewsList + testNewsList:\n",
    "    if url not in urlsToVectorize:\n",
    "        urlsToVectorize.append(url)\n",
    "# We get url to infere for the scoring:\n",
    "urlsToInfere = trainNewsList + testNewsList\n",
    "# Print all:\n",
    "log(str(len(urlsForModel)) + \" urls for urlsForModel:\\n\" + b(urlsForModel), logger=logger)\n",
    "log(str(len(urlsToVectorize)) + \" urls for urlsToVectorize:\\n\" + b(urlsToVectorize), logger=logger)\n",
    "log(str(len(urlsToInfere)) + \" urls for urlsToInfere:\\n\" + b(urlsToInfere), logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twinews news (version 1.0) initialised.\n",
      "  0% [                    ]\n",
      "  9% [=                   ] (48.807s left)\n",
      " 19% [===                 ] (42.066s left)\n",
      " 29% [=====               ] (36.215s left)\n",
      " 39% [=======             ] (30.535s left)\n",
      " 49% [=========           ] (25.515s left)\n",
      " 59% [===========         ] (20.532s left)\n",
      " 69% [=============       ] (15.273s left)\n",
      " 79% [===============     ] (10.155s left)\n",
      " 89% [=================   ] (5.091s left)\n",
      " 99% [=================== ] (0.025s left)\n",
      "100% [====================] (total duration: 50.37s, mean duration: 0.002s)\n",
      "[\n",
      "  [ [ Texas, Congressman, ..., it, . ], [ The, Republican, ..., wife, . ], ..., [ Barton, joined, ..., Texas, . ], [ He, is, ..., Committee, . ] ],\n",
      "  [ [ On, Wednesday, ..., time, . ], [ The, momentous, ..., pants, . ], ..., [ Hashed, Out, ..., W.S.J., ) ], [ Gary, Cohn, ..., Hive, ) ] ],\n",
      "  ...,\n",
      "  [ [ Report, :, ..., Texas, . ], [ (, Photo, ..., over, . ], ..., [ If, -, ..., Quinn, . ], [ Detroit, publicly, ..., Cooter, . ] ],\n",
      "  [ [ Democrats, are, ..., nomination, . ], [ With, Republican, ..., holidays, . ], ..., [ That, could, ..., Sens, . ], [ Lamar, Alexander, ..., issue, . ] ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# We get sentences:\n",
    "sentences = getNewsSentences(urlsToVectorize, logger=logger)\n",
    "bp(sentences, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ [ Texas, Congressman, ..., Committee, . ], [ On, Wednesday, ..., Hive, ) ], ..., [ Report, :, ..., Cooter, . ], [ Democrats, are, ..., issue, . ] ]\n"
     ]
    }
   ],
   "source": [
    "# We flatten sentences:\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = flattenLists(sentences[i])\n",
    "docs = sentences\n",
    "bp(docs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ [ texas, congressman, ..., committee, . ], [ on, wednesday, ..., hive, ) ], ..., [ report, :, ..., cooter, . ], [ democrats, are, ..., issue, . ] ]\n"
     ]
    }
   ],
   "source": [
    "# Lower case:\n",
    "if config['lowercase']:\n",
    "    for i in range(len(docs)):\n",
    "        for u in range(len(docs[i])):\n",
    "            docs[i][u] = docs[i][u].lower()\n",
    "bp(docs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lemmatization   0% [                    ]\n",
      "Lemmatization   9% [=                   ] (2m 3.728s left)\n",
      "Lemmatization  19% [===                 ] (1m 32.497s left)\n",
      "Lemmatization  29% [=====               ] (1m 16.097s left)\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization:\n",
    "if config['doLemmatization']:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    pbar = ProgressBar(len(docs), logger=logger, message=\"Lemmatization\")\n",
    "    for i in range(len(docs)):\n",
    "        for u in range(len(docs[i])):\n",
    "            docs[i][u] = lemmatizer.lemmatize(docs[i][u])\n",
    "        pbar.tic()\n",
    "bp(docs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the corpus:\n",
    "docs = filterCorpus(docs, minDF=config['minDF'], maxDF=config['maxDF'],\n",
    "                    removeEmptyDocs=False, allowEmptyDocs=False, logger=logger)\n",
    "for doc in docs: assert len(doc) > 0\n",
    "bp(docs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.tic(\"Data preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infering topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['model'] == 'gensim-lda':\n",
    "    dictionary = gensim.corpora.Dictionary(docs)\n",
    "    # dictionary.filter_extremes(no_below=config['min_df'])\n",
    "    bow = [dictionary.doc2bow(doc) for doc in docs]\n",
    "    if config['useTFIDF']:\n",
    "        tfidf = gensim.models.TfidfModel(bow)\n",
    "        bow = tfidf[bow]\n",
    "    assert len(bow) == len(urlsToVectorize)\n",
    "    bowForModel = bow[:len(urlsForModel)]\n",
    "    assert len(bowForModel) == config['maxDocuments']\n",
    "    i = 0\n",
    "    for url in urlsToVectorize:\n",
    "        if url == trainNewsList[0]:\n",
    "            break\n",
    "        i += 1\n",
    "    assert i == len(extraNews) or i == 0\n",
    "    bowForInference = bow[i:i + len(trainNews) + len(testNews)]\n",
    "    assert len(bowForInference) == len(trainNews) + len(testNews)\n",
    "    lda_model = gensim.models.LdaMulticore\\\n",
    "    (\n",
    "        bowForModel,\n",
    "        num_topics=config['nbTopics'],\n",
    "        id2word=dictionary,\n",
    "        iterations=config['maxIter'],\n",
    "        decay=config['ldaLearningDecay'],\n",
    "        offset=config['ldaLearningOffset'],\n",
    "        workers=cpuCount(),\n",
    "        passes=3,\n",
    "    )\n",
    "    inferedVectors = []\n",
    "    for current in bowForInference:\n",
    "        topicProbDistrib = lda_model[current]\n",
    "        currentVector = [0.0] * config['nbTopics']\n",
    "        for t, v in topicProbDistrib:\n",
    "            currentVector[t] = v\n",
    "        inferedVectors.append(np.array(currentVector))\n",
    "    assert len(inferedVectors) == len(trainNews) + len(testNews)\n",
    "    assert len(inferedVectors[0]) == config['nbTopics']\n",
    "    topics = []\n",
    "    for i in range(lda_model.num_topics):\n",
    "        current = dict()\n",
    "        for x in lda_model.get_topic_terms(i, topn=100):\n",
    "            current[dictionary[x[0]]] = x[1]\n",
    "        topics.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['model'] == 'sklearn-lda' or config['model'] == 'sklearn-nmf':\n",
    "    if config['model'] == 'sklearn-nmf' or config['useTFIDF']:\n",
    "        vectorizer = TfidfVectorizer\\\n",
    "        (\n",
    "            sublinear_tf=True,\n",
    "            tokenizer=lambda x: x,\n",
    "            preprocessor=lambda x: x,\n",
    "            # lowercase=True, # Doesn't work because we erased preprocessor\n",
    "        )\n",
    "    else:\n",
    "        vectorizer = CountVectorizer\\\n",
    "        (\n",
    "            tokenizer=lambda x: x,\n",
    "            preprocessor=lambda x: x,\n",
    "            # lowercase=True, # Doesn't work because we erased preprocessor\n",
    "        )\n",
    "    vectors = vectorizer.fit_transform(docs)\n",
    "    assert vectors.shape[0] == len(urlsToVectorize)\n",
    "    vectorsForModel = vectors[:len(urlsForModel)]\n",
    "    assert vectorsForModel.shape[0] == config['maxDocuments']\n",
    "    i = 0\n",
    "    for url in urlsToVectorize:\n",
    "        if url == trainNewsList[0]:\n",
    "            break\n",
    "        i += 1\n",
    "    assert i == len(extraNews) or i == 0\n",
    "    vectorsForInference = vectors[i:i + len(trainNews) + len(testNews)]\n",
    "    assert vectorsForInference.shape[0] == len(trainNews) + len(testNews)\n",
    "    if config['model'] == 'sklearn-lda':\n",
    "        model = LatentDirichletAllocation\\\n",
    "        (\n",
    "            n_components=config['nbTopics'],\n",
    "            learning_method=config['ldaLearningMethod'],\n",
    "            learning_offset=config['ldaLearningOffset'],\n",
    "            learning_decay=config['ldaLearningDecay'],\n",
    "            random_state=0,\n",
    "            n_jobs=cpuCount(),\n",
    "            max_iter=config['maxIter'],\n",
    "        )\n",
    "    else:\n",
    "        model = NMF\\\n",
    "        (\n",
    "            n_components=config['nbTopics'],\n",
    "            random_state=0,\n",
    "            alpha=config['nmfAlpha'],\n",
    "            l1_ratio=config['nmfL1Ratio'],\n",
    "            init=config['nmfInit'],\n",
    "            max_iter=config['maxIter'],\n",
    "        )\n",
    "    model.fit(vectorsForModel)\n",
    "    inferedVectors = model.transform(vectorsForInference)\n",
    "    assert inferedVectors.shape[0] == len(trainNews) + len(testNews)\n",
    "    assert inferedVectors[0].shape[0] == config['nbTopics']\n",
    "    topics = []\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        wordProb = []\n",
    "        for i in range(len(topic)):\n",
    "            prob = topic[i]\n",
    "            word = feature_names[i]\n",
    "            wordProb.append((word, prob))\n",
    "        wordProb = sortBy(wordProb, desc=True, index=1)[:100]\n",
    "        current = dict()\n",
    "        for word, prob in wordProb:\n",
    "            current[word] = prob\n",
    "        topics.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.tic(\"Model fitted and topic vectors infered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTopics(topics, maxWords=10, logger=None):\n",
    "    for i in range(len(topics)):\n",
    "        log(str(i) + \": \" + str(\" \".join(list(topics[i].keys())[:10])), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTopicsOf(vector, topics, logger=None):\n",
    "    topicsRepr = \"\"\n",
    "    topTopics = sortBy([(i, score) for i, score in enumerate(vector) if score > 0.1], desc=True, index=1)[:3]\n",
    "    log(\"Top topics number are: \" + str(\" \".join([str(e[0]) for e in topTopics])), logger)\n",
    "    currentTopics = [topics[e[0]] for e in topTopics]\n",
    "    printTopics(currentTopics, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isNotebook:\n",
    "    printTopics(topics, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isNotebook:\n",
    "    try:\n",
    "        dirPath = nosaveDir() + \"/sklearn-models\"\n",
    "        mkdir(dirPath)\n",
    "        configHash = objectToHash(config)[:5]\n",
    "        serialize(model, dirPath + \"/model-\" + configHash + \".pickle\")\n",
    "        toJsonFile(config, dirPath + \"/config-\" + configHash + \".json\")\n",
    "    except Exception as e:\n",
    "        logException(e, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a dict url --> topic vector and a dict url --> text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert len(urlsToInfere) == len(inferedVectors)\n",
    "urlsVectors = dict()\n",
    "for i in range(len(urlsToInfere)):\n",
    "    urlsVectors[urlsToInfere[i]] = inferedVectors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isNotebook:\n",
    "    urlsTexts = dict()\n",
    "    allTexts = getNewsText(urlsToInfere, logger=logger)\n",
    "    for i in range(len(urlsToInfere)):\n",
    "        urlsTexts[urlsToInfere[i]] = allTexts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isNotebook:\n",
    "    userId = list(trainUsers.keys())[11]\n",
    "    xvectors = []\n",
    "    xurls = []\n",
    "    for url in trainUsers[userId]:\n",
    "        xvectors.append(urlsVectors[url])\n",
    "        xurls.append(url)\n",
    "    xvectors = np.array(xvectors)\n",
    "    yvectors = []\n",
    "    yurls = []\n",
    "    for url in candidates[userId][0]:\n",
    "        yvectors.append(urlsVectors[url])\n",
    "        yurls.append(url)\n",
    "    yvectors = np.array(yvectors)\n",
    "    distances = getDistances(xvectors, yvectors, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing some docs with topics:\n",
    "if isNotebook:\n",
    "    for i in range(10):\n",
    "        urls = random.choice([xurls, yurls])\n",
    "        url = random.choice(urls)\n",
    "        text = urlsTexts[url]\n",
    "        vector = urlsVectors[url]\n",
    "        log(url, logger)\n",
    "        printTopicsOf(vector, topics, logger=logger)\n",
    "        log(text, logger)\n",
    "        log(\"\\n\" * 2, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Printing some similar docs:\n",
    "if isNotebook:\n",
    "    for i in range(distances.shape[0]):\n",
    "        if i > 100:\n",
    "            break\n",
    "        # Get train:\n",
    "        trainUrl = xurls[i]\n",
    "        trainText = urlsTexts[trainUrl]\n",
    "        trainVector = urlsVectors[trainUrl]\n",
    "        log(trainUrl, logger)\n",
    "        printTopicsOf(trainVector, topics, logger=logger)\n",
    "        log(trainText[:2000], logger)\n",
    "        log(\"\\n\", logger)\n",
    "        # Get distances:\n",
    "        currentDistances = []\n",
    "        for u in range(len(yurls)):\n",
    "            currentDistances.append((yurls[u], urlsTexts[yurls[u]], distances[i][u]))\n",
    "        topSim = sortBy(currentDistances, index=2, desc=False)[:3]\n",
    "        topDissim = sortBy(currentDistances, index=2, desc=True)[:3]\n",
    "        # Print similars:\n",
    "        log(\"MOST SIMILARS\", logger)\n",
    "        log(\"\\n\", logger)\n",
    "        for url, text, dist in topSim:\n",
    "            log(dist, logger)\n",
    "            log(url, logger)\n",
    "            printTopicsOf(urlsVectors[url], topics, logger=logger)\n",
    "            log(text[:2000], logger)\n",
    "            log(\"\\n\", logger)\n",
    "        # Print dissimilars:\n",
    "        log(\"MOST DISSIMILARS\", logger)\n",
    "        log(\"\\n\", logger)\n",
    "        for url, text, dist in topDissim:\n",
    "            log(dist, logger)\n",
    "            log(url, logger)\n",
    "            printTopicsOf(urlsVectors[url], topics, logger=logger)\n",
    "            log(text[:2000], logger)\n",
    "            log(\"\\n\", logger)\n",
    "        log(\"\\n\", logger)\n",
    "        log(\"\\n\" * 2 + '-' * 20 + \"\\n\" * 2, logger)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False and isNotebook:\n",
    "    config['historyRef'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyRef = config['historyRef']\n",
    "assert (isinstance(historyRef, int) and historyRef >= 1) or (isinstance(historyRef, float) and historyRef > 0.0 and historyRef <= 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = dict()\n",
    "for userId in trainUsers.keys():\n",
    "    if isinstance(historyRef, float):\n",
    "        currentHistoryRef = int(historyRef * len(xurls))\n",
    "    else:\n",
    "        currentHistoryRef = historyRef\n",
    "    xvectors = []\n",
    "    xurls = []\n",
    "    for url in trainUsers[userId]:\n",
    "        xvectors.append(urlsVectors[url])\n",
    "        xurls.append(url)\n",
    "    xvectors = np.array(xvectors)\n",
    "    ranks[userId] = []\n",
    "    for currentCandidates in candidates[userId]:\n",
    "        yvectors = []\n",
    "        yurls = []\n",
    "        for url in currentCandidates:\n",
    "            yvectors.append(urlsVectors[url])\n",
    "            yurls.append(url)\n",
    "        yvectors = np.array(yvectors)\n",
    "        distances = getDistances(xvectors, yvectors, metric=config['distance'], logger=logger)\n",
    "        urlDistances = dict()\n",
    "        for testIndex in range(len(yurls)):\n",
    "            url = yurls[testIndex]\n",
    "            currentDists = distances[:, testIndex]\n",
    "            assert currentDists.shape[0] == len(xurls)\n",
    "            currentDists = sorted(list(currentDists), reverse=False)\n",
    "            currentDists = currentDists[:currentHistoryRef]\n",
    "            currentDist = np.mean(currentDists)\n",
    "            urlDistances[url] = currentDist\n",
    "        rank = [e[0] for e in sortBy(urlDistances, index=1, desc=False)]\n",
    "        ranks[userId].append(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp(ranks, logger, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.tic(\"Ranks done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding ranks to the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addRankings(modelName, ranks, config, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notif(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.tic(\"Ranks stored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
