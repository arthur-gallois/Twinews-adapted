{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond accuracy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Diversity at 100 (div@100) : on prend seulement les 100 premiers elements du ranking et on calcul la diversité de ceux-ci en terme de topic, de TFIDF et de style. Donc la moyenne des pairwise distances $$diversity(R) = \\frac{\\sum_{i=1}^{|R|}\\sum_{j=i+1}^{|R|} dist(R_i, R_j)}{\\frac{{|R|}^2-{|R|}}{2}}$$\n",
    " On ne prend que les 100 premier car si on prennait les 1000, alors tous les modèles auraient la même diversité.\n",
    " * Novelty at 100 (nov@100) : pareil mais entre l'historique utilisateur et R.\n",
    " $$novelty(R, H) = \\frac{\\sum_{i=1}^{|R|}\\sum_{j=1}^{|H|} dist(R_i, H_j)}{|R|.|H|}$$\n",
    " * Strict novelty at 100 (snov@100) : pareil mais on prend le min.\n",
    " $$strictnovelty(R, H) = \\frac{\\sum_{i=1}^{|R|} mindist(R_i, H)}{|R|}$$\n",
    " * Serendipity at 100 (ser@100) : the ratio of relevants items the evaluated model recommanded and the primitive model didn't recommand. With $R$ the recommendation list of the evaluated model, $P$ the recommendation list of the primitive model, $T$ the set of relevant items, and for cases where $T \\setminus P \\neq \\emptyset$, we define the serendipity as:\n",
    " $$serendipity(R, P, T) = \\frac{|R \\cap (T \\setminus P)|}{|T \\setminus P|}$$\n",
    " Cases where $T \\setminus P = \\emptyset$ are not relevant because the primitive model already predicted all relevant items. Thus no model can be serendipe. These cases are not taken into account in the average for all user (+ TODO donner le % des cas $T \\setminus P = \\emptyset$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tipi 86\n",
    "# killbill bacceval ; cd ~/twinews-logs ; jupython -o nohup-bacceval-$HOSTNAME.out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "isNotebook = '__file__' not in locals()\n",
    "TEST = isNotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.location import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.printer import *\n",
    "from databasetools.mongo import *\n",
    "from datastructuretools.cache import *\n",
    "from newstools.goodarticle.utils import *\n",
    "from nlptools.preprocessing import *\n",
    "from nlptools.news import parser as newsParser\n",
    "from machinelearning.iterator import *\n",
    "from twinews.utils import *\n",
    "from twinews.evaluation import metrics\n",
    "from twinews.evaluation.utils import *\n",
    "from twinews.models.genericutils import *\n",
    "import time\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(tmpDir('logs') + \"/beyong-accuracyevaluation.log\") if isNotebook else Logger(\"evaluation-\" + getHostname() + \".log\")\n",
    "tt = TicToc(logger=logger)\n",
    "tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the cache that is a dict-like object (url --> vector) keeping data until 2Go of free RAM:\n",
    "genericCaches = dict()\n",
    "newsCollection = None\n",
    "def getter(key, logger=None, verbose=True):\n",
    "    global newsCollection\n",
    "    global genericCaches\n",
    "    global genericFields\n",
    "    if newsCollection is None:\n",
    "        newsCollection = getNewsCollection(logger=logger, verbose=verbose)\n",
    "    cacheKey, url = key\n",
    "    field = genericFields[cacheKey]\n",
    "    if cacheKey in genericCaches:\n",
    "        genericCache = genericCaches[cacheKey]\n",
    "    else:\n",
    "        genericCache = getGenericCache(cacheKey, readOnly=True, logger=logger, verbose=verbose)\n",
    "        genericCaches[cacheKey] = genericCache\n",
    "    row = newsCollection.findOne({'url': url}, projection={field: True})\n",
    "    theHash = objectToHash(row[field])\n",
    "    return genericCache[theHash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serializabledict twinews-tfidf initialised.\n"
     ]
    }
   ],
   "source": [
    "cache = Cache(getter, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"e\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[(1, 2)] =      1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
