{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commands and notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oomstopper --no-tail combinasons ; killbill combinasons ; cd ~/twinews-logs ; jupython -o nohup-combinasons-$HOSTNAME.out --venv st-venv ~/notebooks/twinews/hjnotebooks/combinasons.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO convertir \"doc2vec\" en \"doc2vec-hash\" --> en cherchant le meilleur ndcg\n",
    "# Pour le parametre qui determine les modèles utilisé pour le merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNotebook = '__file__' not in locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False # isNotebook, True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.location import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.printer import *\n",
    "from nlptools.preprocessing import *\n",
    "from nlptools.basics import *\n",
    "from twinews.utils import *\n",
    "from twinews.models.ranking import *\n",
    "from machinelearning.iterator import *\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twinews.models.genericutils import *\n",
    "from twinews.models.ranking import *\n",
    "from twinews.models.ranking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tictoc starts...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = Logger(tmpDir('logs') + \"/combinasons.log\") if isNotebook else Logger(\"combinasons-\" + getHostname() + \".log\")\n",
    "tt = TicToc(logger=logger)\n",
    "tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestModelKey(model, splitVersion, maxUsers=None, metric='ndcg'):\n",
    "    twinewsRankings = getTwinewsRankings(verbose=False)\n",
    "    twinewsScores = getTwinewsScores(verbose=False)\n",
    "    keys = twinewsRankings.keys()\n",
    "    rows = []\n",
    "    for key in keys:\n",
    "        meta = twinewsRankings.getMeta(key)\n",
    "        if meta['splitVersion'] == splitVersion \\\n",
    "        and meta['maxUsers'] == None \\\n",
    "        and meta['model'] == model:\n",
    "            scoreRow = twinewsScores.findOne({'id': meta['id'], 'metric': metric})\n",
    "            assert 'score' not in meta\n",
    "            meta['score'] = scoreRow['score']\n",
    "            rows.append(meta)\n",
    "    rows = [(e['id'], e['score']) for e in rows]\n",
    "    rows = sortBy(rows, index=1, desc=True)\n",
    "    best = rows[0][0]\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankingsCache = None\n",
    "def getRankings(model, userIds=None):\n",
    "    global rankingsCache\n",
    "    if rankingsCache is None:\n",
    "        rankingsCache = dict()\n",
    "    twinewsRankings = getTwinewsRankings(verbose=False)\n",
    "    if model in rankingsCache:\n",
    "        rankings = rankingsCache[model]\n",
    "    else:\n",
    "        rankings = twinewsRankings[model]\n",
    "        rankingsCache[model] = rankings\n",
    "    assert rankings is not None\n",
    "    if userIds is not None:\n",
    "        rankings = dictSelect(rankings, userIds)\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeTwinewsRankings(modelsRankings, config, *args, logger=None, verbose=True, **kwargs):\n",
    "    # We merge rankings for these users:\n",
    "    mergeRankingsKwargs = dictSelect(config, {'rankAsScore', 'weights', 'alphas', 'betas'})\n",
    "    combRankings = dict()\n",
    "    for userId in modelsRankings[0].keys():\n",
    "        for rkIndex in range(len(modelsRankings[0][userId])):\n",
    "            currentRankings = []\n",
    "            for modelIndex in range(len(modelsRankings)):\n",
    "                currentRankings.append(modelsRankings[modelIndex][userId][rkIndex])\n",
    "            merged = mergeRankings(currentRankings, **mergeRankingsKwargs, returnScores=False, logger=logger)\n",
    "            if userId not in combRankings:\n",
    "                combRankings[userId] = [None] * len(modelsRankings[0][userId])\n",
    "            combRankings[userId][rkIndex] = merged\n",
    "    return combRankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "userIdsCache = None\n",
    "def generateRankings(config, logger=None, verbose=True):\n",
    "    # We init user ids cache:\n",
    "    global userIdsCache\n",
    "    if userIdsCache is None:\n",
    "        userIdsCache = dict()\n",
    "    # We get models:\n",
    "    assert \"models\" in config\n",
    "    assert isinstance(config[\"models\"], list) or isinstance(config[\"models\"], set)\n",
    "    assert len(config[\"models\"]) >= 2\n",
    "    if isinstance(config[\"models\"], list) and models != sorted(models):\n",
    "        raise Exception(\"You need to give models by alphabetic order\")\n",
    "    models = sorted(list(config[\"models\"]))\n",
    "    # We set default params:\n",
    "    if not dictContains(config, 'rankAsScore'):\n",
    "        config['rankAsScore'] = [True] * len(models)\n",
    "        logWarning(\"You didn't set rankAsScore\", logger=logger, verbose=verbose)\n",
    "    if not dictContains(config, 'weights'):\n",
    "        config['weights'] = [1.0 / len(models)] * len(models)\n",
    "        logWarning(\"You didn't set weights\", logger=logger, verbose=verbose)\n",
    "    if not dictContains(config, 'alphas'):\n",
    "        config['alphas'] = [0.5] * len(models)\n",
    "        logWarning(\"You didn't set alphas\", logger=logger, verbose=verbose)\n",
    "    if not dictContains(config, 'betas'):\n",
    "        config['betas'] = [NormalizedLawBeta.LOG] * len(models)\n",
    "        logWarning(\"You didn't set betas\", logger=logger, verbose=verbose)\n",
    "    # We get user ids:\n",
    "    userIds = None\n",
    "    if config[\"maxUsers\"] is not None:\n",
    "        if config[\"maxUsers\"] in userIdsCache:\n",
    "            userIds = userIdsCache[config[\"maxUsers\"]]\n",
    "        else:\n",
    "            evalData = getEvalData(config['splitVersion'], maxExtraNews=0, maxUsers=config['maxUsers'],\n",
    "                                   logger=logger, verbose=verbose)\n",
    "            userIds = set(evalData['candidates'].keys())\n",
    "            log(\"Users: \" + b(userIds), logger)\n",
    "            userIdsCache[config[\"maxUsers\"]] = userIds\n",
    "    # Initi tt:\n",
    "    tt = TicToc(logger=logger)\n",
    "    tt.tic(\"Starting \" + b(models))\n",
    "    # We get best models:\n",
    "    models = sorted([getBestModelKey(model, config['splitVersion']) for model in models])\n",
    "    config['models'] = models\n",
    "    tt.tic(\"Got best models\")\n",
    "    # We check if rankings exists:\n",
    "    if rankingExists(modelName, config):\n",
    "        return (None, None)\n",
    "    # We get rankings:\n",
    "    modelsRankings = []\n",
    "    for model in models:\n",
    "        currentRks = getRankings(model, userIds=userIds)\n",
    "        element = currentRks[list(currentRks.keys())[0]][0][0]\n",
    "        if isinstance(element, str):\n",
    "            logWarning(\"No scores with items in rankings of \" + model, logger, verbose=verbose)\n",
    "            return (None, None)\n",
    "        modelsRankings.append(currentRks)\n",
    "    tt.tic(\"Got all rankings\")\n",
    "    # We chunk rankings:\n",
    "    userIdsChunks = split(sorted(list(modelsRankings[0].keys())), cpuCount())\n",
    "    modelsRankingsChunks = []\n",
    "    for userIdsChunk in userIdsChunks:\n",
    "        current = []\n",
    "        for currentRankings in modelsRankings:\n",
    "            current.append(dictSelect(currentRankings, userIdsChunk))\n",
    "        modelsRankingsChunks.append(current)\n",
    "    modelsRankingsChunks = chunks(modelsRankingsChunks, 1)\n",
    "    tt.tic(\"Rankings chunked\")\n",
    "    # We define the gen funct:\n",
    "    def genFunct(containers, *args, **kwargs):\n",
    "        for modelsRankings in containers:\n",
    "            # with warnings.catch_warnings(): # Doesn't work\n",
    "            #     if filterWarnings:\n",
    "            #         warnings.filterwarnings('ignore', r'encountered in double')\n",
    "            yield mergeTwinewsRankings(modelsRankings, *args, **kwargs)\n",
    "    # We define the mli:\n",
    "    mli = MLIterator(modelsRankingsChunks, genFunct=genFunct, genArgs=(config,),\n",
    "                     parallelProcesses=cpuCount(), maxParallelProcesses=cpuCount(),\n",
    "                     logger=logger, verbose=False)\n",
    "    # We get all merges:\n",
    "    allCombRankings = []\n",
    "    for current in mli:\n",
    "        allCombRankings.append(current)\n",
    "    tt.tic(\"Got all merges from sub-processes\")\n",
    "    # We merge all:\n",
    "    combRankings = mergeDicts(allCombRankings)\n",
    "    tt.toc(b(models) + \" DONE.\")\n",
    "    # And we return it:\n",
    "    return (config, combRankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \\\n",
    "{\n",
    "    'splitVersion': 2,\n",
    "    'maxUsers': 2 if TEST else None, # Sub-sampling\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'combin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsDomain = {'nmf', 'tfidf', 'dbert-ft', 'dbert-base', \n",
    "                'stylo', 'infersent', 'sent2vec', 'word2vec',\n",
    "                'doc2vec', 'bm25', 'bert', 'usent', 'lda'}\n",
    "rankAsScoreDomain = {True, False}\n",
    "alphasDomain = {0.1, 0.25, 0.5, 0.75, 0.9}\n",
    "betasDomain = {NormalizedLawBeta.LOG, NormalizedLawBeta.EXP}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineModels(modelsDomain, amount):\n",
    "    modelsComb = [set(e) for e in combine(modelsDomain, amount) if len(e) == len(set(e))]\n",
    "    result = []\n",
    "    for e in modelsComb:\n",
    "        if e not in result:\n",
    "            result.append(e)\n",
    "    result = sorted(result, key=lambda x: str(sorted(list(x))))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsComb = combineModels(modelsDomain, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelsComb = [e for e in modelsComb if 'tfidf' in e]\n",
    "# modelsComb = [e for e in modelsComb if \"word2vec\" in str(e)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    modelsComb = modelsComb[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ { bert, tfidf }, { bm25, tfidf }, { dbert-base, tfidf }, { dbert-ft, tfidf }, { doc2vec, tfidf }, { infersent, tfidf }, { lda, tfidf }, { nmf, tfidf }, { sent2vec, tfidf }, { stylo, tfidf }, { tfidf, usent }, { tfidf, word2vec } ]\n"
     ]
    }
   ],
   "source": [
    "bp(modelsComb, 5, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankAsScore = [False, False] # [False, False], [True, True]\n",
    "weights = [0.5, 0.5]\n",
    "alphas = [0.5, 0.5]\n",
    "betas = [NormalizedLawBeta.LOG, NormalizedLawBeta.LOG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tictoc starts... | message: Starting [ bert, tfidf ]\n",
      "--> tic: 0.78s | message: Got best models\n",
      "--> tic: 49.8s | message: Got all rankings\n",
      "--> tic: 0.04s | message: Rankings chunked\n",
      "--> tic: 37.46s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 28.129s | message: [ bert-a7c9a, tfidf-4a1dc ] DONE.\n",
      "101.7g of RAM remaining.\n",
      "  8% [=                   ] (24m 1.44s left)\n",
      "--> tictoc starts... | message: Starting [ bm25, tfidf ]\n",
      "--> tic: 0.75s | message: Got best models\n",
      "--> tic: 33.13s | message: Got all rankings\n",
      "--> tic: 0.04s | message: Rankings chunked\n",
      "--> tic: 42s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 15.959s | message: [ bm25-933f7, tfidf-4a1dc ] DONE.\n",
      "95.64g of RAM remaining.\n",
      " 16% [===                 ] (27m 29.05s left)\n",
      "--> tictoc starts... | message: Starting [ dbert-base, tfidf ]\n",
      "--> tic: 0.79s | message: Got best models\n",
      "--> tic: 30.09s | message: Got all rankings\n",
      "--> tic: 0.05s | message: Rankings chunked\n",
      "--> tic: 43.15s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 14.14s | message: [ dbert-base-d092a, tfidf-4a1dc ] DONE.\n",
      "93.53g of RAM remaining.\n",
      " 25% [=====               ] (22m 13.86s left)\n",
      "--> tictoc starts... | message: Starting [ dbert-ft, tfidf ]\n",
      "--> tic: 8.05s | message: Got best models\n",
      "--> tic: 31.31s | message: Got all rankings\n",
      "--> tic: 0.04s | message: Rankings chunked\n",
      "--> tic: 48.45s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 27.92s | message: [ dbert-ft-7847a, tfidf-4a1dc ] DONE.\n",
      "90.93g of RAM remaining.\n",
      " 33% [======              ] (19m 12.119s left)\n",
      "--> tictoc starts... | message: Starting [ doc2vec, tfidf ]\n",
      "--> tic: 0.84s | message: Got best models\n",
      "--> tic: 50.05s | message: Got all rankings\n",
      "--> tic: 0.04s | message: Rankings chunked\n",
      "--> tic: 45.04s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 36.03s | message: [ doc2vec-e013a, tfidf-4a1dc ] DONE.\n",
      "88.17g of RAM remaining.\n",
      " 41% [========            ] (16m 49.287s left)\n",
      "--> tictoc starts... | message: Starting [ infersent, tfidf ]\n",
      "--> tic: 0.62s | message: Got best models\n",
      "--> tic: 55.82s | message: Got all rankings\n",
      "--> tic: 0.05s | message: Rankings chunked\n",
      "--> tic: 32.2s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 28.78s | message: [ infersent-77ec7, tfidf-4a1dc ] DONE.\n",
      "85.63g of RAM remaining.\n",
      " 50% [==========          ] (14m 21.279s left)\n",
      "--> tictoc starts... | message: Starting [ lda, tfidf ]\n",
      "--> tic: 0.66s | message: Got best models\n",
      "--> tic: 37.2s | message: Got all rankings\n",
      "--> tic: 0.05s | message: Rankings chunked\n",
      "--> tic: 1m 18.569s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 56.56s | message: [ lda-82272, tfidf-4a1dc ] DONE.\n",
      "83.15g of RAM remaining.\n",
      " 58% [===========         ] (12m 13.321s left)\n",
      "--> tictoc starts... | message: Starting [ nmf, tfidf ]\n",
      "--> tic: 0.66s | message: Got best models\n",
      "--> tic: 31.3s | message: Got all rankings\n",
      "--> tic: 0.04s | message: Rankings chunked\n",
      "--> tic: 55.68s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 27.78s | message: [ nmf-6078e, tfidf-4a1dc ] DONE.\n",
      "80.89g of RAM remaining.\n",
      " 66% [=============       ] (9m 43.049s left)\n",
      "--> tictoc starts... | message: Starting [ sent2vec, tfidf ]\n",
      "--> tic: 0.68s | message: Got best models\n",
      "--> tic: 52.6s | message: Got all rankings\n",
      "--> tic: 0.05s | message: Rankings chunked\n",
      "--> tic: 35.61s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 29s | message: [ sent2vec-32f92, tfidf-4a1dc ] DONE.\n",
      "78.45g of RAM remaining.\n",
      " 75% [===============     ] (7m 19.576s left)\n",
      "--> tictoc starts... | message: Starting [ stylo, tfidf ]\n",
      "--> tic: 0.67s | message: Got best models\n",
      "--> tic: 36.48s | message: Got all rankings\n",
      "--> tic: 0.05s | message: Rankings chunked\n",
      "--> tic: 1m 15.849s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 53.129s | message: [ stylo-5c321, tfidf-4a1dc ] DONE.\n",
      "75.89g of RAM remaining.\n",
      " 83% [================    ] (4m 57.539s left)\n",
      "--> tictoc starts... | message: Starting [ tfidf, usent ]\n",
      "--> tic: 0.75s | message: Got best models\n",
      "--> tic: 55.46s | message: Got all rankings\n",
      "--> tic: 0.13s | message: Rankings chunked\n",
      "--> tic: 42.35s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 38.769s | message: [ tfidf-4a1dc, usent-64ec0 ] DONE.\n",
      "73.39g of RAM remaining.\n",
      " 91% [==================  ] (2m 29.722s left)\n",
      "--> tictoc starts... | message: Starting [ tfidf, word2vec ]\n",
      "--> tic: 0.71s | message: Got best models\n",
      "--> tic: 42.87s | message: Got all rankings\n",
      "--> tic: 0.07s | message: Rankings chunked\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "/hosthome/Workspace/Python/Utils/SystemTools/systemtools/basics.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [(i - theMin) / (theMax - theMin) for i in theList]\n",
      "--> tic: 1m 23.22s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 2m 6.959s | message: [ tfidf-4a1dc, word2vec-f3c38 ] DONE.\n",
      "70.89g of RAM remaining.\n",
      "100% [====================] (total duration: 30m 32.119s, mean duration: 2m 32.676s)\n"
     ]
    }
   ],
   "source": [
    "for models in pb(modelsComb, logger=logger, printRatio=0.01):\n",
    "    currentConfig = mergeDicts\\\n",
    "    (\n",
    "        config,\n",
    "        {\n",
    "            'models': models,\n",
    "            'rankAsScore': rankAsScore,\n",
    "            'weights': weights,\n",
    "            'alphas': alphas,\n",
    "            'betas': betas,\n",
    "        }\n",
    "    )\n",
    "    try:\n",
    "        (currentConfig, rankings) = generateRankings(currentConfig, logger=logger)\n",
    "    except Exception as e:\n",
    "        (currentConfig, rankings) = (None, None)\n",
    "        logException(e, logger)\n",
    "    if currentConfig is not None:\n",
    "        addRanking(modelName, rankings, currentConfig, logger=logger)\n",
    "        warnFreeRAM(logger=logger)\n",
    "        if freeRAM() < 4:\n",
    "            rankingsCache = None\n",
    "            log(\"Breaking the loop\", logger)\n",
    "            break\n",
    "        rankings = None\n",
    "    else:\n",
    "        log(b(models) + \" already added\", logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getBestModelKey('bert', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
