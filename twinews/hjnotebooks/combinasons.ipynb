{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commands and notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oomstopper --no-tail combinasons ; killbill combinasons ; cd ~/twinews-logs ; jupython -o nohup-combinasons-$HOSTNAME.out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/models/combinasons.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO convertir \"doc2vec\" en \"doc2vec-hash\" --> en cherchant le meilleur ndcg\n",
    "# Pour le parametre qui determine les modèles utilisé pour le merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNotebook = '__file__' not in locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False # isNotebook, True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.location import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.printer import *\n",
    "from nlptools.preprocessing import *\n",
    "from nlptools.basics import *\n",
    "from twinews.utils import *\n",
    "from twinews.models.ranking import *\n",
    "from machinelearning.iterator import *\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twinews.models.genericutils import *\n",
    "from twinews.models.ranking import *\n",
    "from twinews.models.ranking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tictoc starts...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = Logger(tmpDir('logs') + \"/combinasons.log\") if isNotebook else Logger(\"combinasons-\" + getHostname() + \".log\")\n",
    "tt = TicToc(logger=logger)\n",
    "tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestModelKey(model, splitVersion, maxUsers=None, metric='ndcg'):\n",
    "    twinewsRankings = getTwinewsRankings(verbose=False)\n",
    "    twinewsScores = getTwinewsScores(verbose=False)\n",
    "    keys = twinewsRankings.keys()\n",
    "    rows = []\n",
    "    for key in keys:\n",
    "        meta = twinewsRankings.getMeta(key)\n",
    "        if meta['splitVersion'] == splitVersion \\\n",
    "        and meta['maxUsers'] == None \\\n",
    "        and meta['model'] == model:\n",
    "            scoreRow = twinewsScores.findOne({'id': meta['id'], 'metric': metric})\n",
    "            assert 'score' not in meta\n",
    "            meta['score'] = scoreRow['score']\n",
    "            rows.append(meta)\n",
    "    rows = [(e['id'], e['score']) for e in rows]\n",
    "    rows = sortBy(rows, index=1, desc=True)\n",
    "    best = rows[0][0]\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankingsCache = None\n",
    "def getRankings(model, userIds=None):\n",
    "    global rankingsCache\n",
    "    if rankingsCache is None:\n",
    "        rankingsCache = dict()\n",
    "    twinewsRankings = getTwinewsRankings(verbose=False)\n",
    "    if model in rankingsCache:\n",
    "        rankings = rankingsCache[model]\n",
    "    else:\n",
    "        rankings = twinewsRankings[model]\n",
    "        rankingsCache[model] = rankings\n",
    "    assert rankings is not None\n",
    "    if userIds is not None:\n",
    "        rankings = dictSelect(rankings, userIds)\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeTwinewsRankings(modelsRankings, config, *args, logger=None, verbose=True, **kwargs):\n",
    "    # We merge rankings for these users:\n",
    "    mergeRankingsKwargs = dictSelect(config, {'rankAsScore', 'weights', 'alphas', 'betas'})\n",
    "    combRankings = dict()\n",
    "    for userId in modelsRankings[0].keys():\n",
    "        for rkIndex in range(len(modelsRankings[0][userId])):\n",
    "            currentRankings = []\n",
    "            for modelIndex in range(len(modelsRankings)):\n",
    "                currentRankings.append(modelsRankings[modelIndex][userId][rkIndex])\n",
    "            merged = mergeRankings(currentRankings, **mergeRankingsKwargs, returnScores=False, logger=logger)\n",
    "            if userId not in combRankings:\n",
    "                combRankings[userId] = [None] * len(modelsRankings[0][userId])\n",
    "            combRankings[userId][rkIndex] = merged\n",
    "    return combRankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "userIdsCache = None\n",
    "def generateRankings(config, logger=None, verbose=True):\n",
    "    # We init user ids cache:\n",
    "    global userIdsCache\n",
    "    if userIdsCache is None:\n",
    "        userIdsCache = dict()\n",
    "    # We get models:\n",
    "    assert \"models\" in config\n",
    "    assert isinstance(config[\"models\"], list) or isinstance(config[\"models\"], set)\n",
    "    assert len(config[\"models\"]) >= 2\n",
    "    if isinstance(config[\"models\"], list) and models != sorted(models):\n",
    "        raise Exception(\"You need to give models by alphabetic order\")\n",
    "    models = sorted(list(config[\"models\"]))\n",
    "    # We set default params:\n",
    "    if not dictContains(config, 'rankAsScore'):\n",
    "        config['rankAsScore'] = [True] * len(models)\n",
    "        logWarning(\"You didn't set rankAsScore\", logger=logger, verbose=verbose)\n",
    "    if not dictContains(config, 'weights'):\n",
    "        config['weights'] = [1.0 / len(models)] * len(models)\n",
    "        logWarning(\"You didn't set weights\", logger=logger, verbose=verbose)\n",
    "    if not dictContains(config, 'alphas'):\n",
    "        config['alphas'] = [0.5] * len(models)\n",
    "        logWarning(\"You didn't set alphas\", logger=logger, verbose=verbose)\n",
    "    if not dictContains(config, 'betas'):\n",
    "        config['betas'] = [NormalizedLawBeta.LOG] * len(models)\n",
    "        logWarning(\"You didn't set betas\", logger=logger, verbose=verbose)\n",
    "    # We get user ids:\n",
    "    userIds = None\n",
    "    if config[\"maxUsers\"] is not None:\n",
    "        if config[\"maxUsers\"] in userIdsCache:\n",
    "            userIds = userIdsCache[config[\"maxUsers\"]]\n",
    "        else:\n",
    "            evalData = getEvalData(config['splitVersion'], maxExtraNews=0, maxUsers=config['maxUsers'],\n",
    "                                   logger=logger, verbose=verbose)\n",
    "            userIds = set(evalData['candidates'].keys())\n",
    "            log(\"Users: \" + b(userIds), logger)\n",
    "            userIdsCache[config[\"maxUsers\"]] = userIds\n",
    "    # We get best models:\n",
    "    models = sorted([getBestModelKey(model, config['splitVersion']) for model in models])\n",
    "    config['models'] = models\n",
    "    # We check if rankings exists:\n",
    "    if rankingExists(modelName, config):\n",
    "        return (None, None)\n",
    "    # Initi tt:\n",
    "    tt = TicToc(logger=logger)\n",
    "    tt.tic(\"Starting \" + b(models))\n",
    "    # We get rankings:\n",
    "    modelsRankings = []\n",
    "    for model in models:\n",
    "        currentRks = getRankings(model, userIds=userIds)\n",
    "        element = currentRks[list(currentRks.keys())[0]][0][0]\n",
    "        if isinstance(element, str):\n",
    "            logWarning(\"No scores with items in rankings of \" + model, logger, verbose=verbose)\n",
    "            return (None, None)\n",
    "        modelsRankings.append(currentRks)\n",
    "    tt.tic(\"Got all rankings\")\n",
    "    # We chunk rankings:\n",
    "    userIdsChunks = split(sorted(list(modelsRankings[0].keys())), cpuCount())\n",
    "    modelsRankingsChunks = []\n",
    "    for userIdsChunk in userIdsChunks:\n",
    "        current = []\n",
    "        for currentRankings in modelsRankings:\n",
    "            current.append(dictSelect(currentRankings, userIdsChunk))\n",
    "        modelsRankingsChunks.append(current)\n",
    "    modelsRankingsChunks = chunks(modelsRankingsChunks, 1)\n",
    "    tt.tic(\"Rankings chunked\")\n",
    "    # We define the gen funct:\n",
    "    def genFunct(containers, *args, **kwargs):\n",
    "        for modelsRankings in containers:\n",
    "            # with warnings.catch_warnings(): # Doesn't work\n",
    "            #     if filterWarnings:\n",
    "            #         warnings.filterwarnings('ignore', r'encountered in double')\n",
    "            yield mergeTwinewsRankings(modelsRankings, *args, **kwargs)\n",
    "    # We define the mli:\n",
    "    mli = MLIterator(modelsRankingsChunks, genFunct=genFunct, genArgs=(config,),\n",
    "                     parallelProcesses=cpuCount(), maxParallelProcesses=cpuCount(),\n",
    "                     logger=logger, verbose=False)\n",
    "    # We get all merges:\n",
    "    allCombRankings = []\n",
    "    for current in mli:\n",
    "        allCombRankings.append(current)\n",
    "    tt.tic(\"Got all merges from sub-processes\")\n",
    "    # We merge all:\n",
    "    combRankings = mergeDicts(allCombRankings)\n",
    "    tt.toc(b(models) + \" DONE.\")\n",
    "    # And we return it:\n",
    "    return (config, combRankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \\\n",
    "{\n",
    "    'splitVersion': 2,\n",
    "    'maxUsers': 2 if TEST else None, # Sub-sampling\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'combin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsDomain = {'lda', 'nmf', 'tfidf', 'bm25', 'dbert-ft', 'dbert-base', \n",
    "          'stylo', 'infersent', 'sent2vec', 'word2vec', 'doc2vec', 'usent', 'bert'}\n",
    "rankAsScoreDomain = {True, False}\n",
    "alphasDomain = {0.1, 0.25, 0.5, 0.75, 0.9}\n",
    "betasDomain = {NormalizedLawBeta.LOG, NormalizedLawBeta.EXP}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineModels(modelsDomain, amount):\n",
    "    modelsComb = [set(e) for e in combine(modelsDomain, amount) if len(e) == len(set(e))]\n",
    "    result = []\n",
    "    for e in modelsComb:\n",
    "        if e not in result:\n",
    "            result.append(e)\n",
    "    result = sorted(result, key=lambda x: str(sorted(list(x))))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsComb2 = combineModels(modelsDomain, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    modelsComb2 = modelsComb2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelsComb2 = [e for e in modelsComb2 if \"word2vec\" in str(e)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ { bert, bm25 }, { bert, dbert-base }, { bert, dbert-ft }, { bert, doc2vec }, { bert, infersent }, { bert, lda }, { bert, nmf }, { bert, sent2vec }, { bert, stylo }, { bert, tfidf }, { bert, usent }, { bert, word2vec }, { bm25, dbert-base }, { bm25, dbert-ft }, { bm25, doc2vec }, { bm25, infersent }, { bm25, lda }, { bm25, nmf }, { bm25, sent2vec }, { bm25, stylo }, { bm25, tfidf }, { bm25, usent }, { bm25, word2vec }, { dbert-base, dbert-ft }, { dbert-base, doc2vec }, { dbert-base, infersent }, { dbert-base, lda }, { dbert-base, nmf }, { dbert-base, sent2vec }, { dbert-base, stylo }, { dbert-base, tfidf }, { dbert-base, usent }, { dbert-base, word2vec }, { dbert-ft, doc2vec }, { dbert-ft, infersent }, { dbert-ft, lda }, { dbert-ft, nmf }, { dbert-ft, sent2vec }, { dbert-ft, stylo }, { dbert-ft, tfidf }, { dbert-ft, usent }, { dbert-ft, word2vec }, { doc2vec, infersent }, { doc2vec, lda }, { doc2vec, nmf }, { doc2vec, sent2vec }, { doc2vec, stylo }, { doc2vec, tfidf }, { doc2vec, usent }, { doc2vec, word2vec }, { infersent, lda }, { infersent, nmf }, { infersent, sent2vec }, { infersent, stylo }, { infersent, tfidf }, { infersent, usent }, { infersent, word2vec }, { lda, nmf }, { lda, sent2vec }, { lda, stylo }, { lda, tfidf }, { lda, usent }, { lda, word2vec }, { nmf, sent2vec }, { nmf, stylo }, { nmf, tfidf }, { nmf, usent }, { nmf, word2vec }, { sent2vec, stylo }, { sent2vec, tfidf }, { sent2vec, usent }, { sent2vec, word2vec }, { stylo, tfidf }, { stylo, usent }, { stylo, word2vec }, { tfidf, usent }, { tfidf, word2vec }, { usent, word2vec } ]\n"
     ]
    }
   ],
   "source": [
    "bp(modelsComb2, 5, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankAsScore = [False, False]\n",
    "weights = [0.5, 0.5]\n",
    "alphas = [0.5, 0.5]\n",
    "betas = [NormalizedLawBeta.LOG, NormalizedLawBeta.LOG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{ bert, bm25 } already added\n",
      "  1% [                    ]\n",
      "{ bert, dbert-base } already added\n",
      "  2% [                    ]\n",
      "{ bert, dbert-ft } already added\n",
      "  3% [                    ]\n",
      "{ bert, doc2vec } already added\n",
      "  5% [=                   ] (32.93s left)\n",
      "{ bert, infersent } already added\n",
      "  6% [=                   ] (34.31s left)\n",
      "--> tictoc starts... | message: Starting [ bert-65e2b, lda-d4f1d ]\n",
      "--> tic: 29.93s | message: Got all rankings\n",
      "--> tic: 0.05s | message: Rankings chunked\n",
      "--> tic: 18.39s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 48.41s | message: [ bert-65e2b, lda-d4f1d ] DONE.\n",
      "62.8g of RAM remaining.\n",
      "  7% [=                   ] (14m 6.959s left)\n",
      "--> tictoc starts... | message: Starting [ bert-65e2b, nmf-9cd4f ]\n",
      "--> tic: 20.74s | message: Got all rankings\n",
      "--> tic: 0.03s | message: Rankings chunked\n",
      "--> tic: 23.37s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 44.18s | message: [ bert-65e2b, nmf-9cd4f ] DONE.\n",
      "60.43g of RAM remaining.\n",
      "  8% [=                   ] (22m 53.849s left)\n",
      "{ bert, sent2vec } already added\n",
      " 10% [==                  ] (19m 59.099s left)\n",
      "{ bert, stylo } already added\n",
      " 11% [==                  ] (17m 34.78s left)\n",
      "{ bert, tfidf } already added\n",
      " 12% [==                  ] (15m 39.148s left)\n",
      "{ bert, usent } already added\n",
      " 14% [==                  ] (14m 4.199s left)\n",
      "{ bert, word2vec } already added\n",
      " 15% [===                 ] (12m 44.775s left)\n",
      "{ bm25, dbert-base } already added\n",
      " 16% [===                 ] (11m 37.849s left)\n",
      "{ bm25, dbert-ft } already added\n",
      " 17% [===                 ] (10m 40.274s left)\n",
      "{ bm25, doc2vec } already added\n",
      " 19% [===                 ] (9m 50.351s left)\n",
      "{ bm25, infersent } already added\n",
      " 20% [====                ] (9m 6.529s left)\n",
      "--> tictoc starts... | message: Starting [ bm25-1eb2a, lda-d4f1d ]\n",
      "--> tic: 23.01s | message: Got all rankings\n",
      "--> tic: 0.05s | message: Rankings chunked\n",
      "--> tic: 16.79s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 39.89s | message: [ bm25-1eb2a, lda-d4f1d ] DONE.\n",
      "56.9g of RAM remaining.\n",
      " 21% [====                ] (15m 50.344s left)\n",
      "--> tictoc starts... | message: Starting [ bm25-1eb2a, nmf-9cd4f ]\n",
      "--> tic: 0.09s | message: Got all rankings\n",
      "--> tic: 0.04s | message: Rankings chunked\n",
      "--> tic: 44.89s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 45.06s | message: [ bm25-1eb2a, nmf-9cd4f ] DONE.\n",
      "56.71g of RAM remaining.\n",
      " 23% [====                ] (29m 35.066s left)\n",
      "{ bm25, sent2vec } already added\n",
      " 24% [====                ] (27m 39.359s left)\n",
      "{ bm25, stylo } already added\n",
      " 25% [=====               ] (25m 51.268s left)\n",
      "{ bm25, tfidf } already added\n",
      " 26% [=====               ] (24m 13.825s left)\n",
      "{ bm25, usent } already added\n",
      " 28% [=====               ] (22m 45.127s left)\n",
      "{ bm25, word2vec } already added\n",
      " 29% [=====               ] (21m 23.939s left)\n",
      "{ dbert-base, dbert-ft } already added\n",
      " 30% [======              ] (20m 9.509s left)\n",
      "{ dbert-base, doc2vec } already added\n",
      " 32% [======              ] (19m 1.026s left)\n",
      "{ dbert-base, infersent } already added\n",
      " 33% [======              ] (17m 57.48s left)\n",
      "--> tictoc starts... | message: Starting [ dbert-base-aafd1, lda-d4f1d ]\n",
      "--> tic: 17.7s | message: Got all rankings\n",
      "--> tic: 0.02s | message: Rankings chunked\n",
      "--> tic: 24.99s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 42.77s | message: [ dbert-base-aafd1, lda-d4f1d ] DONE.\n",
      "55.55g of RAM remaining.\n",
      " 34% [======              ] (20m 7.509s left)\n",
      "--> tictoc starts... | message: Starting [ dbert-base-aafd1, nmf-9cd4f ]\n",
      "--> tic: 0.11s | message: Got all rankings\n",
      "--> tic: 0.04s | message: Rankings chunked\n",
      "--> tic: 46.15s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 46.34s | message: [ dbert-base-aafd1, nmf-9cd4f ] DONE.\n",
      "55.04g of RAM remaining.\n",
      " 35% [=======             ] (21m 47.5s left)\n",
      "{ dbert-base, sent2vec } already added\n",
      " 37% [=======             ] (20m 39.294s left)\n",
      "{ dbert-base, stylo } already added\n",
      " 38% [=======             ] (19m 34.431s left)\n",
      "{ dbert-base, tfidf } already added\n",
      " 39% [=======             ] (18m 33.869s left)\n",
      "{ dbert-base, usent } already added\n",
      " 41% [========            ] (17m 36.936s left)\n",
      "{ dbert-base, word2vec } already added\n",
      " 42% [========            ] (16m 43.595s left)\n",
      "{ dbert-ft, doc2vec } already added\n",
      " 43% [========            ] (15m 53.415s left)\n",
      "--> tictoc starts... | message: Starting [ dbert-ft-d1b5f, infersent-02118 ]\n",
      "--> tic: 30.79s | message: Got all rankings\n",
      "--> tic: 0.02s | message: Rankings chunked\n",
      "--> tic: 55.83s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 26.68s | message: [ dbert-ft-d1b5f, infersent-02118 ] DONE.\n",
      "52.08g of RAM remaining.\n",
      " 44% [========            ] (17m 23.155s left)\n",
      "--> tictoc starts... | message: Starting [ dbert-ft-d1b5f, lda-d4f1d ]\n",
      "--> tic: 0.09s | message: Got all rankings\n",
      "--> tic: 0.03s | message: Rankings chunked\n",
      "--> tic: 26.51s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 26.67s | message: [ dbert-ft-d1b5f, lda-d4f1d ] DONE.\n",
      "51.77g of RAM remaining.\n",
      " 46% [=========           ] (18m 31.413s left)\n",
      "--> tictoc starts... | message: Starting [ dbert-ft-d1b5f, nmf-9cd4f ]\n",
      "--> tic: 0.1s | message: Got all rankings\n",
      "--> tic: 0.04s | message: Rankings chunked\n",
      "--> tic: 24.74s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 24.92s | message: [ dbert-ft-d1b5f, nmf-9cd4f ] DONE.\n",
      "51.82g of RAM remaining.\n",
      " 47% [=========           ] (19m 43.005s left)\n",
      "--> tictoc starts... | message: Starting [ dbert-ft-d1b5f, sent2vec-7e0f9 ]\n",
      "--> tic: 18.9s | message: Got all rankings\n",
      "--> tic: 0.02s | message: Rankings chunked\n",
      "--> tic: 1m 3.2s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 22.18s | message: [ dbert-ft-d1b5f, sent2vec-7e0f9 ] DONE.\n",
      "50.87g of RAM remaining.\n",
      " 48% [=========           ] (21m 8.694s left)\n",
      "--> tictoc starts... | message: Starting [ dbert-ft-d1b5f, stylo-3a64b ]\n",
      "--> tic: 20.63s | message: Got all rankings\n",
      "--> tic: 0.03s | message: Rankings chunked\n",
      "--> tic: 39.71s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 0.429s | message: [ dbert-ft-d1b5f, stylo-3a64b ] DONE.\n",
      "51.82g of RAM remaining.\n",
      " 50% [==========          ] (22m 14.96s left)\n",
      "--> tictoc starts... | message: Starting [ dbert-ft-d1b5f, tfidf-6056f ]\n",
      "--> tic: 24.55s | message: Got all rankings\n",
      "--> tic: 0.04s | message: Rankings chunked\n",
      "--> tic: 1m 16.36s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 40.989s | message: [ dbert-ft-d1b5f, tfidf-6056f ] DONE.\n",
      "56.87g of RAM remaining.\n",
      " 51% [==========          ] (26m 34.822s left)\n",
      "--> tictoc starts... | message: Starting [ dbert-ft-d1b5f, usent-b1150 ]\n",
      "--> tic: 34.25s | message: Got all rankings\n",
      "--> tic: 0.03s | message: Rankings chunked\n",
      "--> tic: 49.08s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 23.459s | message: [ dbert-ft-d1b5f, usent-b1150 ] DONE.\n",
      "55.28g of RAM remaining.\n",
      " 52% [==========          ] (26m 57.414s left)\n",
      "{ dbert-ft, word2vec } already added\n",
      " 53% [==========          ] (25m 39.591s left)\n",
      "--> tictoc starts... | message: Starting [ doc2vec-19ca3, infersent-02118 ]\n",
      "--> tic: 24.56s | message: Got all rankings\n",
      "--> tic: 0.06s | message: Rankings chunked\n",
      "--> tic: 1m 32.61s | message: Got all merges from sub-processes\n",
      "--> toc total duration: 1m 57.29s | message: [ doc2vec-19ca3, infersent-02118 ] DONE.\n",
      "53.58g of RAM remaining.\n",
      " 55% [===========         ] (27m 1.623s left)\n",
      "--> tictoc starts... | message: Starting [ doc2vec-19ca3, lda-d4f1d ]\n",
      "--> tic: 0.08s | message: Got all rankings\n",
      "--> tic: 0.04s | message: Rankings chunked\n"
     ]
    }
   ],
   "source": [
    "for models in pb(modelsComb2, logger=logger, printRatio=0.01):\n",
    "    currentConfig = mergeDicts\\\n",
    "    (\n",
    "        config,\n",
    "        {\n",
    "            'models': models,\n",
    "            'rankAsScore': rankAsScore,\n",
    "            'weights': weights,\n",
    "            'alphas': alphas,\n",
    "            'betas': betas,\n",
    "        }\n",
    "    )\n",
    "    (currentConfig, rankings) = generateRankings(currentConfig, logger=logger)\n",
    "    if currentConfig is not None:\n",
    "        addRanking(modelName, rankings, currentConfig, logger=logger)\n",
    "        warnFreeRAM(logger=logger)\n",
    "        if freeRAM() < 4:\n",
    "            rankingsCache = None\n",
    "            log(\"Breaking the loop\", logger)\n",
    "            break\n",
    "    else:\n",
    "        log(b(models) + \" already added\", logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
