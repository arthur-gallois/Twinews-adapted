{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond accuracy evaluation (bacceval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    " * Diversity at 100 (div@100) : on prend seulement les 100 premiers elements du ranking et on calcul la diversité de ceux-ci en terme de topic, de TFIDF et de style. Donc la moyenne des pairwise distances $$diversity(R) = \\frac{\\sum_{i=1}^{|R|}\\sum_{j=i+1}^{|R|} dist(R_i, R_j)}{\\frac{{|R|}^2-{|R|}}{2}}$$\n",
    " With R a set of recommendation lists. On ne prend que les 100 premier car si on prennait les 1000, alors tous les modèles auraient la même diversité.\n",
    " On utilise les representation vectorielles de TFIDF, style et topic avec la cosine distance. Une quatrieme diversity se base sur la moyenne des distance de jaccard. Attention cette distance c'est pas [l'extension à n ensembles comme décrit sur wikipedia](https://fr.wikipedia.org/wiki/Indice_et_distance_de_Jaccard) (car l'intersection de bcp de document donnera simplement un ensemble vide ou composé de stop words...) mais la moyenne des pairwises distances comme dans cet [article](https://sci-hub.tw/https://ieeexplore.ieee.org/abstract/document/4812525) et [celui-ci](http://www.l3s.de/~siersdorfer/sources/2012/fp055-deng.pdf) (refined diversity jaccard) :\n",
    " $$JD(A, B) = 1 - \\frac{|A \\cap B|}{|A \\cup B|}$$ where A and B are sets of words from the item A and item B. TODO dire si on supprime les stopwords.\n",
    " * Novelty at 100 (nov@100) : pareil mais entre l'historique utilisateur et R.\n",
    " $$novelty(R, H) = \\frac{\\sum_{i=1}^{|R|}\\sum_{j=1}^{|H|} dist(R_i, H_j)}{|R|.|H|}$$\n",
    " * Strict novelty at 100 (snov@100) : pareil mais on prend le min.\n",
    " $$strictnovelty(R, H) = \\frac{\\sum_{i=1}^{|R|} mindist(R_i, H)}{|R|}$$\n",
    " * Serendipity at 100 (ser@100) : the ratio of relevants items the evaluated model recommanded and the primitive model didn't recommand. With $R$ the recommendation set of the evaluated model, $P$ the recommendation set of the primitive model, $T$ the set of relevant items, and for cases where $T \\setminus P \\neq \\emptyset$, we define the serendipity as:\n",
    " $$serendipity(R, P, T) = \\frac{|R \\cap (T \\setminus P)|}{|T \\setminus P|}$$\n",
    " Cases where $T \\setminus P = \\emptyset$ are not relevant because the primitive model already predicted all relevant items. Thus no model can be serendipe. These cases are not taken into account in the average for all user (+ TODO donner le % des cas $T \\setminus P = \\emptyset$).\n",
    " Les modèles primitif sont le modèle TFIDF avec historyRef=1 et lowercase et lemmatization. L'autre est le modèle qui prend le set des mots sans stop words pour l'historique, et cherche la meilleur similarité jaccard dans les candidats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    " * Ne pas faire de normalisation sauf à la fin quand on aura TOUTES les diversity, meme la diversité de random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pourquoi dbert-ft permet de maximiser diversité et accuracy ?\n",
    "\n",
    " * Il donne un espace vectoriel qui est plus loin, moins semantique, plus focalisé sur les sequence faiblemenet semantique \n",
    " * Le modèle est donc très complementaire puisqu'arrive à trouver des articles interessant pour l'utilistaur juste par le style mais qui diverge d'un point de vue topic...\n",
    " * on peut donner un bout d'explication en mentionnant le TFIDF focus (non spécificité) que j'ai mentionné au chapitre style\n",
    " * autre explication avec serendipity ?\n",
    " * Ou parce qu'il reconnait les sources ? TODO voir l'overlap de source interuser. Faire une baseline qui recommande la source majoritaire ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oomstopper --no-tail bacceval ; killbill bacceval ; cd ~/twinews-logs ; jupython -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other runs:\n",
    "# oomstopper --no-tail bacceval ; cd ~/twinews-logs ; jupython -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple runs:\n",
    "# oomstopper --no-tail bacceval ; killbill bacceval ; cd ~/twinews-logs ; jupython --no-tail -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb ; sleep 30 ; oomstopper --no-tail bacceval ; cd ~/twinews-logs ; jupython --no-tail -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb ; sleep 30 ; oomstopper --no-tail bacceval ; cd ~/twinews-logs ; jupython --no-tail -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb ; sleep 30 ; oomstopper --no-tail bacceval ; cd ~/twinews-logs ; jupython --no-tail -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb ; sleep 30 ; oomstopper --no-tail bacceval ; cd ~/twinews-logs ; jupython --no-tail -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb ; sleep 30 ; oomstopper --no-tail bacceval ; cd ~/twinews-logs ; jupython --no-tail -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "isNotebook = '__file__' not in locals()\n",
    "TEST = isNotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.location import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.printer import *\n",
    "from databasetools.mongo import *\n",
    "from datastructuretools.cache import *\n",
    "from newstools.goodarticle.utils import *\n",
    "from nlptools.preprocessing import *\n",
    "from nlptools.news import parser as newsParser\n",
    "from machinelearning.iterator import *\n",
    "from twinews.utils import *\n",
    "from twinews.evaluation import metrics\n",
    "from twinews.evaluation.utils import *\n",
    "from twinews.models.genericutils import *\n",
    "from twinews.models.ranking import *\n",
    "import time\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'the',\n",
       " ',',\n",
       " 'to',\n",
       " 'and',\n",
       " 'a',\n",
       " 'of',\n",
       " 'in',\n",
       " 'for',\n",
       " 'on',\n",
       " 'that',\n",
       " 'is',\n",
       " 'with',\n",
       " '-',\n",
       " 'it',\n",
       " 'at',\n",
       " 'as',\n",
       " 'from',\n",
       " '\"',\n",
       " 'be',\n",
       " 'by',\n",
       " 'this',\n",
       " 'have',\n",
       " 'an',\n",
       " 'are',\n",
       " 'but',\n",
       " 'has',\n",
       " 'was',\n",
       " 'not',\n",
       " '__int_2__',\n",
       " 'they',\n",
       " 'more',\n",
       " 'or',\n",
       " 'who',\n",
       " 'one',\n",
       " 'their',\n",
       " 'about',\n",
       " 'we',\n",
       " 'will',\n",
       " 'said',\n",
       " 'which',\n",
       " 'all',\n",
       " 'also',\n",
       " '__int_4__',\n",
       " 'up',\n",
       " 'when',\n",
       " 'been',\n",
       " 'out',\n",
       " 'can',\n",
       " ':',\n",
       " 'he',\n",
       " 'there',\n",
       " '(',\n",
       " 'do',\n",
       " 'than',\n",
       " 'what',\n",
       " 'new',\n",
       " 'if',\n",
       " 'other',\n",
       " 'so',\n",
       " 'time',\n",
       " 'would',\n",
       " 'were',\n",
       " 'i',\n",
       " 'you',\n",
       " 'after',\n",
       " 'people',\n",
       " 'had',\n",
       " 'some',\n",
       " ')',\n",
       " 'into',\n",
       " 'like',\n",
       " 'his',\n",
       " 'its',\n",
       " 'just',\n",
       " 'over',\n",
       " 'first',\n",
       " 'year',\n",
       " 'no',\n",
       " 'them',\n",
       " 'two',\n",
       " 'years',\n",
       " 'could',\n",
       " 'our',\n",
       " 'how',\n",
       " 'now',\n",
       " '__int_1__',\n",
       " 'most',\n",
       " 'only',\n",
       " 'those',\n",
       " 'because',\n",
       " 'many',\n",
       " \"'\",\n",
       " 'while',\n",
       " 'get',\n",
       " 'make',\n",
       " 'last',\n",
       " 'even',\n",
       " 'where',\n",
       " 'these',\n",
       " 'did',\n",
       " 'before',\n",
       " 'through',\n",
       " 'way',\n",
       " '__int_3__',\n",
       " '?',\n",
       " 'being',\n",
       " 'any',\n",
       " 'work',\n",
       " 'well',\n",
       " 'then',\n",
       " 'much',\n",
       " 'made',\n",
       " 'back',\n",
       " 'take',\n",
       " 'she',\n",
       " 'may',\n",
       " 'still',\n",
       " 'does',\n",
       " 'us',\n",
       " 'see',\n",
       " 'such',\n",
       " 'state',\n",
       " 'since',\n",
       " 'should',\n",
       " 'part',\n",
       " 'three',\n",
       " 'during',\n",
       " 'including',\n",
       " 'day',\n",
       " 'long',\n",
       " 'know',\n",
       " 'down',\n",
       " 'going',\n",
       " 'around',\n",
       " 'help',\n",
       " 'according',\n",
       " 'my',\n",
       " 'very',\n",
       " 'need',\n",
       " 'go',\n",
       " 'both',\n",
       " 'her',\n",
       " 'another',\n",
       " 'your',\n",
       " 'here',\n",
       " 'say',\n",
       " 'think',\n",
       " 'off',\n",
       " 'want',\n",
       " 'right',\n",
       " 'between',\n",
       " 'world',\n",
       " 'public',\n",
       " 'good',\n",
       " 'high',\n",
       " 'same',\n",
       " 'own',\n",
       " 'every',\n",
       " 'next',\n",
       " 'president',\n",
       " 'told',\n",
       " 'use',\n",
       " 'come',\n",
       " 'under',\n",
       " 'him',\n",
       " 'me',\n",
       " 'against',\n",
       " 'called',\n",
       " ';',\n",
       " 'too',\n",
       " 'week',\n",
       " 'says',\n",
       " 'life',\n",
       " 'really',\n",
       " 'end',\n",
       " 'without',\n",
       " 'few',\n",
       " 'each',\n",
       " 'home',\n",
       " 'found',\n",
       " 'something',\n",
       " 'used',\n",
       " 'based',\n",
       " 'lot',\n",
       " 'place',\n",
       " 'better',\n",
       " 'old',\n",
       " 'never',\n",
       " 'things',\n",
       " 'news',\n",
       " 'why',\n",
       " 'times',\n",
       " 'national',\n",
       " 'best',\n",
       " 'making',\n",
       " 'working',\n",
       " 'might',\n",
       " 'put',\n",
       " 'group',\n",
       " 'country',\n",
       " 'today',\n",
       " 'support',\n",
       " 'look',\n",
       " 'million',\n",
       " 'four',\n",
       " 'city',\n",
       " 'house',\n",
       " 'find',\n",
       " 'already',\n",
       " 'little',\n",
       " 'less',\n",
       " 'set',\n",
       " 'big',\n",
       " 'past',\n",
       " 'u.s.',\n",
       " 'across',\n",
       " 'different',\n",
       " 'states',\n",
       " 'government',\n",
       " 'school',\n",
       " 'number',\n",
       " 'whether',\n",
       " 'community',\n",
       " 'american',\n",
       " 'family',\n",
       " 'change',\n",
       " 'far',\n",
       " 'five',\n",
       " 'several',\n",
       " 'though',\n",
       " 'often',\n",
       " 'great',\n",
       " 'important',\n",
       " 'among',\n",
       " 'business',\n",
       " 'become',\n",
       " 'least',\n",
       " 'percent',\n",
       " 'point',\n",
       " 'away',\n",
       " 'came',\n",
       " 'others',\n",
       " 'later',\n",
       " 'former',\n",
       " 'got',\n",
       " 'second',\n",
       " 'left',\n",
       " 'able',\n",
       " 'days',\n",
       " 'director',\n",
       " 'show',\n",
       " 'office',\n",
       " 'company',\n",
       " 'yet',\n",
       " 'story',\n",
       " 'once',\n",
       " 'took',\n",
       " 'however',\n",
       " 'recent',\n",
       " 'keep',\n",
       " 'until',\n",
       " 'university',\n",
       " 'early',\n",
       " 'always',\n",
       " 'local',\n",
       " 'hard',\n",
       " 'give',\n",
       " 'month',\n",
       " 'top',\n",
       " 'months',\n",
       " 'money',\n",
       " 'case',\n",
       " 'doing',\n",
       " 'having',\n",
       " 'law',\n",
       " 'trump',\n",
       " 'system',\n",
       " 'future',\n",
       " 'enough',\n",
       " 'ago',\n",
       " 'center',\n",
       " 'members',\n",
       " 'start',\n",
       " 'open',\n",
       " 'asked',\n",
       " 'department',\n",
       " 'getting',\n",
       " 'real',\n",
       " 'full',\n",
       " 'ca',\n",
       " 'thing',\n",
       " 'report',\n",
       " 'health',\n",
       " 'likely',\n",
       " '__float_1__',\n",
       " 'using',\n",
       " 'ever',\n",
       " 'again',\n",
       " '...',\n",
       " 'known',\n",
       " 'small',\n",
       " 'information',\n",
       " 'makes',\n",
       " 'team',\n",
       " 'along',\n",
       " 'white',\n",
       " 'seen',\n",
       " 'looking',\n",
       " 'york',\n",
       " 'social',\n",
       " 'comes',\n",
       " 'must',\n",
       " 'process',\n",
       " 'done',\n",
       " 'fact',\n",
       " 'went',\n",
       " 'given',\n",
       " 'together',\n",
       " 'person',\n",
       " 'taking',\n",
       " 'trying',\n",
       " 'within',\n",
       " 'united',\n",
       " 'research',\n",
       " 'federal',\n",
       " 'program',\n",
       " 'instead',\n",
       " 'media',\n",
       " 'call',\n",
       " 'let',\n",
       " 'run',\n",
       " 'feel',\n",
       " 'children',\n",
       " 'nearly',\n",
       " 'free',\n",
       " 'job',\n",
       " 'move',\n",
       " 'started',\n",
       " 'area',\n",
       " 'major',\n",
       " 'almost',\n",
       " 'continue',\n",
       " 'added',\n",
       " 'power',\n",
       " 'kind',\n",
       " 'provide',\n",
       " 'plan',\n",
       " 'recently',\n",
       " 'man',\n",
       " 'means',\n",
       " 'care',\n",
       " 'sure',\n",
       " 'half',\n",
       " 'general',\n",
       " 'live',\n",
       " 'coming',\n",
       " '!',\n",
       " 'large',\n",
       " 'service',\n",
       " 'history',\n",
       " 'clear',\n",
       " 'six',\n",
       " 'believe',\n",
       " 'policy',\n",
       " 'young',\n",
       " 'post',\n",
       " 'possible',\n",
       " 'actually',\n",
       " 'pay',\n",
       " 'order',\n",
       " 'experience',\n",
       " 'washington',\n",
       " 'night',\n",
       " 'political',\n",
       " 'officials',\n",
       " 'behind',\n",
       " 'issue',\n",
       " 'close',\n",
       " 'saying',\n",
       " 'example',\n",
       " 'level',\n",
       " 'women',\n",
       " 'current',\n",
       " 'include',\n",
       " 'data',\n",
       " 'earlier',\n",
       " 'issues',\n",
       " 'problem',\n",
       " 'line',\n",
       " 'read',\n",
       " 'especially',\n",
       " 'needs',\n",
       " 'outside',\n",
       " 'led',\n",
       " 'someone',\n",
       " 'taken',\n",
       " 'services',\n",
       " 'statement',\n",
       " 'thought',\n",
       " 'face',\n",
       " 'companies',\n",
       " 'course',\n",
       " 'ways',\n",
       " 'idea',\n",
       " 'lead',\n",
       " 'wrote',\n",
       " 'everyone',\n",
       " 'building',\n",
       " 'rather',\n",
       " 'america',\n",
       " 'head',\n",
       " 'create',\n",
       " 'lives',\n",
       " 'chief',\n",
       " 'began',\n",
       " 'wanted',\n",
       " 'anything',\n",
       " 'reported',\n",
       " 'third',\n",
       " 'everything',\n",
       " 'human',\n",
       " 'following',\n",
       " 'act',\n",
       " 'late',\n",
       " 'bring',\n",
       " 'play',\n",
       " 'worked',\n",
       " 'north',\n",
       " 'bill',\n",
       " 'decision',\n",
       " 'access',\n",
       " 'needed',\n",
       " 'nothing',\n",
       " 'county',\n",
       " 'executive',\n",
       " 'staff',\n",
       " 'available',\n",
       " 'twitter',\n",
       " 'low',\n",
       " 'potential',\n",
       " 'john',\n",
       " 'control',\n",
       " 'question',\n",
       " 'name',\n",
       " 'matter',\n",
       " 'tell',\n",
       " 'similar',\n",
       " 'try',\n",
       " 'deal',\n",
       " 'role',\n",
       " 'plans',\n",
       " 'term',\n",
       " 'cost',\n",
       " 'side',\n",
       " 'industry',\n",
       " 'administration',\n",
       " 'despite',\n",
       " 'forward',\n",
       " 'themselves',\n",
       " 'market',\n",
       " 'announced',\n",
       " 'development',\n",
       " 'whose',\n",
       " 'project',\n",
       " 'hours',\n",
       " 'stop',\n",
       " 'action',\n",
       " 'follow',\n",
       " 'tuesday',\n",
       " 'weeks',\n",
       " 'special',\n",
       " 'share',\n",
       " 'love',\n",
       " 'near',\n",
       " 'held',\n",
       " 'south',\n",
       " 'further',\n",
       " 'court',\n",
       " 'talk',\n",
       " 'per',\n",
       " 'impact',\n",
       " 'key',\n",
       " 'campaign',\n",
       " 'understand',\n",
       " 'short',\n",
       " 'became',\n",
       " 'expected',\n",
       " 'police',\n",
       " 'focus',\n",
       " 'higher',\n",
       " 'am',\n",
       " 'shows',\n",
       " 'increase',\n",
       " 'effort',\n",
       " 'hope',\n",
       " 'takes',\n",
       " 'released',\n",
       " 'reason',\n",
       " 'result',\n",
       " 'opportunity',\n",
       " 'press',\n",
       " 'lost',\n",
       " 'either',\n",
       " 'single',\n",
       " 'living',\n",
       " 'received',\n",
       " 'anyone',\n",
       " 'men',\n",
       " 'turn',\n",
       " 'study',\n",
       " 'growing',\n",
       " 'morning',\n",
       " 'longer',\n",
       " 'students',\n",
       " 'board',\n",
       " 'monday',\n",
       " 'street',\n",
       " 'security',\n",
       " 'whole',\n",
       " 'room',\n",
       " 'saw',\n",
       " 'education',\n",
       " 'questions',\n",
       " 'strong',\n",
       " 'party',\n",
       " 'member',\n",
       " 'sense',\n",
       " 'although',\n",
       " 'black',\n",
       " 'donald',\n",
       " 'wednesday',\n",
       " 'spent',\n",
       " 'bad',\n",
       " 'technology',\n",
       " 'age',\n",
       " 'soon',\n",
       " 'created',\n",
       " 'friday',\n",
       " 'efforts',\n",
       " 'thursday',\n",
       " 'college',\n",
       " 'leaders',\n",
       " 'currently',\n",
       " 'groups',\n",
       " 'private',\n",
       " 'works',\n",
       " 'build',\n",
       " 'international',\n",
       " 'friends',\n",
       " 'probably',\n",
       " 'allow',\n",
       " 'meeting',\n",
       " 'personal',\n",
       " 'risk',\n",
       " 'difficult',\n",
       " 'due',\n",
       " 'involved',\n",
       " 'changes',\n",
       " 'true',\n",
       " 'senior',\n",
       " 'wo',\n",
       " 'rights',\n",
       " 'economic',\n",
       " 'running',\n",
       " 'simply',\n",
       " 'online',\n",
       " 'leave',\n",
       " 'hit',\n",
       " 'decades',\n",
       " 'hand',\n",
       " 'nation',\n",
       " 'interest',\n",
       " 'financial',\n",
       " 'list',\n",
       " 'helped',\n",
       " 'woman',\n",
       " 'record',\n",
       " 'toward',\n",
       " 'front',\n",
       " 'billion',\n",
       " 'mean',\n",
       " 'offer',\n",
       " 'beyond',\n",
       " 'response',\n",
       " 'sometimes',\n",
       " 'game',\n",
       " 'food',\n",
       " 'january',\n",
       " 'else',\n",
       " 'itself',\n",
       " 'consider',\n",
       " 'significant',\n",
       " 'step',\n",
       " 'facebook',\n",
       " 'areas',\n",
       " 'problems',\n",
       " 'stay',\n",
       " 'wants',\n",
       " 'legal',\n",
       " 'november',\n",
       " 'meet',\n",
       " 'families',\n",
       " 'gave',\n",
       " 'attention',\n",
       " 'published',\n",
       " 'class',\n",
       " 'americans',\n",
       " 'cut',\n",
       " 'address',\n",
       " 'certain',\n",
       " 'space',\n",
       " 'related',\n",
       " 'brought',\n",
       " 'photo',\n",
       " 'seven',\n",
       " 'seems',\n",
       " 'stories',\n",
       " 'included',\n",
       " 'ask',\n",
       " 'video',\n",
       " 'learn',\n",
       " 'middle',\n",
       " 'non',\n",
       " 'quickly',\n",
       " 'form',\n",
       " 'series',\n",
       " 'email',\n",
       " 'district',\n",
       " 'includes',\n",
       " 'common',\n",
       " 'agency',\n",
       " 'committee',\n",
       " 'republican',\n",
       " 'hold',\n",
       " 'event',\n",
       " 'force',\n",
       " 'self',\n",
       " 'death',\n",
       " 'particularly',\n",
       " 'co',\n",
       " 'view',\n",
       " 'goes',\n",
       " 'turned',\n",
       " 'organization',\n",
       " 'happen',\n",
       " 'west',\n",
       " 'california',\n",
       " 'reports',\n",
       " 'fall',\n",
       " 'final',\n",
       " 'evidence',\n",
       " 'jobs',\n",
       " 'sent',\n",
       " 'inside',\n",
       " 'sign',\n",
       " 'happened',\n",
       " 'leading',\n",
       " 'cases',\n",
       " 'thousands',\n",
       " 'words',\n",
       " 'december',\n",
       " 'ability',\n",
       " 'interview',\n",
       " 'latest',\n",
       " 'global',\n",
       " 'eight',\n",
       " 'himself',\n",
       " 'easy',\n",
       " 'tax',\n",
       " 'heard',\n",
       " 'majority',\n",
       " 'war',\n",
       " 'medical',\n",
       " 'biggest',\n",
       " 'leader',\n",
       " 'felt',\n",
       " 'total',\n",
       " 'moment',\n",
       " 'congress',\n",
       " 'water',\n",
       " 'entire',\n",
       " 'daily',\n",
       " 'career',\n",
       " 'throughout',\n",
       " 'amount',\n",
       " 'goal',\n",
       " 'perhaps',\n",
       " 'reach',\n",
       " 'resources',\n",
       " 'march',\n",
       " 'approach',\n",
       " 'position',\n",
       " 'return',\n",
       " 'child',\n",
       " 'paid',\n",
       " 'knew',\n",
       " 'mind',\n",
       " 'justice',\n",
       " 'continued',\n",
       " 'october',\n",
       " 'giving',\n",
       " 'average',\n",
       " 'terms',\n",
       " 'election',\n",
       " 'largest',\n",
       " 'bit',\n",
       " 'built',\n",
       " 'book',\n",
       " 'below',\n",
       " 'field',\n",
       " 'season',\n",
       " 'parents',\n",
       " 'lower',\n",
       " 'rate',\n",
       " 'success',\n",
       " 'multiple',\n",
       " 'decided',\n",
       " 'senate',\n",
       " 'moving',\n",
       " 'chance',\n",
       " 'alone',\n",
       " 'talking',\n",
       " 'kids',\n",
       " 'david',\n",
       " 'calls',\n",
       " 'programs',\n",
       " 'pretty',\n",
       " 'addition',\n",
       " 'costs',\n",
       " 'light',\n",
       " 'allowed',\n",
       " 'points',\n",
       " 'air',\n",
       " 'remain',\n",
       " 'comment',\n",
       " 'win',\n",
       " 'funding',\n",
       " 'growth',\n",
       " 'buy',\n",
       " 'additional',\n",
       " 'events',\n",
       " 'student',\n",
       " 'finally',\n",
       " 'met',\n",
       " 'rest',\n",
       " 'cause',\n",
       " 'starting',\n",
       " 'results',\n",
       " 'gets',\n",
       " 'tried',\n",
       " 'value',\n",
       " 'body',\n",
       " 'provided',\n",
       " 'period',\n",
       " 'wrong',\n",
       " 'road',\n",
       " 'thinking',\n",
       " 'previous',\n",
       " 'society',\n",
       " 'individual',\n",
       " 'official',\n",
       " 'above',\n",
       " 'workers',\n",
       " 'release',\n",
       " 'passed',\n",
       " 'professor',\n",
       " 'employees',\n",
       " 'huge',\n",
       " 'mark',\n",
       " 'site',\n",
       " 'safety',\n",
       " 'energy',\n",
       " 'couple',\n",
       " 'lack',\n",
       " 'communities',\n",
       " 'summer',\n",
       " 'worth',\n",
       " '__float_2__',\n",
       " 'maybe',\n",
       " 'drive',\n",
       " 'attorney',\n",
       " 'fight',\n",
       " 'remains',\n",
       " 'officer',\n",
       " 'science',\n",
       " 'protect',\n",
       " 'central',\n",
       " 'mother',\n",
       " 'annual',\n",
       " 'effect',\n",
       " 'management',\n",
       " 'schools',\n",
       " 'situation',\n",
       " 'heart',\n",
       " 'conference',\n",
       " 'hear',\n",
       " 'september',\n",
       " 'culture',\n",
       " 'vote',\n",
       " 'receive',\n",
       " 'specific',\n",
       " 'countries',\n",
       " 'seem',\n",
       " 'moved',\n",
       " 'stand',\n",
       " 'residents',\n",
       " 'serious',\n",
       " 'immediately',\n",
       " 'ones',\n",
       " 'focused',\n",
       " 'required',\n",
       " 'concerns',\n",
       " 'difference',\n",
       " 'association',\n",
       " 'considered',\n",
       " 'showed',\n",
       " 'network',\n",
       " 'quite',\n",
       " 'changed',\n",
       " 'quality',\n",
       " 'phone',\n",
       " 'michael',\n",
       " 'main',\n",
       " 'challenge',\n",
       " 'environment',\n",
       " 'described',\n",
       " 'raised',\n",
       " 'eventually',\n",
       " 'car',\n",
       " 'numbers',\n",
       " 'fire',\n",
       " 'reached',\n",
       " 'serve',\n",
       " 'critical',\n",
       " 'ahead',\n",
       " 'businesses',\n",
       " 'popular',\n",
       " 'particular',\n",
       " 'minutes',\n",
       " 'hundreds',\n",
       " 'east',\n",
       " 'hands',\n",
       " 'increased',\n",
       " 'ground',\n",
       " 'democratic',\n",
       " 'investigation',\n",
       " 'via',\n",
       " 'helping',\n",
       " 'benefits',\n",
       " 'previously',\n",
       " 'watch',\n",
       " 'creating',\n",
       " 'expect',\n",
       " 'check',\n",
       " 'june',\n",
       " 'article',\n",
       " 'safe',\n",
       " 'answer',\n",
       " 'adding',\n",
       " 'noted',\n",
       " 'review',\n",
       " 'named',\n",
       " 'decade',\n",
       " 'income',\n",
       " 'designed',\n",
       " 'website',\n",
       " 'won',\n",
       " 'died',\n",
       " 'played',\n",
       " 'places',\n",
       " 'improve',\n",
       " 'learned',\n",
       " 'beginning',\n",
       " 'account',\n",
       " 'rules',\n",
       " 'gone',\n",
       " 'ensure',\n",
       " 'figure',\n",
       " 'written',\n",
       " 'images',\n",
       " 'council',\n",
       " 'red',\n",
       " 'ready',\n",
       " 'asking',\n",
       " 'playing',\n",
       " 'spend',\n",
       " 'break',\n",
       " 'calling',\n",
       " 'message',\n",
       " 'training',\n",
       " 'economy',\n",
       " 'benefit',\n",
       " 'population',\n",
       " 'begin',\n",
       " 'capital',\n",
       " 'served',\n",
       " 'ceo',\n",
       " 'seeing',\n",
       " 'town',\n",
       " 'san',\n",
       " 'rise',\n",
       " 'pass',\n",
       " 'certainly',\n",
       " 'greater',\n",
       " 'deep',\n",
       " 'shared',\n",
       " 'continues',\n",
       " 'author',\n",
       " 'learning',\n",
       " 'land',\n",
       " 'natural',\n",
       " 'add',\n",
       " 'price',\n",
       " 'speak',\n",
       " 'leadership',\n",
       " 'looks',\n",
       " 'offered',\n",
       " 'park',\n",
       " 'levels',\n",
       " 'politics',\n",
       " 'dollars',\n",
       " 'directly',\n",
       " 'range',\n",
       " 'reality',\n",
       " 'budget',\n",
       " 'simple',\n",
       " 'firm',\n",
       " 'friend',\n",
       " 'powerful',\n",
       " 'source',\n",
       " 'visit',\n",
       " 'practice',\n",
       " 'spending',\n",
       " 'sunday',\n",
       " 'remember',\n",
       " 'overall',\n",
       " 'various',\n",
       " 'individuals',\n",
       " 'father',\n",
       " 'millions',\n",
       " 'present',\n",
       " 'exactly',\n",
       " 'details',\n",
       " 'cities',\n",
       " 'associated',\n",
       " 'limited',\n",
       " 'yes',\n",
       " '__netloc__',\n",
       " 'studies',\n",
       " 'relationship',\n",
       " 'star',\n",
       " 'successful',\n",
       " 'version',\n",
       " 'fund',\n",
       " 'systems',\n",
       " 'july',\n",
       " 'investment',\n",
       " 'digital',\n",
       " 'compared',\n",
       " 'race',\n",
       " 'secretary',\n",
       " 'shot',\n",
       " 'followed',\n",
       " 'wife',\n",
       " 'republicans',\n",
       " 'model',\n",
       " 'positive',\n",
       " 'projects',\n",
       " 'reasons',\n",
       " 'type',\n",
       " 'obama',\n",
       " 'sexual',\n",
       " 'complete',\n",
       " 'policies',\n",
       " 'grow',\n",
       " 'word',\n",
       " 'anti',\n",
       " 'vice',\n",
       " 'require',\n",
       " 'institute',\n",
       " 'hour',\n",
       " 'looked',\n",
       " 'son',\n",
       " 'foundation',\n",
       " 'saturday',\n",
       " 'century',\n",
       " 'parts',\n",
       " 'larger',\n",
       " 'reduce',\n",
       " 'conversation',\n",
       " 'happy',\n",
       " 'finding',\n",
       " 'leaving',\n",
       " 'writing',\n",
       " 'gives',\n",
       " 'military',\n",
       " 'experts',\n",
       " 'raise',\n",
       " 'opened']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining logger:\n",
    "logger = Logger(tmpDir('logs') + \"/bacceval.log\") if isNotebook else Logger(\"bacceval-\" + getHostname() + \"-\" + getDateSec() + \".log\")\n",
    "tt = TicToc(logger=logger)\n",
    "tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the cache that is a dict-like object (url --> vector) keeping data until 2Go of free RAM:\n",
    "genericCaches = dict()\n",
    "newsCollection = getNewsCollection(logger=logger)\n",
    "def getter(key, logger=None, verbose=True):\n",
    "    global newsCollection\n",
    "    global genericCaches\n",
    "    global genericFields\n",
    "    if newsCollection is None:\n",
    "        newsCollection = getNewsCollection(logger=logger, verbose=verbose)\n",
    "    cacheKey, url = key\n",
    "    field = genericFields[cacheKey]\n",
    "    if cacheKey in genericCaches:\n",
    "        genericCache = genericCaches[cacheKey]\n",
    "    else:\n",
    "        genericCache = getGenericCache(cacheKey, logger=logger, verbose=verbose)\n",
    "        genericCaches[cacheKey] = genericCache\n",
    "    row = newsCollection.findOne({'url': url}, projection={field: True})\n",
    "    theHash = objectToHash(row[field])\n",
    "    return genericCache[theHash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define primitive models and cache keys:\n",
    "pmodels = {1: \"tfidf-4b89a\", 2: \"tfidf-71fb5\"}\n",
    "cacheKeys = {\"tfidf\", \"dbert-ft\", \"nmf\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the cache instance (don't forget to purge it at the end):\n",
    "cache = Cache(getter, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get scores collection and the rankings GridFS:\n",
    "twinewsScores = getTwinewsScores(logger=logger)\n",
    "twinewsRankings = getTwinewsRankings(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cacheForceFeeding(model, maxItems=None, logger=None, verbose=True):\n",
    "    global cache\n",
    "    global newsCollection\n",
    "    i = 0\n",
    "    urls = list(newsCollection.distinct(\"url\"))\n",
    "    if maxItems is not None:\n",
    "        urls = urls[:maxItems]\n",
    "    for url in pb(urls, printRatio=0.01, message=\"Force-feeding the cache...\",\n",
    "                  logger=logger, verbose=verbose):\n",
    "        cache[(model, url)]\n",
    "        if i % 1000 == 0 and freeRAM() < 2:\n",
    "            logWarning(\"Stopping because no RAM left.\", logger)\n",
    "            break\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicDistPrint(url1, url2, dist, prob=1.0, logger=None, verbose=True):\n",
    "    if verbose:\n",
    "        if getRandomFloat() < prob and (dist >= 0.96 or dist < 0.84):\n",
    "                log(dist, logger)\n",
    "                # t1 = getNewsField(url1, 'detokText')\n",
    "                # t2 = getNewsField(url2, 'detokText')\n",
    "                t1Words = set(flattenLists(getNewsField(url1, 'sentences', verbose=False)))\n",
    "                t2Words = set(flattenLists(getNewsField(url2, 'sentences', verbose=False)))\n",
    "                inter = t1Words.intersection(t2Words)\n",
    "                log(\"-\" * 20, logger)\n",
    "                bp(t1Words, 4, logger)\n",
    "                log(\"-\" * 20, logger)\n",
    "                bp(t2Words, 4, logger)\n",
    "                log(\"-\" * 20, logger)\n",
    "                bp(inter, 5, logger)\n",
    "                log(len(inter), logger)\n",
    "                log(\"#\" * 20, logger)\n",
    "                log(\"#\" * 20, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfDiversityAt100(urls, logger=None, verbose=False):\n",
    "    return diversity(urls, 'tfidf', at=100, logger=logger, verbose=verbose)\n",
    "def styleDiversityAt100(urls, logger=None, verbose=False):\n",
    "    return diversity(urls, 'dbert-ft', at=100, logger=logger, verbose=verbose)\n",
    "def topicDiversityAt100(urls, logger=None, verbose=False):\n",
    "    return diversity(urls, 'nmf', at=100, logger=logger, verbose=verbose)\n",
    "def diversity(urls, model, at=100, distance=\"cosine\", logger=None, verbose=False):\n",
    "    global cache\n",
    "    assert isinstance(urls, list)\n",
    "    urls = urls[:at]\n",
    "    assert len(urls) == at\n",
    "    vectors = vstack([cache[(model, url)] for url in urls])\n",
    "    distances = getDistances(vectors, vectors, metric=distance, verbose=False)\n",
    "    pairwiseCount = 0\n",
    "    distSum = 0\n",
    "    for i in range(at):\n",
    "        for u in range(i+1, at):\n",
    "            dist = distances[i][u]\n",
    "            distSum += dist\n",
    "            pairwiseCount += 1\n",
    "            basicDistPrint(urls[i], urls[u], dist, verbose=TEST and verbose, logger=logger)\n",
    "    assert pairwiseCount == (at**2 - at) / 2 # \\frac{{|R|}^2-{|R|}}{2}\n",
    "    return distSum / pairwiseCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swJaccardRepr(url, *args, **kwargs):\n",
    "    return __jaccardRepr(url, 200, *args, **kwargs)\n",
    "def jaccardRepr(url, *args, **kwargs):\n",
    "    return __jaccardRepr(url, 0, *args, **kwargs)\n",
    "def __jaccardRepr\\\n",
    "(\n",
    "    url,\n",
    "    stopWordAmount,\n",
    "    lowercase=True,\n",
    "    logger=None, verbose=True,\n",
    "):\n",
    "    global newsCollection\n",
    "    global STOP_WORDS\n",
    "    assert '__int_1__' in STOP_WORDS\n",
    "    if stopWordAmount is None or stopWordAmount == 0:\n",
    "        sw = None\n",
    "    else:\n",
    "        sw = set(STOP_WORDS[:stopWordAmount])\n",
    "    sentences = getNewsField(url, 'sentences', verbose=False)\n",
    "    tokens = flattenLists(sentences)\n",
    "    if lowercase:\n",
    "        tokens = [e.lower() for e in tokens]\n",
    "    tokens = set(tokens)\n",
    "    if sw is not None and len(sw) > 0:\n",
    "        tokens = set([e for e in tokens if e not in sw])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccardDistance(url1, url2, cache):\n",
    "    words1 = cache[url1]\n",
    "    words2 = cache[url2]\n",
    "    return 1 - len(words1.intersection(words2)) / len((words1.union(words2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swJaccardDiversityAt100(urls, logger=None, verbose=False):\n",
    "    return jaccardDiversity(urls, True, at=100, logger=logger, verbose=verbose)\n",
    "def jaccardDiversityAt100(urls, logger=None, verbose=False):\n",
    "    return jaccardDiversity(urls, False, at=100, logger=logger, verbose=verbose)\n",
    "def jaccardDiversity(urls, useSW, at=100, logger=None, verbose=False):\n",
    "    global swJaccardCache\n",
    "    global jaccardCache\n",
    "    assert isinstance(urls, list)\n",
    "    urls = urls[:at]\n",
    "    assert len(urls) == at\n",
    "    pairwiseCount = 0\n",
    "    distSum = 0\n",
    "    for i in range(at):\n",
    "        for u in range(i+1, at):\n",
    "            dist = jaccardDistance(urls[i], urls[u], swJaccardCache if useSW else jaccardCache)\n",
    "            distSum += dist\n",
    "            pairwiseCount += 1\n",
    "            basicDistPrint(urls[i], urls[u], dist, verbose=TEST and verbose, logger=logger)\n",
    "    assert pairwiseCount == (at**2 - at) / 2 # \\frac{{|R|}^2-{|R|}}{2}\n",
    "    return distSum / pairwiseCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swJaccardCache = Cache(swJaccardRepr, logger=logger)\n",
    "jaccardCache = Cache(jaccardRepr, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We init an eval data cache:\n",
    "def evalDataGetter(splitVersion, logger=None, verbose=True):\n",
    "    log(\"Downloading eval data version \" + str(splitVersion) + \"...\", logger, verbose=verbose)\n",
    "    return getEvalData(splitVersion, logger=logger, verbose=verbose, maxExtraNews=0)\n",
    "evalDataCache = Cache(evalDataGetter, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc params:\n",
    "iterations = 1 if isNotebook else 10000000\n",
    "sleep = 0 if isNotebook else 30\n",
    "exceptionSleep = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Metrics for local:\n",
    "diversityMetrics = \\\n",
    "{\n",
    "    'div@100': tfidfDiversityAt100,\n",
    "    'style-div@100': styleDiversityAt100,\n",
    "    'topic-div@100': topicDiversityAt100,\n",
    "}\n",
    "jaccardDiversityMetrics = \\\n",
    "{\n",
    "    'jacc-div@100': jaccardDiversityAt100,\n",
    "    'swjacc-div@100': swJaccardDiversityAt100,\n",
    "}\n",
    "noveltyMetrics = {}\n",
    "strictNoveltyMetrics = {}\n",
    "serendipityMetrics = {}\n",
    "tipiNum = lambda: tipiNumber(toInteger=True)\n",
    "if TEST:\n",
    "    diversityMetrics = dictSelect(diversityMetrics, {})\n",
    "    # cacheForceFeeding('tfidf', maxItems=300, logger=logger)\n",
    "elif tipiNum() in {60, 61, 62, 63}:\n",
    "    logWarning(\"Caching only tfidf representations.\", logger)\n",
    "    diversityMetrics = dictSelect(diversityMetrics, {'div@100'})\n",
    "    # cacheForceFeeding('tfidf', logger=logger)\n",
    "elif tipiNum() in {90, 92, 93, 95}:\n",
    "    pass\n",
    "    # logWarning(\"Caching only dbert-ft representations.\", logger)\n",
    "    # diversityMetrics = dictSelect(diversityMetrics, {'style-div@100'})\n",
    "    # cacheForceFeeding('dbert-ft', logger=logger)\n",
    "elif tipiNum() in {1, 2, 3, 4}:\n",
    "    pass\n",
    "    # logWarning(\"Caching only nmf representations.\", logger)\n",
    "    # diversityMetrics = dictSelect(diversityMetrics, {'topic-div@100'})\n",
    "    # cacheForceFeeding('nmf', logger=logger)\n",
    "else:\n",
    "    logWarning(\"We take all metrics, the cache can be overflowed...\", logger)\n",
    "metricFuncts = mergeDicts(diversityMetrics, jaccardDiversityMetrics, noveltyMetrics, strictNoveltyMetrics, serendipityMetrics)\n",
    "log(\"Current metric functions:\\n\" + b(metricFuncts.keys(), 5), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a certain amount of iterations:\n",
    "for i in range(iterations):\n",
    "    # We get all\n",
    "    modelsKeys = shuffle(list(twinewsRankings.keys()))\n",
    "    if TEST:\n",
    "        modelsKeys = [e for e in modelsKeys if \"combin\" not in e]\n",
    "        modelsKeys = modelsKeys[:1]\n",
    "    # For all model instances:\n",
    "    for modelKey in modelsKeys:\n",
    "        # We init the eval data to None:\n",
    "        evalData = None\n",
    "        rankings = None\n",
    "        # For all metrics:\n",
    "        for metricKey, metricFunct in metricFuncts.items():\n",
    "            # If we didn't added the score previously:\n",
    "            if not twinewsScores.has({'id': modelKey, 'metric': metricKey}):\n",
    "                try:\n",
    "                    # We print infos:\n",
    "                    log(\"Computing \" + metricKey + \" score of \" + modelKey + \"...\", logger)\n",
    "                    # We get all data:\n",
    "                    meta = twinewsRankings.getMeta(modelKey)\n",
    "                    splitVersion = meta['splitVersion']\n",
    "                    maxUsers = meta['maxUsers']\n",
    "                    modelName = meta['model']\n",
    "                    # We get eval data:\n",
    "                    if evalData is None:\n",
    "                        evalData = evalDataCache[splitVersion]\n",
    "                    candidates = evalData['candidates']\n",
    "                    # We get rankings:\n",
    "                    if rankings is None:\n",
    "                        log(\"Downloading rankings of \" + modelKey + \"...\", logger)\n",
    "                        rankings = twinewsRankings[modelKey]\n",
    "                        if rankings is None or len(rankings) == 0:\n",
    "                            raise Exception(\"Rankings of \" + modelKey + \" doesn't exist anymore, you need to re-generate it.\")\n",
    "                        else:\n",
    "                            checkRankings(rankings, candidates, maxUsers=maxUsers)\n",
    "                        log(\"Done.\", logger)\n",
    "                    # Init scores:\n",
    "                    scores = []\n",
    "                    # Diversity:\n",
    "                    if metricKey in diversityMetrics or metricKey in jaccardDiversityMetrics:\n",
    "                        userIds = list(rankings.keys())\n",
    "                        if TEST:\n",
    "                            userIds = userIds[:10]\n",
    "                        for userId in pb(userIds, logger=logger, message=\"Computing \" + metricKey + \" of \" + modelKey):\n",
    "                            for currentRankings in rankings[userId]:\n",
    "                                assert len(currentRankings) >= 100\n",
    "                                assert isinstance(currentRankings, list)\n",
    "                                assert isinstance(currentRankings[0], str) or isinstance(currentRankings[0], tuple)\n",
    "                                if isinstance(currentRankings[0], tuple):\n",
    "                                    currentUrls = [e[0] for e in currentRankings]\n",
    "                                else:\n",
    "                                    currentUrls = currentRankings\n",
    "                                score = metricFunct(currentUrls, logger=logger)\n",
    "                                scores.append(score)\n",
    "                        if not TEST:\n",
    "                            assert len(scores) >= len(rankings)\n",
    "                    # Novelty:\n",
    "                    elif metricKey in noveltyMetrics:\n",
    "                        pass\n",
    "                    # Strict novelty:\n",
    "                    elif metricKey in strictNoveltyMetrics:\n",
    "                        pass\n",
    "                    # Serendipity:\n",
    "                    elif metricKey in serendipityMetrics:\n",
    "                        pass\n",
    "                    # We mean all scrores:\n",
    "                    score = float(np.mean(scores))\n",
    "                    # And finally we add the score in the db:\n",
    "                    if not TEST:\n",
    "                        addTwinewsScore(modelKey, metricKey, score, verbose=False)\n",
    "                    # We print result:\n",
    "                    log(metricKey + \" score of \" + modelKey + \": \" + str(truncateFloat(score, 3)), logger)\n",
    "                except Exception as e:\n",
    "                    if isNotebook:\n",
    "                        raise e\n",
    "                    else:\n",
    "                        logError(str(e), logger)\n",
    "                        time.sleep(exceptionSleep)\n",
    "    if sleep > 0:\n",
    "        log(\"Sleeping \" + str(sleep) + \" seconds for the iteration \" + str(i) + \" on \" + str(iterations) + \"...\", logger)\n",
    "        time.sleep(sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isNotebook and TEST:\n",
    "    urls = shuffle(list(newsCollection.distinct(\"url\")))[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isNotebook and TEST:\n",
    "    log(tfidfDiversityAt100(urls), logger)\n",
    "    log(styleDiversityAt100(urls), logger)\n",
    "    log(topicDiversityAt100(urls), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isNotebook and TEST:\n",
    "    urls = shuffle(list(newsCollection.distinct(\"url\")))[:100]\n",
    "    jaccardDistance(urls[0], urls[1], swJaccardCache)\n",
    "    jaccardDiversity(urls, False, verbose=True, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.purge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
