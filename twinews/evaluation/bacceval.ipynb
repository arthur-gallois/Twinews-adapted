{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond accuracy evaluation (bacceval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    " * Diversity at 100 (div@100) : on prend seulement les 100 premiers elements du ranking et on calcul la diversité de ceux-ci en terme de topic, de TFIDF et de style. Donc la moyenne des pairwise distances $$diversity(R) = \\frac{\\sum_{i=1}^{|R|}\\sum_{j=i+1}^{|R|} dist(R_i, R_j)}{\\frac{{|R|}^2-{|R|}}{2}}$$\n",
    " With R a set of recommendation lists. On ne prend que les 100 premier car si on prennait les 1000, alors tous les modèles auraient la même diversité.\n",
    " On utilise les representation vectorielles de TFIDF, style et topic avec la cosine distance. Une quatrieme diversity se base sur la moyenne des distance de jaccard. Attention cette distance c'est pas [l'extension à n ensembles comme décrit sur wikipedia](https://fr.wikipedia.org/wiki/Indice_et_distance_de_Jaccard) (car l'intersection de bcp de document donnera simplement un ensemble vide ou composé de stop words...) mais la moyenne des pairwises distances comme dans cet [article](https://sci-hub.tw/https://ieeexplore.ieee.org/abstract/document/4812525) et [celui-ci](http://www.l3s.de/~siersdorfer/sources/2012/fp055-deng.pdf) (refined diversity jaccard) :\n",
    " $$JD(A, B) = 1 - \\frac{|A \\cap B|}{|A \\cup B|}$$ where A and B are sets of words from the item A and item B. TODO dire si on supprime les stopwords.\n",
    " * Novelty at 100 (nov@100) : pareil mais entre l'historique utilisateur et R.\n",
    " $$novelty(R, H) = \\frac{\\sum_{i=1}^{|R|}\\sum_{j=1}^{|H|} dist(R_i, H_j)}{|R|.|H|}$$\n",
    " * Strict novelty at 100 (snov@100) : pareil mais on prend le min.\n",
    " $$strictnovelty(R, H) = \\frac{\\sum_{i=1}^{|R|} mindist(R_i, H)}{|R|}$$\n",
    " * Serendipity at 100 (ser@100) : the ratio of relevants items the evaluated model recommanded and the primitive model didn't recommand. With $R$ the recommendation set of the evaluated model, $P$ the recommendation set of the primitive model, $T$ the set of relevant items, and for cases where $T \\setminus P \\neq \\emptyset$, we define the serendipity as:\n",
    " $$serendipity(R, P, T) = \\frac{|R \\cap (T \\setminus P)|}{|T \\setminus P|}$$\n",
    " Cases where $T \\setminus P = \\emptyset$ are not relevant because the primitive model already predicted all relevant items. Thus no model can be serendipe. These cases are not taken into account in the average for all user (+ TODO donner le % des cas $T \\setminus P = \\emptyset$).\n",
    " Les modèles primitif sont le modèle TFIDF avec historyRef=1 et lowercase et lemmatization. L'autre est le modèle qui prend le set des mots sans stop words pour l'historique, et cherche la meilleur similarité jaccard dans les candidats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mongo monitoring\n",
    "\n",
    "    db.getCollection('scores').find({'metric': 'snov@100'}).count()\n",
    "    db.getCollection('scores').find({'metric': 'jacc-snov@100'}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Killer unique run:\n",
    "# oomstopper --no-tail bacceval ; killbill bacceval ; cd ~/twinews-logs ; jupython -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique run:\n",
    "# oomstopper --no-tail bacceval ; cd ~/twinews-logs ; jupython -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Killer triple run:\n",
    "# oomstopper --no-tail bacceval ; killbill bacceval ; cd ~/twinews-logs ; jupython --no-tail -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb ; sleep 30 ; jupython --no-tail -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb ; sleep 30 ; jupython --no-tail -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triple run:\n",
    "# oomstopper --no-tail bacceval ; cd ~/twinews-logs ; jupython --no-tail -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb ; sleep 30 ; jupython --no-tail -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb ; sleep 30 ; jupython --no-tail -o nohup-bacceval-$HOSTNAME-$(date +%Y-%m-%d.%M-%S).out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/bacceval.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "isNotebook = '__file__' not in locals()\n",
    "TEST = isNotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.location import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.printer import *\n",
    "from databasetools.mongo import *\n",
    "from datastructuretools.cache import *\n",
    "from newstools.goodarticle.utils import *\n",
    "from nlptools.preprocessing import *\n",
    "from nlptools.news import parser as newsParser\n",
    "from machinelearning.iterator import *\n",
    "from twinews.utils import *\n",
    "from twinews.evaluation import metrics\n",
    "from twinews.evaluation.utils import *\n",
    "from twinews.models.genericutils import *\n",
    "from twinews.models.ranking import *\n",
    "import time\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining logger:\n",
    "logger = Logger(tmpDir('logs') + \"/bacceval.log\") if isNotebook else Logger(\"bacceval-\" + getHostname() + \"-\" + getDateSec() + \".log\")\n",
    "tt = TicToc(logger=logger)\n",
    "tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the cache that is a dict-like object (url --> vector) keeping data until 2Go of free RAM:\n",
    "genericCaches = dict()\n",
    "newsCollection = getNewsCollection(logger=logger)\n",
    "def getter(key, logger=None, verbose=True):\n",
    "    global newsCollection\n",
    "    global genericCaches\n",
    "    global genericFields\n",
    "    if newsCollection is None:\n",
    "        newsCollection = getNewsCollection(logger=logger, verbose=verbose)\n",
    "    cacheKey, url = key\n",
    "    field = genericFields[cacheKey]\n",
    "    if cacheKey in genericCaches:\n",
    "        genericCache = genericCaches[cacheKey]\n",
    "    else:\n",
    "        genericCache = getGenericCache(cacheKey, logger=logger, verbose=verbose)\n",
    "        genericCaches[cacheKey] = genericCache\n",
    "    row = newsCollection.findOne({'url': url}, projection={field: True})\n",
    "    theHash = objectToHash(row[field])\n",
    "    return genericCache[theHash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the minFreeRAM:\n",
    "minFreeRAM = 4\n",
    "cleanInterval = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define primitive models and cache keys:\n",
    "cacheKeys = {\"tfidf\", \"dbert-ft\", \"nmf\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the cache instance (don't forget to purge it at the end):\n",
    "cache = Cache(getter, logger=logger, name=\"cacheForGenericVectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get scores collection and the rankings GridFS:\n",
    "twinewsScores = getTwinewsScores(logger=logger)\n",
    "twinewsRankings = getTwinewsRankings(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cacheForceFeeding(model, maxItems=None, logger=None, verbose=True):\n",
    "    global cache\n",
    "    global newsCollection\n",
    "    i = 0\n",
    "    urls = list(newsCollection.distinct(\"url\"))\n",
    "    if maxItems is not None:\n",
    "        urls = urls[:maxItems]\n",
    "    for url in pb(urls, printRatio=0.01, message=\"Force-feeding the cache...\",\n",
    "                  logger=logger, verbose=verbose):\n",
    "        cache[(model, url)]\n",
    "        if i % 1000 == 0 and freeRAM() < 2:\n",
    "            logWarning(\"Stopping because no RAM left.\", logger)\n",
    "            break\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicDistPrint(url1, url2, dist, prob=1.0, logger=None, verbose=True):\n",
    "    if verbose:\n",
    "        if getRandomFloat() < prob and (dist >= 0.99 or dist < 0.84):\n",
    "                log(dist, logger)\n",
    "                # t1 = getNewsField(url1, 'detokText')\n",
    "                # t2 = getNewsField(url2, 'detokText')\n",
    "                t1Words = set(flattenLists(getNewsField(url1, 'sentences', verbose=False)))\n",
    "                t2Words = set(flattenLists(getNewsField(url2, 'sentences', verbose=False)))\n",
    "                inter = t1Words.intersection(t2Words)\n",
    "                log(\"-\" * 20, logger)\n",
    "                bp(t1Words, 4, logger)\n",
    "                log(\"-\" * 20, logger)\n",
    "                bp(t2Words, 4, logger)\n",
    "                log(\"-\" * 20, logger)\n",
    "                bp(inter, 5, logger)\n",
    "                log(len(inter), logger)\n",
    "                log(\"#\" * 20, logger)\n",
    "                log(\"#\" * 20, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfDiversityAt100(urls, logger=None, verbose=False):\n",
    "    return diversity(urls, 'tfidf', at=100, logger=logger, verbose=verbose)\n",
    "def styleDiversityAt100(urls, logger=None, verbose=False):\n",
    "    return diversity(urls, 'dbert-ft', at=100, logger=logger, verbose=verbose)\n",
    "def topicDiversityAt100(urls, logger=None, verbose=False):\n",
    "    return diversity(urls, 'nmf', at=100, logger=logger, verbose=verbose)\n",
    "def diversity(urls, model, at=100, distance=\"cosine\", logger=None, verbose=False):\n",
    "    global cache\n",
    "    assert isinstance(urls, list)\n",
    "    urls = urls[:at]\n",
    "    assert len(urls) == at\n",
    "    vectors = vstack([cache[(model, url)] for url in urls])\n",
    "    distances = getDistances(vectors, vectors, metric=distance, verbose=False)\n",
    "    pairwiseCount = 0\n",
    "    distSum = 0\n",
    "    for i in range(at):\n",
    "        for u in range(i+1, at):\n",
    "            dist = distances[i][u]\n",
    "            distSum += dist\n",
    "            pairwiseCount += 1\n",
    "            basicDistPrint(urls[i], urls[u], dist, verbose=TEST and verbose, logger=logger)\n",
    "    assert pairwiseCount == (at**2 - at) / 2 # \\frac{{|R|}^2-{|R|}}{2}\n",
    "    return distSum / pairwiseCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swJaccardRepr(url, *args, **kwargs):\n",
    "    return __jaccardRepr(url, 200, *args, **kwargs)\n",
    "def jaccardRepr(url, *args, **kwargs):\n",
    "    return __jaccardRepr(url, 0, *args, **kwargs)\n",
    "def __jaccardRepr\\\n",
    "(\n",
    "    url,\n",
    "    stopWordAmount,\n",
    "    lowercase=True,\n",
    "    logger=None, verbose=True,\n",
    "):\n",
    "    global newsCollection\n",
    "    global STOP_WORDS\n",
    "    assert '__int_1__' in STOP_WORDS\n",
    "    if stopWordAmount is None or stopWordAmount == 0:\n",
    "        sw = None\n",
    "    else:\n",
    "        sw = set(STOP_WORDS[:stopWordAmount])\n",
    "    sentences = getNewsField(url, 'sentences', verbose=False)\n",
    "    tokens = flattenLists(sentences)\n",
    "    if lowercase:\n",
    "        tokens = [e.lower() for e in tokens]\n",
    "    tokens = set(tokens)\n",
    "    if sw is not None and len(sw) > 0:\n",
    "        tokens = set([e for e in tokens if e not in sw])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    def jaccardDistance(url1, url2, cache):\n",
    "        assert isinstance(useSW, Cache)\n",
    "        words1 = cache[url1]\n",
    "        words2 = cache[url2]\n",
    "        return 1 - len(words1.intersection(words2)) / len((words1.union(words2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccardDistance(key, **kwargs):\n",
    "    url1, url2, useSW = key\n",
    "    return __jaccardDistance(url1, url2, useSW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccardDistanceCache = Cache\\\n",
    "(\n",
    "    jaccardDistance,\n",
    "    logger=logger,\n",
    "    minFreeRAM=minFreeRAM + 5,\n",
    "    name=\"jaccardDistanceCache\",\n",
    "    indexStrings=True,\n",
    "    cleanInterval=cleanInterval / 10,\n",
    "    actionCleanInterval=60 * 10,\n",
    "    fake=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __jaccardDistance(url1, url2, useSW):\n",
    "    global jaccardCache\n",
    "    global swJaccardCache\n",
    "    assert isinstance(useSW, bool)\n",
    "    cache = swJaccardCache if useSW else jaccardCache\n",
    "    words1 = cache[url1]\n",
    "    words2 = cache[url2]\n",
    "    return 1 - len(words1.intersection(words2)) / len((words1.union(words2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swJaccardDiversityAt100(urls, logger=None, verbose=False):\n",
    "    return jaccardDiversity(urls, True, at=100, logger=logger, verbose=verbose)\n",
    "def jaccardDiversityAt100(urls, logger=None, verbose=False):\n",
    "    return jaccardDiversity(urls, False, at=100, logger=logger, verbose=verbose)\n",
    "def jaccardDiversity(urls, useSW, at=100, logger=None, verbose=False):\n",
    "    global swJaccardCache\n",
    "    global jaccardCache\n",
    "    assert isinstance(urls, list)\n",
    "    urls = urls[:at]\n",
    "    assert len(urls) == at\n",
    "    pairwiseCount = 0\n",
    "    distSum = 0\n",
    "    for i in range(at):\n",
    "        for u in range(i+1, at):\n",
    "            dist = jaccardDistanceCache[(urls[i], urls[u], useSW)]\n",
    "            distSum += dist\n",
    "            pairwiseCount += 1\n",
    "            basicDistPrint(urls[i], urls[u], dist, verbose=TEST and verbose, logger=logger)\n",
    "    assert pairwiseCount == (at**2 - at) / 2 # \\frac{{|R|}^2-{|R|}}{2}\n",
    "    return distSum / pairwiseCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swJaccardCache = Cache(swJaccardRepr, logger=logger, name=\"swJaccardCache\", minFreeRAM=minFreeRAM + 1, cleanInterval=cleanInterval)\n",
    "jaccardCache = Cache(jaccardRepr, logger=logger, name=\"jaccardCache\", minFreeRAM=minFreeRAM + 1, cleanInterval=cleanInterval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfNoveltyAt100(*args, logger=None, verbose=False):\n",
    "    return novelty(*args, 'tfidf', at=100, logger=logger, verbose=verbose)\n",
    "def styleNoveltyAt100(*args, logger=None, verbose=False):\n",
    "    return novelty(*args, 'dbert-ft', at=100, logger=logger, verbose=verbose)\n",
    "def topicNoveltyAt100(*args, logger=None, verbose=False):\n",
    "    return novelty(*args, 'nmf', at=100, logger=logger, verbose=verbose)\n",
    "def novelty(historyUrls, urls, model, at=100, distance=\"cosine\", logger=None, verbose=False):\n",
    "    global cache\n",
    "    assert isinstance(urls, list)\n",
    "    urls = urls[:at]\n",
    "    assert len(urls) == at\n",
    "    historyUrls = list(historyUrls)\n",
    "    assert len(historyUrls) > 0\n",
    "    historyVectors = vstack([cache[(model, url)] for url in historyUrls])\n",
    "    vectors = vstack([cache[(model, url)] for url in urls])\n",
    "    distances = getDistances(historyVectors, vectors, metric=distance, verbose=False)\n",
    "    pairwiseCount = 0\n",
    "    distSum = 0\n",
    "    for i in range(len(historyUrls)):\n",
    "        for u in range(len(urls)):\n",
    "            dist = distances[i][u]\n",
    "            distSum += dist\n",
    "            pairwiseCount += 1\n",
    "            basicDistPrint(historyUrls[i], urls[u], dist, verbose=TEST and verbose, logger=logger)\n",
    "    assert pairwiseCount == len(historyUrls) * len(urls)\n",
    "    return distSum / pairwiseCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swJaccardNoveltyAt100(*args, logger=None, verbose=False):\n",
    "    return jaccardNovelty(*args, True, at=100, logger=logger, verbose=verbose)\n",
    "def jaccardNoveltyAt100(*args, logger=None, verbose=False):\n",
    "    return jaccardNovelty(*args, False, at=100, logger=logger, verbose=verbose)\n",
    "def jaccardNovelty(historyUrls, urls, useSW, at=100, logger=None, verbose=False):\n",
    "    global swJaccardCache\n",
    "    global jaccardCache\n",
    "    assert isinstance(urls, list)\n",
    "    urls = urls[:at]\n",
    "    assert len(urls) == at\n",
    "    historyUrls = list(historyUrls)\n",
    "    assert len(historyUrls) > 0\n",
    "    pairwiseCount = 0\n",
    "    distSum = 0\n",
    "    for i in range(len(historyUrls)):\n",
    "        for u in range(len(urls)):\n",
    "            dist = jaccardDistanceCache[(historyUrls[i], urls[u], useSW)]\n",
    "            distSum += dist\n",
    "            pairwiseCount += 1\n",
    "            basicDistPrint(historyUrls[i], urls[u], dist, verbose=TEST and verbose, logger=logger)\n",
    "    assert pairwiseCount == len(historyUrls) * len(urls)\n",
    "    return distSum / pairwiseCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strict novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfStrictNoveltyAt100(*args, logger=None, verbose=False):\n",
    "    return strictNovelty(*args, 'tfidf', at=100, logger=logger, verbose=verbose)\n",
    "def styleStrictNoveltyAt100(*args, logger=None, verbose=False):\n",
    "    return strictNovelty(*args, 'dbert-ft', at=100, logger=logger, verbose=verbose)\n",
    "def topicStrictNoveltyAt100(*args, logger=None, verbose=False):\n",
    "    return strictNovelty(*args, 'nmf', at=100, logger=logger, verbose=verbose)\n",
    "def strictNovelty(historyUrls, urls, model, at=100, distance=\"cosine\", logger=None, verbose=False):\n",
    "    global cache\n",
    "    assert isinstance(urls, list)\n",
    "    urls = urls[:at]\n",
    "    assert len(urls) == at\n",
    "    historyUrls = list(historyUrls)\n",
    "    assert len(historyUrls) > 0\n",
    "    historyVectors = vstack([cache[(model, url)] for url in historyUrls])\n",
    "    vectors = vstack([cache[(model, url)] for url in urls])\n",
    "    distances = getDistances(historyVectors, vectors, metric=distance, verbose=False)\n",
    "    pairwiseCount = 0\n",
    "    distSum = 0\n",
    "    for u in range(len(urls)):\n",
    "        minDist = None\n",
    "        for i in range(len(historyUrls)):\n",
    "            dist = distances[i][u]\n",
    "            if dist > 0 and dist < 0.00001:\n",
    "                dist = 0.0\n",
    "            if minDist is None or dist < minDist:\n",
    "                minDist = dist\n",
    "            basicDistPrint(historyUrls[i], urls[u], dist, verbose=TEST and verbose, logger=logger)\n",
    "        pairwiseCount += 1\n",
    "        distSum += minDist\n",
    "    assert pairwiseCount == len(urls)\n",
    "    return distSum / pairwiseCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard strict novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swJaccardStrictNoveltyAt100(*args, logger=None, verbose=False):\n",
    "    return jaccardStrictNovelty(*args, True, at=100, logger=logger, verbose=verbose)\n",
    "def jaccardStrictNoveltyAt100(*args, logger=None, verbose=False):\n",
    "    return jaccardStrictNovelty(*args, False, at=100, logger=logger, verbose=verbose)\n",
    "def jaccardStrictNovelty(historyUrls, urls, useSW, at=100, logger=None, verbose=False):\n",
    "    global swJaccardCache\n",
    "    global jaccardCache\n",
    "    assert isinstance(urls, list)\n",
    "    urls = urls[:at]\n",
    "    assert len(urls) == at\n",
    "    historyUrls = list(historyUrls)\n",
    "    assert len(historyUrls) > 0\n",
    "    pairwiseCount = 0\n",
    "    distSum = 0\n",
    "    for u in range(len(urls)):\n",
    "        minDist = None\n",
    "        for i in range(len(historyUrls)):\n",
    "            dist = jaccardDistanceCache[(historyUrls[i], urls[u], useSW)]\n",
    "            if dist > 0 and dist < 0.00001:\n",
    "                dist = 0.0\n",
    "            if minDist is None or dist < minDist:\n",
    "                minDist = dist\n",
    "            basicDistPrint(historyUrls[i], urls[u], dist, verbose=TEST and verbose, logger=logger)\n",
    "        pairwiseCount += 1\n",
    "        distSum += minDist\n",
    "    assert pairwiseCount == len(urls)\n",
    "    return distSum / pairwiseCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serendipity\n",
    "\n",
    " * splitVersion 1, rankings having no serendipity scores for tfidf-ser@100: **24.0%** (meaning the primitive model predicted all relevant items, thus 0-division in the formula...)\n",
    " * splitVersion 1, for jacc-ser@100: **2.31%**\n",
    " * splitVersion 2, for tfidf-ser@100: **27.9%**\n",
    " * splitVersion 2, for jacc-ser@100: **2.88%**\n",
    " * For wtfidf-ser@100: **28.78%** (unknown splitVersion)\n",
    " * For style-ser@100: **22.15%** (unknown splitVersion)\n",
    " * For bm25-ser@100: **28.78%** (unknown splitVersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmodels = {1: {\"tfidf\": \"tfidf-4b89a\", \"wtfidf\": \"tfidf-7febb\", \"jaccard\": \"jaccard-1d3f1\", \"bm25\": \"bm25-933f7\", \"dbert-ft\": \"dbert-ft-7847a\"}, 2: {\"tfidf\": \"tfidf-71fb5\", \"wtfidf\": \"tfidf-7e79d\", \"jaccard\": \"jaccard-1499a\", \"bm25\": \"bm25-1eb2a\", \"dbert-ft\": \"dbert-ft-d1b5f\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfSerendipityAt100(rankings, userId, rankingIndex, splitVersion, logger=None, verbose=False):\n",
    "    return serendipity(rankings, userId, rankingIndex, splitVersion, 'tfidf', at=100, logger=logger, verbose=verbose)\n",
    "def wtfidfSerendipityAt100(rankings, userId, rankingIndex, splitVersion, logger=None, verbose=False):\n",
    "    return serendipity(rankings, userId, rankingIndex, splitVersion, 'wtfidf', at=100, logger=logger, verbose=verbose)\n",
    "def bm25SerendipityAt100(rankings, userId, rankingIndex, splitVersion, logger=None, verbose=False):\n",
    "    return serendipity(rankings, userId, rankingIndex, splitVersion, 'bm25', at=100, logger=logger, verbose=verbose)\n",
    "def styleSerendipityAt100(rankings, userId, rankingIndex, splitVersion, logger=None, verbose=False):\n",
    "    return serendipity(rankings, userId, rankingIndex, splitVersion, 'dbert-ft', at=100, logger=logger, verbose=verbose)\n",
    "def jaccardSerendipityAt100(rankings, userId, rankingIndex, splitVersion, logger=None, verbose=False):\n",
    "    return serendipity(rankings, userId, rankingIndex, splitVersion, 'jaccard', at=100, logger=logger, verbose=verbose)\n",
    "def serendipity(rankings, userId, rankingIndex, splitVersion, model, at=100, logger=None, verbose=False):\n",
    "    global pmodels\n",
    "    global pmodelsRankingsCache\n",
    "    global evalDataCache\n",
    "    # Getting T:\n",
    "    evalData = evalDataCache[splitVersion]\n",
    "    T = set(evalData['testUsers'][userId].keys())\n",
    "    # Getting R:\n",
    "    R = rankings[userId][rankingIndex]\n",
    "    if isinstance(R[0], tuple):\n",
    "        R = [e[0] for e in R]\n",
    "    R = set(R[:at])\n",
    "    assert len(R) == 100\n",
    "    # Getting P:\n",
    "    pmodel = pmodels[splitVersion][model]\n",
    "    prankings = pmodelsRankingsCache[pmodel]\n",
    "    P = prankings[userId][rankingIndex]\n",
    "    if isinstance(P[0], tuple):\n",
    "        P = [e[0] for e in P]\n",
    "    P = set(P[:at])\n",
    "    assert len(P) == 100\n",
    "    # Getting T minus P:\n",
    "    TminusP = set([e for e in T if e not in P])\n",
    "    # We check if this is relevant:\n",
    "    if len(TminusP) == 0:\n",
    "        return None\n",
    "    # We compute the ratio:\n",
    "    score = len(R.intersection(TminusP)) / len(TminusP)\n",
    "    # Printing stuff:\n",
    "    if TEST:\n",
    "        allItems = T.union(R).union(P)\n",
    "        idsMap = dict()\n",
    "        i = 0\n",
    "        for url in allItems:\n",
    "            idsMap[url] = i\n",
    "            i += 1\n",
    "        T = set([idsMap[e] for e in T])\n",
    "        R = set([idsMap[e] for e in R])\n",
    "        P = set([idsMap[e] for e in P])\n",
    "        TminusP = set([idsMap[e] for e in TminusP])\n",
    "        log(\"userId: \" + str(userId), logger)\n",
    "        log(\"splitVersion: \" + str(splitVersion), logger)\n",
    "        log(\"model: \" + str(model), logger)\n",
    "        log(\"-\" * 20, logger)\n",
    "        log(\"T: \" + str(T), logger)\n",
    "        log(\"-\" * 20, logger)\n",
    "        log(\"R: \" + str(R), logger)\n",
    "        log(\"-\" * 20, logger)\n",
    "        log(\"P: \" + str(P), logger)\n",
    "        log(\"-\" * 20, logger)\n",
    "        log(\"TminusP: \" + str(TminusP), logger)\n",
    "        log(\"-\" * 20, logger)\n",
    "        log(\"score: \" + str(score), logger)\n",
    "        log(\"#\" * 20, logger)\n",
    "        log(\"#\" * 20, logger)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRankings(key, logger=None, verbose=True, **kwargs):\n",
    "    log(\"Downloading rankings of the primitive model \" + key + \"...\", logger, verbose=verbose)\n",
    "    rk = twinewsRankings[key]\n",
    "    log(\"Done.\", logger, verbose=verbose)\n",
    "    return rk\n",
    "pmodelsRankingsCache = Cache(getRankings, logger=logger, name=\"pmodelsRankingsCache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We init an eval data cache:\n",
    "def evalDataGetter(splitVersion, logger=None, verbose=True):\n",
    "    log(\"Downloading eval data version \" + str(splitVersion) + \"...\", logger, verbose=verbose)\n",
    "    return getEvalData(splitVersion, logger=logger, verbose=verbose, maxExtraNews=0)\n",
    "evalDataCache = Cache(evalDataGetter, logger=logger, name=\"evalDataCache\", minFreeRAM=minFreeRAM + 3, cleanInterval=cleanInterval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc params:\n",
    "iterations = 1 if isNotebook else 10000000\n",
    "sleep = 0 if isNotebook else 30\n",
    "exceptionSleep = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prevent reloading rankings at each test:\n",
    "testRankings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Metrics for local:\n",
    "metricFuncts = \\\n",
    "{\n",
    "    ##### Diversity #####\n",
    "    'div@100': tfidfDiversityAt100,\n",
    "    'style-div@100': styleDiversityAt100,\n",
    "    'topic-div@100': topicDiversityAt100,\n",
    "    ##### Jaccard diversity #####\n",
    "    'jacc-div@100': jaccardDiversityAt100,\n",
    "    'swjacc-div@100': swJaccardDiversityAt100,\n",
    "    ##### Novelty #####\n",
    "    'nov@100': tfidfNoveltyAt100,\n",
    "    'style-nov@100': styleNoveltyAt100,\n",
    "    'topic-nov@100': topicNoveltyAt100,\n",
    "    ##### Jaccard novelty #####\n",
    "    'jacc-nov@100': jaccardNoveltyAt100,\n",
    "    'swjacc-nov@100': swJaccardNoveltyAt100,\n",
    "    ##### Strict novelty #####\n",
    "    'snov@100': tfidfStrictNoveltyAt100,\n",
    "    'style-snov@100': styleStrictNoveltyAt100,\n",
    "    'topic-snov@100': topicStrictNoveltyAt100,\n",
    "    ##### Jaccard strict novelty #####\n",
    "    'jacc-snov@100': jaccardStrictNoveltyAt100,\n",
    "    'swjacc-snov@100': swJaccardStrictNoveltyAt100,\n",
    "    ##### Serendipity #####\n",
    "    'tfidf-ser@100': tfidfSerendipityAt100,\n",
    "    'wtfidf-ser@100': wtfidfSerendipityAt100,\n",
    "    'bm25-ser@100': bm25SerendipityAt100,\n",
    "    'style-ser@100': styleSerendipityAt100,\n",
    "    'jacc-ser@100': jaccardSerendipityAt100,\n",
    "}\n",
    "tipiNum = lambda: tipiNumber(toInteger=True)\n",
    "# cacheForceFeeding('tfidf', maxItems=300, logger=logger)\n",
    "if TEST:\n",
    "    metricFuncts = dictSelect(metricFuncts, {'jacc-div@100', 'swjacc-div@100', 'jacc-nov@100', 'swjacc-nov@100', 'jacc-snov@100', 'swjacc-snov@100'})\n",
    "# elif tipiNum() in {60, 61, 62, 63}:\n",
    "#     metricFuncts = dictSelect(metricFuncts, {'div@100', 'nov@100'})\n",
    "elif isHostname(\"titanv\"):\n",
    "    metricFuncts = dictSelect(metricFuncts, {'swjacc-nov@100', 'swjacc-snov@100'})\n",
    "elif isHostname(\"kepler\"):\n",
    "    metricFuncts = dictSelect(metricFuncts, {'swjacc-nov@100', 'swjacc-snov@100'})\n",
    "elif isHostname(\"tipi\"):\n",
    "    # metricFuncts = dictSelect(metricFuncts, {'jacc-div@100', 'swjacc-div@100', 'jacc-nov@100', 'swjacc-nov@100', 'jacc-snov@100', 'swjacc-snov@100'})\n",
    "    # metricFuncts = dictSelect(metricFuncts, {'div@100', 'nov@100', 'snov@100'})\n",
    "    # metricFuncts = dictSelect(metricFuncts, {'topic-div@100', 'topic-nov@100', 'topic-snov@100'})\n",
    "    # metricFuncts = dictSelect(metricFuncts, {'style-div@100', 'style-nov@100', 'style-snov@100'})\n",
    "    # metricFuncts = dictSelect(metricFuncts, {'jacc-div@100', 'swjacc-div@100', 'jacc-nov@100', 'swjacc-nov@100', 'jacc-snov@100', 'swjacc-snov@100'})\n",
    "    metricFuncts = dictSelect(metricFuncts, {'jacc-div@100', 'swjacc-div@100', 'jacc-nov@100', 'swjacc-nov@100', 'jacc-snov@100', 'swjacc-snov@100'})\n",
    "    if False:\n",
    "        tipis = \"88 81 85 82 92 93 95 58 63 80 57 59 56 04 61 62 90 86 83 94 84 89 01 87 06 02 03\".split()\n",
    "        tipis = [int(e) for e in tipis]\n",
    "        tipis = shuffle(tipis, seed=0)\n",
    "        tipis = split(tipis, 4)\n",
    "        if tipiNum() in tipis[0]:\n",
    "            metricFuncts = dictSelect(metricFuncts, {'swjacc-div@100'})\n",
    "        elif tipiNum() in tipis[1]:\n",
    "            metricFuncts = dictSelect(metricFuncts, {'swjacc-nov@100', 'swjacc-snov@100'})\n",
    "        elif tipiNum() in tipis[2]:\n",
    "            metricFuncts = dictSelect(metricFuncts, {'jacc-div@100'})\n",
    "        elif tipiNum() in tipis[3]:\n",
    "            metricFuncts = dictSelect(metricFuncts, {'jacc-nov@100', 'jacc-snov@100'})\n",
    "        else:\n",
    "            metricFuncts = dictSelect(metricFuncts, {'jacc-nov@100', 'jacc-snov@100'})\n",
    "elif octods():\n",
    "    # metricFuncts = dictSelect(metricFuncts, {'jacc-nov@100', 'jacc-snov@100'})\n",
    "    metricFuncts = dictSelect(metricFuncts, {'jacc-div@100', 'swjacc-div@100', 'jacc-nov@100', 'swjacc-nov@100', 'jacc-snov@100', 'swjacc-snov@100'})\n",
    "else:\n",
    "    # metricFuncts = dictSelect(metricFuncts, {'jacc-nov@100', 'jacc-snov@100'})\n",
    "    metricFuncts = dictSelect(metricFuncts, {'jacc-div@100', 'swjacc-div@100', 'jacc-nov@100', 'swjacc-nov@100', 'jacc-snov@100', 'swjacc-snov@100'})\n",
    "log(\"Current metric functions:\\n\" + b(metricFuncts.keys(), 5), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print size of caches each n seconds:\n",
    "def cacheInfos(*args, **kwargs):\n",
    "    if isFile(tmpDir() + \"/cache-infos\"):\n",
    "        for current in [cache, swJaccardCache, jaccardCache, pmodelsRankingsCache, evalDataCache, jaccardDistanceCache]:\n",
    "            current.printState()\n",
    "cachePrintTimer = Timer(cacheInfos, 60 * 5)\n",
    "cachePrintTimer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For a certain amount of iterations:\n",
    "for i in range(iterations):\n",
    "    # We get all\n",
    "    modelsKeys = shuffle(sorted(list(twinewsRankings.keys())), seed=0 if TEST else None)\n",
    "    if TEST:\n",
    "        modelsKeys = [e for e in modelsKeys if \"combin\" not in e]\n",
    "        modelsKeys = modelsKeys[:1]\n",
    "    # For all model instances:\n",
    "    tt.tic(display=False)\n",
    "    for modelKey in modelsKeys:\n",
    "        # We init the eval data to None:\n",
    "        evalData = None\n",
    "        rankings = None\n",
    "        # For all metrics:\n",
    "        for metricKey, metricFunct in metricFuncts.items():\n",
    "            # If we didn't added the score previously:\n",
    "            if TEST or (not twinewsScores.has({'id': modelKey, 'metric': metricKey})):\n",
    "                try:\n",
    "                    # We print infos:\n",
    "                    log(\"Computing \" + metricKey + \" score of \" + modelKey + \"...\", logger)\n",
    "                    # We get all data:\n",
    "                    meta = twinewsRankings.getMeta(modelKey)\n",
    "                    splitVersion = meta['splitVersion']\n",
    "                    maxUsers = meta['maxUsers']\n",
    "                    modelName = meta['model']\n",
    "                    # We get eval data:\n",
    "                    if evalData is None:\n",
    "                        evalData = evalDataCache[splitVersion]\n",
    "                    candidates = evalData['candidates']\n",
    "                    # We get rankings:\n",
    "                    if rankings is None:\n",
    "                        if TEST and testRankings is not None:\n",
    "                            logWarning(\"Taking testRankings as rankings !!! \" * 20, logger)\n",
    "                            rankings = testRankings\n",
    "                        else:\n",
    "                            localTT = TicToc(logger=logger)\n",
    "                            localTT.tic(\"Downloading rankings of \" + modelKey + \"...\")\n",
    "                            rankings = twinewsRankings[modelKey]\n",
    "                            if rankings is None or len(rankings) == 0:\n",
    "                                raise Exception(\"Rankings of \" + modelKey + \" doesn't exist anymore, you need to re-generate it.\")\n",
    "                            else:\n",
    "                                checkRankings(rankings, candidates, maxUsers=maxUsers)\n",
    "                            localTT.toc(modelKey + \" downloaded.\", logger)\n",
    "                            if TEST:\n",
    "                                testRankings = rankings\n",
    "                    # Init scores:\n",
    "                    scores = []\n",
    "                    # We get user ids:\n",
    "                    userIds = shuffle(sorted(list(rankings.keys())), seed=0)\n",
    "                    if TEST:\n",
    "                        userIds = userIds[:100]\n",
    "                    # Diversity:\n",
    "                    if 'div@' in metricKey:\n",
    "                        for userId in pb(userIds, logger=logger, message=\"Computing \" + metricKey + \" of \" + modelKey):\n",
    "                            for currentRankings in rankings[userId]:\n",
    "                                assert len(currentRankings) >= 100\n",
    "                                assert isinstance(currentRankings, list)\n",
    "                                assert isinstance(currentRankings[0], str) or isinstance(currentRankings[0], tuple)\n",
    "                                if isinstance(currentRankings[0], tuple):\n",
    "                                    currentUrls = [e[0] for e in currentRankings]\n",
    "                                else:\n",
    "                                    currentUrls = currentRankings\n",
    "                                score = metricFunct(currentUrls, logger=logger)\n",
    "                                scores.append(score)\n",
    "                        if not TEST:\n",
    "                            assert len(scores) >= len(rankings)\n",
    "                    # Novelty:\n",
    "                    elif 'nov@' in metricKey:\n",
    "                        for userId in pb(userIds, logger=logger, message=\"Computing \" + metricKey + \" of \" + modelKey):\n",
    "                            for currentRankings in rankings[userId]:\n",
    "                                assert len(currentRankings) >= 100\n",
    "                                assert isinstance(currentRankings, list)\n",
    "                                assert isinstance(currentRankings[0], str) or isinstance(currentRankings[0], tuple)\n",
    "                                if isinstance(currentRankings[0], tuple):\n",
    "                                    currentUrls = [e[0] for e in currentRankings]\n",
    "                                else:\n",
    "                                    currentUrls = currentRankings\n",
    "                                historyUrls = set(evalData['trainUsers'][userId].keys())\n",
    "                                score = metricFunct(historyUrls, currentUrls, logger=logger)\n",
    "                                scores.append(score)\n",
    "                        if not TEST:\n",
    "                            assert len(scores) >= len(rankings)\n",
    "                    # Serendipity:\n",
    "                    elif 'ser@' in metricKey:\n",
    "                        totalScoresToCompute = 0\n",
    "                        noneScores = 0\n",
    "                        for userId in pb(userIds, logger=logger, message=\"Computing \" + metricKey + \" of \" + modelKey):\n",
    "                            for rankingIndex in range(len(rankings[userId])):\n",
    "                                currentRankings = rankings[userId][rankingIndex]\n",
    "                                assert len(currentRankings) >= 100\n",
    "                                assert isinstance(currentRankings, list)\n",
    "                                assert isinstance(currentRankings[0], str) or isinstance(currentRankings[0], tuple)\n",
    "                                score = metricFunct(rankings, userId, rankingIndex, splitVersion, logger=logger)\n",
    "                                if score is None:\n",
    "                                    noneScores += 1\n",
    "                                else:\n",
    "                                    scores.append(score)\n",
    "                                totalScoresToCompute += 1\n",
    "                        log(\"Rankings having no serendipity scores for \" + metricKey + \": \" + str(truncateFloat(noneScores / totalScoresToCompute * 100, 2)) + \"%\", logger)\n",
    "                    else:\n",
    "                        logError(\"The metric key \" + metricKey + \" is unknown.\", logger)\n",
    "                    # We mean all scrores:\n",
    "                    if len(scores) == 0:\n",
    "                        score = 0.0\n",
    "                    else:\n",
    "                        score = float(np.mean(scores))\n",
    "                    # And finally we add the score in the db:\n",
    "                    if not TEST:\n",
    "                        addTwinewsScore(modelKey, metricKey, score, verbose=False)\n",
    "                    # We print result:\n",
    "                    log(metricKey + \" score of \" + modelKey + \": \" + str(truncateFloat(score, 3)), logger)\n",
    "                except AssertionError as error:\n",
    "                    logException(e, logger)\n",
    "                except Exception as e:\n",
    "                    if isNotebook:\n",
    "                        raise e\n",
    "                    else:\n",
    "                        logError(str(e), logger)\n",
    "                        time.sleep(exceptionSleep)\n",
    "        tt.tic(modelKey + \" done.\")\n",
    "    if sleep > 0:\n",
    "        log(\"Sleeping \" + str(sleep) + \" seconds for the iteration \" + str(i) + \" on \" + str(iterations) + \"...\", logger)\n",
    "        time.sleep(sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isNotebook and TEST:\n",
    "    urls = shuffle(list(newsCollection.distinct(\"url\")))[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isNotebook and TEST:\n",
    "    log(tfidfDiversityAt100(urls), logger)\n",
    "    log(styleDiversityAt100(urls), logger)\n",
    "    log(topicDiversityAt100(urls), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isNotebook and TEST:\n",
    "    urls = shuffle(list(newsCollection.distinct(\"url\")))[:100]\n",
    "    jaccardDistance(urls[0], urls[1], swJaccardCache)\n",
    "    jaccardDiversity(urls, False, verbose=True, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isNotebook and TEST:\n",
    "    def parallelJaccardDiversity(urls, useSW, at=100, logger=None, verbose=False):\n",
    "        \"\"\"\n",
    "            Much slower...\n",
    "        \"\"\"\n",
    "        global swJaccardCache\n",
    "        global jaccardCache\n",
    "        assert isinstance(urls, list)\n",
    "        urls = urls[:at]\n",
    "        assert len(urls) == at\n",
    "        # Getting data:\n",
    "        cache = swJaccardCache if useSW else jaccardCache\n",
    "        data = dict()\n",
    "        for url in urls:\n",
    "            data[url] = cache[url]\n",
    "        # Getting pairs to compute:\n",
    "        pairs = []\n",
    "        for i in range(at):\n",
    "            for u in range(i+1, at):\n",
    "                pairs.append((i, u))\n",
    "        pairsChunks = split(pairs, cpuCount())\n",
    "        # Defining the gen fucnt:\n",
    "        def genFunct(pairs, urls, data, *args, **kwargs):\n",
    "            for i, u in pairs:\n",
    "                yield ((i, u), jaccardDistance(urls[i], urls[u], data))\n",
    "        # Defining the MLIterator:\n",
    "        mli = MLIterator(pairsChunks, genFunct, genArgs=(urls, data), verbose=False, parallelProcesses=cpuCount(), maxParallelProcesses=cpuCount())\n",
    "        # Iterating all pairs yielded by the mli:\n",
    "        pairwiseCount = 0\n",
    "        distSum = 0\n",
    "        for ((i, u), dist) in mli:\n",
    "            distSum += dist\n",
    "            pairwiseCount += 1\n",
    "        # Checking the size:\n",
    "        assert pairwiseCount == (at**2 - at) / 2 # \\frac{{|R|}^2-{|R|}}{2}\n",
    "        # Returning the result:\n",
    "        return distSum / pairwiseCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isNotebook and TEST:\n",
    "    urls = shuffle(list(newsCollection.distinct(\"url\")))[:100]\n",
    "    tt.tic(display=False)\n",
    "    for i in range(100):\n",
    "        print(jaccardDiversity(urls, False, verbose=False, logger=logger))\n",
    "    tt.tic()\n",
    "    tt.tic(display=False)\n",
    "    for i in range(100):\n",
    "        print(parallelJaccardDiversity(urls, False, verbose=False, logger=logger))\n",
    "    tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isNotebook and TEST:\n",
    "    urls = shuffle(list(newsCollection.distinct(\"url\")))[:100]\n",
    "    at = 50\n",
    "    historyUrls1 = urls[:10]\n",
    "    urls1 = urls[:50]\n",
    "    historyUrls2 = urls[50:60]\n",
    "    urls2 = urls[:50]\n",
    "    historyUrls3 = urls[:60]\n",
    "    urls3 = urls[:50]\n",
    "    historyUrls4 = urls[:60]\n",
    "    urls4 = urls[:49] + [urls[62]]\n",
    "    print(jaccardStrictNovelty(historyUrls1, urls1, True, at=at, logger=logger, verbose=True))\n",
    "    print(jaccardStrictNovelty(historyUrls2, urls2, True, at=at, logger=logger))\n",
    "    print(jaccardStrictNovelty(historyUrls3, urls3, True, at=at, logger=logger))\n",
    "    print(jaccardStrictNovelty(historyUrls4, urls4, True, at=at, logger=logger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.purge()\n",
    "swJaccardCache.purge()\n",
    "jaccardCache.purge()\n",
    "pmodelsRankingsCache.purge()\n",
    "evalDataCache.purge()\n",
    "jaccardDistanceCache.purge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
