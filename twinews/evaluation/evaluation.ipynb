{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNotebook = '__file__' not in locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.location import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.printer import *\n",
    "from databasetools.mongo import *\n",
    "from newstools.goodarticle.utils import *\n",
    "from nlptools.preprocessing import *\n",
    "from nlptools.news import parser as newsParser\n",
    "from machinelearning.iterator import *\n",
    "from twinews.utils import *\n",
    "from twinews.evaluation import metrics\n",
    "from twinews.evaluation.utils import *\n",
    "import time\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tictoc starts...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = Logger(tmpDir('logs') + \"/evaluation.log\") if isNotebook else Logger(\"evaluation.log\")\n",
    "tt = TicToc(logger=logger)\n",
    "tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1 if isNotebook else 10000000\n",
    "sleep = 0 if isNotebook else 10\n",
    "exceptionSleep = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricFuncts = \\\n",
    "{\n",
    "    'ndcg': metrics.ndcg,\n",
    "    'ndcg@10': metrics.ndcgAt10,\n",
    "    'ndcg@100': metrics.ndcgAt100,\n",
    "    'mrr': metrics.mrr,\n",
    "    'p@10': metrics.pAt10,\n",
    "    'p@100': metrics.pAt100,\n",
    "    'map': metrics.map,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twinews scores initialised.\n",
      "Computing ndcg score of lda-aa8d5...\n",
      "Downloading eval data version 2...\n",
      "--> tic: 32.79s | message: Eval data loaded\n",
      "--> toc total duration: 35.92s | message: Got Twinews evaluation data\n",
      "Downloading rankings of lda-aa8d5...\n",
      "Done.\n",
      "ndcg score of lda-aa8d5: 0.25\n",
      "Computing ndcg@10 score of lda-aa8d5...\n",
      "ndcg@10 score of lda-aa8d5: 0.03\n",
      "Computing ndcg@100 score of lda-aa8d5...\n",
      "ndcg@100 score of lda-aa8d5: 0.09\n",
      "Computing mrr score of lda-aa8d5...\n",
      "mrr score of lda-aa8d5: 0.08\n",
      "Computing p@10 score of lda-aa8d5...\n",
      "p@10 score of lda-aa8d5: 0.02\n",
      "Computing p@100 score of lda-aa8d5...\n",
      "p@100 score of lda-aa8d5: 0.01\n",
      "Computing map score of lda-aa8d5...\n",
      "map score of lda-aa8d5: 0.03\n",
      "Computing ndcg score of nmf-b61b9...\n",
      "Downloading eval data version 2...\n",
      "--> tic: 32.29s | message: Eval data loaded\n",
      "--> toc total duration: 35.3s | message: Got Twinews evaluation data\n",
      "Downloading rankings of nmf-b61b9...\n",
      "Done.\n",
      "ndcg score of nmf-b61b9: 0.4\n",
      "Computing ndcg@10 score of nmf-b61b9...\n",
      "ndcg@10 score of nmf-b61b9: 0.18\n",
      "Computing ndcg@100 score of nmf-b61b9...\n",
      "ndcg@100 score of nmf-b61b9: 0.31\n",
      "Computing mrr score of nmf-b61b9...\n",
      "mrr score of nmf-b61b9: 0.31\n",
      "Computing p@10 score of nmf-b61b9...\n",
      "p@10 score of nmf-b61b9: 0.12\n",
      "Computing p@100 score of nmf-b61b9...\n",
      "p@100 score of nmf-b61b9: 0.04\n",
      "Computing map score of nmf-b61b9...\n",
      "map score of nmf-b61b9: 0.15\n",
      "Computing ndcg score of lda-b637b...\n",
      "Downloading eval data version 2...\n",
      "--> tic: 33.1s | message: Eval data loaded\n",
      "--> toc total duration: 36.27s | message: Got Twinews evaluation data\n",
      "Downloading rankings of lda-b637b...\n",
      "Done.\n",
      "ndcg score of lda-b637b: 0.25\n",
      "Computing ndcg@10 score of lda-b637b...\n",
      "ndcg@10 score of lda-b637b: 0.03\n",
      "Computing ndcg@100 score of lda-b637b...\n",
      "ndcg@100 score of lda-b637b: 0.08\n",
      "Computing mrr score of lda-b637b...\n",
      "mrr score of lda-b637b: 0.08\n",
      "Computing p@10 score of lda-b637b...\n",
      "p@10 score of lda-b637b: 0.02\n",
      "Computing p@100 score of lda-b637b...\n",
      "p@100 score of lda-b637b: 0.01\n",
      "Computing map score of lda-b637b...\n",
      "map score of lda-b637b: 0.03\n",
      "Computing ndcg score of nmf-dea50...\n",
      "Downloading eval data version 2...\n",
      "--> tic: 32.51s | message: Eval data loaded\n",
      "--> toc total duration: 35.48s | message: Got Twinews evaluation data\n",
      "Downloading rankings of nmf-dea50...\n",
      "Done.\n",
      "ndcg score of nmf-dea50: 0.4\n",
      "Computing ndcg@10 score of nmf-dea50...\n",
      "ndcg@10 score of nmf-dea50: 0.17\n",
      "Computing ndcg@100 score of nmf-dea50...\n",
      "ndcg@100 score of nmf-dea50: 0.31\n",
      "Computing mrr score of nmf-dea50...\n",
      "mrr score of nmf-dea50: 0.3\n",
      "Computing p@10 score of nmf-dea50...\n",
      "p@10 score of nmf-dea50: 0.11\n",
      "Computing p@100 score of nmf-dea50...\n",
      "p@100 score of nmf-dea50: 0.04\n",
      "Computing map score of nmf-dea50...\n",
      "map score of nmf-dea50: 0.14\n",
      "Computing ndcg score of lda-51ce2...\n",
      "Downloading eval data version 2...\n",
      "--> tic: 33.62s | message: Eval data loaded\n",
      "--> toc total duration: 36.23s | message: Got Twinews evaluation data\n",
      "Downloading rankings of lda-51ce2...\n",
      "Done.\n",
      "ndcg score of lda-51ce2: 0.28\n",
      "Computing ndcg@10 score of lda-51ce2...\n",
      "ndcg@10 score of lda-51ce2: 0.04\n",
      "Computing ndcg@100 score of lda-51ce2...\n",
      "ndcg@100 score of lda-51ce2: 0.12\n",
      "Computing mrr score of lda-51ce2...\n",
      "mrr score of lda-51ce2: 0.1\n",
      "Computing p@10 score of lda-51ce2...\n",
      "p@10 score of lda-51ce2: 0.03\n",
      "Computing p@100 score of lda-51ce2...\n",
      "p@100 score of lda-51ce2: 0.02\n",
      "Computing map score of lda-51ce2...\n",
      "map score of lda-51ce2: 0.04\n",
      "Computing ndcg score of lda-2fa8e...\n",
      "Downloading eval data version 2...\n",
      "--> tic: 32.56s | message: Eval data loaded\n",
      "--> toc total duration: 35.45s | message: Got Twinews evaluation data\n",
      "Downloading rankings of lda-2fa8e...\n",
      "Done.\n",
      "ndcg score of lda-2fa8e: 0.36\n",
      "Computing ndcg@10 score of lda-2fa8e...\n",
      "ndcg@10 score of lda-2fa8e: 0.13\n",
      "Computing ndcg@100 score of lda-2fa8e...\n",
      "ndcg@100 score of lda-2fa8e: 0.24\n",
      "Computing mrr score of lda-2fa8e...\n",
      "mrr score of lda-2fa8e: 0.25\n",
      "Computing p@10 score of lda-2fa8e...\n",
      "p@10 score of lda-2fa8e: 0.09\n",
      "Computing p@100 score of lda-2fa8e...\n",
      "p@100 score of lda-2fa8e: 0.03\n",
      "Computing map score of lda-2fa8e...\n",
      "map score of lda-2fa8e: 0.1\n",
      "Computing ndcg score of nmf-09f9c...\n",
      "Downloading eval data version 2...\n",
      "--> tic: 32.81s | message: Eval data loaded\n",
      "--> toc total duration: 35.94s | message: Got Twinews evaluation data\n",
      "Downloading rankings of nmf-09f9c...\n",
      "Done.\n",
      "ndcg score of nmf-09f9c: 0.4\n",
      "Computing ndcg@10 score of nmf-09f9c...\n",
      "ndcg@10 score of nmf-09f9c: 0.18\n",
      "Computing ndcg@100 score of nmf-09f9c...\n",
      "ndcg@100 score of nmf-09f9c: 0.31\n",
      "Computing mrr score of nmf-09f9c...\n",
      "mrr score of nmf-09f9c: 0.31\n",
      "Computing p@10 score of nmf-09f9c...\n",
      "p@10 score of nmf-09f9c: 0.12\n",
      "Computing p@100 score of nmf-09f9c...\n",
      "p@100 score of nmf-09f9c: 0.04\n",
      "Computing map score of nmf-09f9c...\n",
      "map score of nmf-09f9c: 0.14\n",
      "Computing ndcg score of lda-72dfd...\n",
      "Downloading eval data version 2...\n",
      "--> tic: 33.45s | message: Eval data loaded\n",
      "--> toc total duration: 36.44s | message: Got Twinews evaluation data\n",
      "Downloading rankings of lda-72dfd...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-182c4d8af3c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misNotebook\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                         \u001b[0mlogException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-182c4d8af3c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                         \u001b[0mrankingsKeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrankings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0mcandidatesKeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrankingsKeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidatesKeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrankingsKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidatesKeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidatesKeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0muserId\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrankings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We get scores collection et the rankings GridFS:\n",
    "twinewsScores = getTwinewsScores(logger=logger)\n",
    "twinewsRankings = getTwinewsRankings(logger=logger)\n",
    "# For a certain amount of iterations:\n",
    "for i in range(iterations):\n",
    "    # We get all\n",
    "    modelsKeys = twinewsRankings.keys()\n",
    "    # For all model instances:\n",
    "    for modelKey in modelsKeys:\n",
    "        # We init the eval data to None:\n",
    "        evalData = None\n",
    "        rankings = None\n",
    "        # For all metrics:\n",
    "        for metricKey, metricFunct in metricFuncts.items():\n",
    "            # If we didn't added the score previously:\n",
    "            if not twinewsScores.has({'id': modelKey, 'metric': metricKey}):\n",
    "                try:\n",
    "                    # We print infos:\n",
    "                    log(\"Computing \" + metricKey + \" score of \" + modelKey + \"...\", logger)\n",
    "                    # We get all data:\n",
    "                    meta = twinewsRankings.getMeta(modelKey)\n",
    "                    splitVersion = meta['splitVersion']\n",
    "                    maxUsers = meta['maxUsers']\n",
    "                    modelName = meta['model']\n",
    "                    # We get eval data:\n",
    "                    if evalData is None:\n",
    "                        log(\"Downloading eval data version \" + str(splitVersion) + \"...\", logger)\n",
    "                        evalData = getEvalData(splitVersion, logger=logger, maxExtraNews=0)\n",
    "                    candidates = evalData['candidates']\n",
    "                    # We get rankings:\n",
    "                    if rankings is None:\n",
    "                        log(\"Downloading rankings of \" + modelKey + \"...\", logger)\n",
    "                        rankings = twinewsRankings[modelKey]\n",
    "                        # We check if rankings are coherent with candidates (for the right split version):\n",
    "                        gotACheck = False\n",
    "                        rankingsKeys = set(rankings.keys())\n",
    "                        candidatesKeys = set(candidates.keys())\n",
    "                        if maxUsers is None:\n",
    "                        assert len(rankingsKeys) == len(candidatesKeys)\n",
    "                        assert len(rankingsKeys.union(candidatesKeys)) == len(candidatesKeys)\n",
    "                        for userId in rankings:\n",
    "                            assert len(rankings[userId]) == len(candidates[userId])\n",
    "                            for i, ranking in enumerate(rankings[userId]):\n",
    "                                assert isinstance(ranking, list)\n",
    "                                rankingSet = set(ranking)\n",
    "                                currentCandidates = candidates[userId][i]\n",
    "                                assert len(rankingSet) == len(currentCandidates)\n",
    "                                assert isinstance(currentCandidates, set)\n",
    "                                assert len(rankingSet.union(currentCandidates)) == len(rankingSet)\n",
    "                                gotACheck = True\n",
    "                        assert gotACheck\n",
    "                        log(\"Done.\", logger)\n",
    "                    # We convert all in a list of rel vectors:\n",
    "                    rels = []\n",
    "                    for userId in rankings:\n",
    "                        for ranking in rankings[userId]:\n",
    "                            rel = rankingToRelevanceVector(ranking, set(evalData['testUsers'][userId].keys()))\n",
    "                            rels.append(rel)\n",
    "                    # We compute all scores:\n",
    "                    scores = []\n",
    "                    for rel in rels:\n",
    "                        scores.append(metricFunct(rel))\n",
    "                    # We mean all scrores:\n",
    "                    score = np.mean(scores)\n",
    "                    # And finally we add the score in the db:\n",
    "                    addTwinewsScore(modelKey, metricKey, score, verbose=False)\n",
    "                    # We print result:\n",
    "                    log(metricKey + \" score of \" + modelKey + \": \" + str(truncateFloat(score, 2)), logger)\n",
    "                except Exception as e:\n",
    "                    if isNotebook:\n",
    "                        raise e\n",
    "                    else:\n",
    "                        logException(e, logger)\n",
    "                        time.sleep(exceptionSleep)\n",
    "    time.sleep(sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
