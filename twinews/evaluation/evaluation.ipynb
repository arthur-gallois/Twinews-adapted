{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script loop infinitely to evaluate new rankings added in the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tipi 86\n",
    "# killbill evaluation ; cd ~/twinews-logs ; jupython -o nohup-evaluation.out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/evaluation/evaluation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNotebook = '__file__' not in locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = isNotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.location import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.printer import *\n",
    "from databasetools.mongo import *\n",
    "from newstools.goodarticle.utils import *\n",
    "from nlptools.preprocessing import *\n",
    "from nlptools.news import parser as newsParser\n",
    "from machinelearning.iterator import *\n",
    "from twinews.utils import *\n",
    "from twinews.evaluation import metrics\n",
    "from twinews.evaluation.utils import *\n",
    "import time\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(tmpDir('logs') + \"/evaluation.log\") if isNotebook else Logger(\"evaluation.log\")\n",
    "tt = TicToc(logger=logger)\n",
    "tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1 if isNotebook else 10000000\n",
    "sleep = 0 if isNotebook else 30\n",
    "exceptionSleep = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricFuncts = \\\n",
    "{\n",
    "    'ndcg': metrics.ndcg,\n",
    "    'ndcg@10': metrics.ndcgAt10,\n",
    "    'ndcg@100': metrics.ndcgAt100,\n",
    "    'mrr': metrics.mrr,\n",
    "    'p@10': metrics.pAt10,\n",
    "    'p@100': metrics.pAt100,\n",
    "    'map': metrics.map,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    metricFuncts = \\\n",
    "    {\n",
    "        'ndcg': metrics.ndcg,\n",
    "        # 'ndcg@10': metrics.ndcgAt10,\n",
    "        # 'ndcg@100': metrics.ndcgAt100,\n",
    "        # 'mrr': metrics.mrr,\n",
    "        # 'p@10': metrics.pAt10,\n",
    "        # 'p@100': metrics.pAt100,\n",
    "        # 'map': metrics.map,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We get scores collection et the rankings GridFS:\n",
    "twinewsScores = getTwinewsScores(logger=logger)\n",
    "twinewsRankings = getTwinewsRankings(logger=logger)\n",
    "# For a certain amount of iterations:\n",
    "for i in range(iterations):\n",
    "    # We get all\n",
    "    modelsKeys = twinewsRankings.keys()\n",
    "    # For all model instances:\n",
    "    for modelKey in modelsKeys:\n",
    "        # We init the eval data to None:\n",
    "        evalData = None\n",
    "        rankings = None\n",
    "        # For all metrics:\n",
    "        for metricKey, metricFunct in metricFuncts.items():\n",
    "            # If we didn't added the score previously:\n",
    "            if not twinewsScores.has({'id': modelKey, 'metric': metricKey}):\n",
    "                try:\n",
    "                    # We print infos:\n",
    "                    log(\"Computing \" + metricKey + \" score of \" + modelKey + \"...\", logger)\n",
    "                    # We get all data:\n",
    "                    meta = twinewsRankings.getMeta(modelKey)\n",
    "                    splitVersion = meta['splitVersion']\n",
    "                    maxUsers = meta['maxUsers']\n",
    "                    modelName = meta['model']\n",
    "                    # We get eval data:\n",
    "                    if evalData is None:\n",
    "                        log(\"Downloading eval data version \" + str(splitVersion) + \"...\", logger)\n",
    "                        evalData = getEvalData(splitVersion, logger=logger, maxExtraNews=0)\n",
    "                    candidates = evalData['candidates']\n",
    "                    # We get rankings:\n",
    "                    if rankings is None:\n",
    "                        log(\"Downloading rankings of \" + modelKey + \"...\", logger)\n",
    "                        rankings = twinewsRankings[modelKey]\n",
    "                        checkRankings(rankings, candidates, maxUsers=maxUsers)\n",
    "                        log(\"Done.\", logger)\n",
    "                    # We convert all in a list of rel vectors:\n",
    "                    rels = []\n",
    "                    for userId in rankings:\n",
    "                        for ranking in rankings[userId]:\n",
    "                            if isinstance(ranking[0], tuple):\n",
    "                                ranking = [e[0] for e in ranking]\n",
    "                            rel = rankingToRelevanceVector(ranking, set(evalData['testUsers'][userId].keys()))\n",
    "                            rels.append(rel)\n",
    "                    # We compute all scores:\n",
    "                    scores = []\n",
    "                    for rel in rels:\n",
    "                        scores.append(metricFunct(rel))\n",
    "                    # We mean all scrores:\n",
    "                    score = np.mean(scores)\n",
    "                    # And finally we add the score in the db:\n",
    "                    if not TEST:\n",
    "                        addTwinewsScore(modelKey, metricKey, score, verbose=False)\n",
    "                    # We print result:\n",
    "                    log(metricKey + \" score of \" + modelKey + \": \" + str(truncateFloat(score, 2)), logger)\n",
    "                except Exception as e:\n",
    "                    if isNotebook:\n",
    "                        raise e\n",
    "                    else:\n",
    "                        logException(e, logger)\n",
    "                        time.sleep(exceptionSleep)\n",
    "    if sleep > 0:\n",
    "        log(\"Sleeping \" + str(sleep) + \" seconds for the iteration \" + str(i) + \" on \" + str(iterations) + \"...\", logger)\n",
    "    time.sleep(sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
