{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd ~/twinews-logs ; jupython -o nohup-bm25-$HOSTNAME.out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/models/bm25.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNotebook = '__file__' not in locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = isNotebook #Â isNotebook, True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.location import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.printer import *\n",
    "from nlptools.preprocessing import *\n",
    "from twinews.utils import *\n",
    "from twinews.models.ranking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tictoc starts...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = Logger(tmpDir('logs') + \"/bm25.log\") if isNotebook else Logger(\"bm25-\" + getHostname() + \".log\")\n",
    "tt = TicToc(logger=logger)\n",
    "tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \\\n",
    "{\n",
    "    'splitVersion': 2,\n",
    "    \n",
    "    'maxUsers': 2 if TEST else None, # Sub-sampling\n",
    "    'minDF': None if TEST else None, # Remove words that have a document frequency ratio lower than 1 / 500\n",
    "    'maxDF': None if TEST else None, # Remove top 300 voc elements\n",
    "    \n",
    "    'lowercase': False if TEST else False,\n",
    "    'doLemmatization': False if TEST else False,\n",
    "    \n",
    "    'k1': 1.5,\n",
    "    'b': 0.75,\n",
    "    'epsilon': 0.25,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'bm25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we check if we already generated ranking for this model with this specific config:\n",
    "if not isNotebook:\n",
    "    if rankingExists(modelName, config, logger=logger):\n",
    "        raise Exception(modelName + \" with this config already exist:\\n\" + b(config, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tic: 32.19s | message: Eval data loaded\n",
      "--> toc total duration: 32.47s | message: Got Twinews evaluation data\n",
      "{ candidates, extraNews, meta, testNews, testUsers, trainNews, trainUsers }\n",
      "{ 'created': 2020.03.24-14.28.06, 'endDate': 2018-01-15, 'id': 2, 'ranksLength': 1000, 'splitDate': 2017-12-25, 'startDate': 2017-10-01, 'testMaxNewsPerUser': 97, 'testMeanNewsPerUser': 7.22, 'testMinNewsPerUser': 2, 'testNewsCount': 71781, 'totalNewsAvailable': 570210, 'trainMaxNewsPerUser': 379, 'trainMeanNewsPerUser': 26.48, 'trainMinNewsPerUser': 8, 'trainNewsCount': 237150, 'usersCount': 15905 }\n"
     ]
    }
   ],
   "source": [
    "# Getting users and news\n",
    "evalData = getEvalData(config['splitVersion'], maxExtraNews=0, maxUsers=config['maxUsers'], logger=logger)\n",
    "(trainUsers, testUsers, trainNews, testNews, candidates, extraNews) = \\\n",
    "(evalData['trainUsers'], evalData['testUsers'], evalData['trainNews'],\n",
    " evalData['testNews'], evalData['candidates'], evalData['extraNews'])\n",
    "bp(evalData.keys(), 5, logger)\n",
    "log(b(evalData['meta'], 5), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here it is important to convert urls to lists because we want the same order to retrieve vectors by index...\n",
    "# And we shuffle it so we do not stick urls a a user at the begin...\n",
    "# But we seed the random to always have same order...\n",
    "trainNewsList = shuffle(list(trainNews), seed=0)\n",
    "testNewsList = shuffle(list(testNews), seed=0)\n",
    "newsList = trainNewsList + testNewsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28 urls for trainNewsList\n",
      "1989 urls for testNewsList\n",
      "2017 urls for newsList\n"
     ]
    }
   ],
   "source": [
    "# Print all:\n",
    "log(str(len(trainNewsList)) + \" urls for trainNewsList\", logger=logger)\n",
    "log(str(len(testNewsList)) + \" urls for testNewsList\", logger=logger)\n",
    "log(str(len(newsList)) + \" urls for newsList\", logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twinews news (version 1.0) initialised.\n",
      "  0% [                    ]\n",
      "  9% [=                   ] (42.734s left)\n",
      " 19% [===                 ] (36.558s left)\n",
      " 29% [=====               ] (31.914s left)\n",
      " 39% [=======             ] (27.594s left)\n",
      " 49% [=========           ] (23.069s left)\n",
      " 59% [===========         ] (18.613s left)\n",
      " 69% [=============       ] (13.882s left)\n",
      " 79% [===============     ] (9.296s left)\n",
      " 89% [=================   ] (4.73s left)\n",
      " 99% [=================== ] (0.158s left)\n",
      "100% [====================] (total duration: 45.65s, mean duration: 0.022s)\n",
      "[\n",
      "  [ [ The, Brazil, ..., more, . ], [ He, was, ..., play, . ], ..., [ That, football, . ], [ It, was, ..., am, . ] ],\n",
      "  [ [ Proponents, of, ..., north, . ], [ As, part, ..., years, . ], ..., [ The, next, ..., November, __int_4__ ], [ \", With, ..., Governments, . ] ],\n",
      "  ...,\n",
      "  [ [ The, Mission, ..., community, . ], [ According, to, ..., to, . ], ..., [ \", A, ..., said, . ], [ Mission, :, ..., Mission, St. ] ],\n",
      "  [ [ When, Lexington, ..., stomach, . ], [ \", It, ..., Richmond, . ], ..., [ \", Lexington, ..., said, . ], [ \", Lexington, ..., Cemetery, . ] ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# We get sentences:\n",
    "sentences = getNewsSentences(newsList, logger=logger)\n",
    "bp(sentences, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ [ The, Brazil, ..., am, . ], [ Proponents, of, ..., Governments, . ], ..., [ The, Mission, ..., Mission, St. ], [ When, Lexington, ..., Cemetery, . ] ]\n"
     ]
    }
   ],
   "source": [
    "# We flatten sentences:\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = flattenLists(sentences[i])\n",
    "docs = sentences\n",
    "bp(docs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ [ The, Brazil, ..., am, . ], [ Proponents, of, ..., Governments, . ], ..., [ The, Mission, ..., Mission, St. ], [ When, Lexington, ..., Cemetery, . ] ]\n"
     ]
    }
   ],
   "source": [
    "# Lower case:\n",
    "if config['lowercase']:\n",
    "    for i in pb(list(range(len(docs))), logger=logger, message=\"Lower casing\"):\n",
    "        for u in range(len(docs[i])):\n",
    "            docs[i][u] = docs[i][u].lower()\n",
    "bp(docs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ [ The, Brazil, ..., am, . ], [ Proponents, of, ..., Governments, . ], ..., [ The, Mission, ..., Mission, St. ], [ When, Lexington, ..., Cemetery, . ] ]\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization:\n",
    "if config['doLemmatization']:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    pbar = ProgressBar(len(docs), logger=logger, message=\"Lemmatization\")\n",
    "    for i in range(len(docs)):\n",
    "        for u in range(len(docs[i])):\n",
    "            docs[i][u] = lemmatizer.lemmatize(docs[i][u])\n",
    "        pbar.tic()\n",
    "bp(docs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the corpus:\n",
    "if config['minDF'] is not None or config['maxDF'] is not None:\n",
    "    docs = filterCorpus(docs, minDF=config['minDF'], maxDF=config['maxDF'],\n",
    "                        removeEmptyDocs=False, allowEmptyDocs=False, logger=logger)\n",
    "    for doc in docs: assert len(doc) > 0\n",
    "    bp(docs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tic: 1m 18.45s | message: Data preprocessed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.45"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.tic(\"Data preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlDocs = dict()\n",
    "for i in range(len(newsList)):\n",
    "    urlDocs[newsList[i]] = docs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating rankings  50% [==========          ] 790664132 (7.55s left)\n",
      "Generating rankings 100% [====================] 2617447752 (total duration: 15.19s, mean duration: 7.595s)\n"
     ]
    }
   ],
   "source": [
    "rankings = dict()\n",
    "pbar = ProgressBar(len(evalData['candidates']), logger=logger, message=\"Generating rankings\", printRatio=0.01)\n",
    "for userId in evalData['candidates']:\n",
    "    request = []\n",
    "    for url in evalData['trainUsers'][userId]:\n",
    "        request += urlDocs[url]\n",
    "    currentRankings = []\n",
    "    for candidates in evalData['candidates'][userId]:\n",
    "        candidates = list(candidates)\n",
    "        urlCorpus = dict()\n",
    "        for i in range(len(candidates)):\n",
    "            urlCorpus[candidates[i]] = urlDocs[candidates[i]]\n",
    "        urlCorpus = list(urlCorpus.items())\n",
    "        corpus = [e[1] for e in urlCorpus]\n",
    "        try:\n",
    "            # This is the new version not yet pushed on pipy:\n",
    "            model = bm25.BM25(corpus, k1=config['k1'], b=config['b'], epsilon=config['epsilon'])\n",
    "        except:\n",
    "            # This is the actual version with parameters as global variables:\n",
    "            bm25.PARAM_K1 = config['k1']\n",
    "            bm25.PARAM_B = config['b']\n",
    "            bm25.EPSILON = config['epsilon']\n",
    "            model = bm25.BM25(corpus)\n",
    "        scores = model.get_scores(request)\n",
    "        scoresWithUrl = []\n",
    "        for i in range(len(scores)):\n",
    "            scoresWithUrl.append((urlCorpus[i][0], scores[i]))\n",
    "        ranking = sortBy(scoresWithUrl, index=1, desc=True)\n",
    "        ranking = [e[0] for e in ranking]\n",
    "        currentRankings.append(ranking)\n",
    "    rankings[userId] = currentRankings\n",
    "    pbar.tic(str(userId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '2617447752': \n",
      "  [\n",
      "    [\n",
      "      https://trib.al/PiFii15,\n",
      "      http://bit.ly/2AkNlxU,\n",
      "      http://www.stltoday.com/sports/college/mizzou/drew-lock-puts-nfl-on-hold-will-return-to-mizzou/article_cb5dd7fa-783d-5458-9bef-e22ab0743a22.html?utm_medium=social&utm_source=twitter&utm_campaign=user-share,\n",
      "      https://mobile.nytimes.com/2018/01/06/world/asia/north-korea-nuclear-missile-intelligence.html,\n",
      "      http://www.daily-chronicle.com/lists/2017/12/31/e8ec758e9f5a4d54b391fa43e2595e22/index.xml?page=1,\n",
      "      https://www.theguardian.com/football/2018/jan/07/video-assistant-referees-errors-mike-riley,\n",
      "      http://www.nzherald.co.nz/sport/news/article.cfm?c_id=4&objectid=11962735,\n",
      "      http://nymag.com/daily/intelligencer/2017/08/felix-sater-donald-trump-russia-investigation.html,\n",
      "      http://www.argusleader.com/story/sports/2018/01/12/heart-attack-referee/1027871001/,\n",
      "      http://ow.ly/34Lp30hBCDI,\n",
      "      ...,\n",
      "      http://boston.cbslocal.com/2017/12/24/patriots-clinch-first-round-bye-jimmy-garoppolo-49ers/,\n",
      "      https://buff.ly/2Few0du,\n",
      "      http://www.tbo.com/news/Today-s-WriteLane-podcast-The-House-on-the-Corner_164374738#sthash.2rZvSw0B.uxfs,\n",
      "      https://www.washingtonpost.com/news/energy-environment/wp/2018/01/08/the-nations-rivers-and-streams-are-getting-dangerously-saltier/?tid=ss_tw&utm_term=.0256b9768971,\n",
      "      http://ow.ly/tTw730hHaYI,\n",
      "      https://www.straight.com/news/1011656/free-transit-returns-metro-vancouver-new-years-eve-along-extended-skytrain-and-seabus,\n",
      "      http://bit.ly/2E8UUK7,\n",
      "      http://www.kvoa.com/story/37180975/waiter-gets-a-tip-he-can-drive-home,\n",
      "      https://www.csindy.com/SideDish/archives/2017/12/29/mccabes-to-close-become-streetcar-520,\n",
      "      https://www.businesspost.ie/opinion/government-shown-no-urgency-reform-health-service-406246?utm_source=twitter&utm_campaign=article&utm_medium=web\n",
      "    ]\n",
      "  ],\n",
      "  '790664132': \n",
      "  [\n",
      "    [\n",
      "      http://bbc.in/2DCRxw6,\n",
      "      https://buff.ly/2Dpi9Ra,\n",
      "      https://www.theatlantic.com/business/archive/2017/12/suburban-poverty-and-recession/549350/?utm_source=Sightline%20Institute&utm_medium=web-email&utm_campaign=Sightline%20News%20Selections,\n",
      "      https://buff.ly/2lPiiF7,\n",
      "      http://ow.ly/1tti30hKdYn,\n",
      "      https://www.seattletimes.com/seattle-news/politics/how-the-sausage-is-made-legal-pressure-helped-airbnb-host-in-seattle-win-special-deal/?utm_source=twitter&utm_medium=social&utm_campaign=article_left_1.1,\n",
      "      http://www.phoenixnewtimes.com/news/hot-nights-cold-cases-will-they-ever-find-the-killers-9538347,\n",
      "      https://www.vox.com/policy-and-politics/2018/1/2/16181734/12-steps-aa-na-studies,\n",
      "      http://www.wbur.org/npr/570224090/the-sexual-assault-epidemic-no-one-talks-about,\n",
      "      http://bit.ly/2qoqFvg,\n",
      "      ...,\n",
      "      http://www.kusi.com/shallotte-river-swamp-park-alligators-survive-iced-lake/,\n",
      "      https://lnkd.in/eeSr8zE,\n",
      "      https://academic.oup.com/jleo/article/29/2/355/914869,\n",
      "      https://www.wsj.com/articles/making-a-connection-bridges-from-around-the-world-1514561467,\n",
      "      http://m.arkansasonline.com/news/2018/jan/10/sweet-second-helpings-20180110/,\n",
      "      http://bit.ly/2lQR2pJ,\n",
      "      http://walkacrosstexas.tamu.edu/developing-good-balance-core-successful-exercise/,\n",
      "      https://eighthjdcourt.wordpress.com/2018/01/02/january-6-job-fair-great-place-to-get-in-on-opportunities-for-jobs-to-protect-courts/,\n",
      "      http://flatheadbeacon.com/2018/01/10/death-trap-technologies/,\n",
      "      http://ow.ly/ioBD30hrTP6\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "bp(rankings, logger, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tic: 24m 56.019s | message: Rankings done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1496.02"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.tic(\"Rankings done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding rankings to the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the doc!\n",
    "addRanking(modelName, rankings, config, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tic: 7.91s | message: Rankings stored\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.91"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.tic(\"Rankings stored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> toc total duration: 26m 22.819s\n"
     ]
    }
   ],
   "source": [
    "totalDuration = tt.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "notif(modelName + '-' + objectToHash(config)[:5] + \" done in \" + secondsToHumanReadableDuration(totalDuration) + \" on \" + getHostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
