{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oomstopper --no-tail genericmodels ; killbill genericmodels ; cd ~/twinews-logs ; jupython -o nohup-genericmodels-$HOSTNAME.out --venv st-venv ~/Workspace/Python/Datasets/Twinews/twinews/models/genericmodels.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNotebook = '__file__' not in locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = isNotebook # isNotebook, True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemtools.hayj import *\n",
    "from systemtools.location import *\n",
    "from systemtools.basics import *\n",
    "from systemtools.file import *\n",
    "from systemtools.printer import *\n",
    "from nlptools.preprocessing import *\n",
    "from nlptools.basics import *\n",
    "from twinews.utils import *\n",
    "from twinews.models.ranking import *\n",
    "from machinelearning.iterator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twinews.models.genericutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tictoc starts...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = Logger(tmpDir('logs') + \"/generic.log\") if isNotebook else Logger(\"generic-\" + getHostname() + \".log\")\n",
    "tt = TicToc(logger=logger)\n",
    "tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacheKey = \\\n",
    "(\n",
    "    # 'dbert-ft'\n",
    "    # 'dbert-base'\n",
    "    # 'infersent'\n",
    "    # 'usent'\n",
    "    # 'sent2vec'\n",
    "    'doc2vec'\n",
    "    # 'bert'\n",
    "    # 'stylo'\n",
    "    # 'nmf'\n",
    "    # 'tfidf'\n",
    "    # 'word2vec'\n",
    ")\n",
    "cacheField = genericFields[cacheKey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \\\n",
    "{\n",
    "    'splitVersion': 2,\n",
    "    'maxUsers': 2 if TEST else None, # Sub-sampling\n",
    "    \n",
    "    'distance': 'cosine', # 'cosine', 'euclidean', 'kl', 'js' (ValueError math domain error pour kl et js)\n",
    "    'historyRef': 0.35, # 0.1, 0.3, 0.4, 0.6, 1.0, 1, 3, 10, 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = mergeDicts(config, {})\n",
    "modelName = cacheKey\n",
    "getCache = lambda: getGenericCache(cacheKey, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we check if we already generated ranking for this model with this specific config:\n",
    "if not isNotebook:\n",
    "    if rankingExists(modelName, config, logger=logger):\n",
    "        raise Exception(modelName + \" with this config already exist:\\n\" + b(config, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating rankings for infersent (`detokSentences` field) with the config:\n",
      "{ 'distance': cosine, 'historyRef': 0.4, 'maxUsers': 2, 'splitVersion': 2 }\n"
     ]
    }
   ],
   "source": [
    "log(\"Generating rankings for \" + modelName + ' (`' + cacheField + '` field) with the config:\\n' + b(config, 5), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> tic: 32.66s | message: Eval data loaded\n",
      "--> toc total duration: 32.97s | message: Got Twinews evaluation data\n",
      "{ candidates, extraNews, meta, testNews, testUsers, trainNews, trainUsers }\n",
      "{ 'created': 2020.03.24-14.28.06, 'endDate': 2018-01-15, 'id': 2, 'ranksLength': 1000, 'splitDate': 2017-12-25, 'startDate': 2017-10-01, 'testMaxNewsPerUser': 97, 'testMeanNewsPerUser': 7.22, 'testMinNewsPerUser': 2, 'testNewsCount': 71781, 'totalNewsAvailable': 570210, 'trainMaxNewsPerUser': 379, 'trainMeanNewsPerUser': 26.48, 'trainMinNewsPerUser': 8, 'trainNewsCount': 237150, 'usersCount': 15905 }\n"
     ]
    }
   ],
   "source": [
    "# Getting users and news\n",
    "evalData = getEvalData(config['splitVersion'], maxExtraNews=0, maxUsers=config['maxUsers'], logger=logger)\n",
    "(trainUsers, testUsers, trainNews, testNews, candidates, extraNews) = \\\n",
    "(evalData['trainUsers'], evalData['testUsers'], evalData['trainNews'],\n",
    " evalData['testNews'], evalData['candidates'], evalData['extraNews'])\n",
    "bp(evalData.keys(), 5, logger)\n",
    "log(b(evalData['meta'], 5), logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here it is important to convert urls to lists because we want the same order to retrieve vectors by index...\n",
    "# And we shuffle it so we do not stick urls a a user at the begin...\n",
    "# But we seed the random to always have same order...\n",
    "trainNewsList = shuffle(list(trainNews), seed=0)\n",
    "testNewsList = shuffle(list(testNews), seed=0)\n",
    "newsList = trainNewsList + testNewsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28 urls for trainNewsList\n",
      "1989 urls for testNewsList\n",
      "2017 urls for newsList\n"
     ]
    }
   ],
   "source": [
    "# Print all:\n",
    "log(str(len(trainNewsList)) + \" urls for trainNewsList\", logger=logger)\n",
    "log(str(len(testNewsList)) + \" urls for testNewsList\", logger=logger)\n",
    "log(str(len(newsList)) + \" urls for newsList\", logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genFunct(containers, field, getCache, *args, **kwargs):\n",
    "    if not isinstance(containers[0], list):\n",
    "        containers = [containers]\n",
    "    cache = getCache()\n",
    "    newsCollection = getNewsCollection(verbose=False)\n",
    "    for container in containers:\n",
    "        for url in container:\n",
    "            vector = getVector(url, field, cache, newsCollection)\n",
    "            assert vector is not None\n",
    "            yield (url, vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "With parallelProcesses > 1, this iterator is not consistent, meaning 2 iterations over same containers will not give items in the same order\n",
      "21 containers to process.\n"
     ]
    }
   ],
   "source": [
    "mli = MLIterator\\\n",
    "(\n",
    "    chunks(newsList, 100 if TEST else 5000),\n",
    "    # chunks(newsList, int(len(newsList) / 100)),\n",
    "    genFunct, genArgs=(cacheField, getCache,),\n",
    "    logger=logger,\n",
    "    printRatio=0.03, queuesMaxSize=1000,\n",
    "    parallelProcesses=cpuCount(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception type: <class 'AssertionError'>\n",
      "Exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hayj/Workspace/Python/Utils/MachineLearning/machinelearning/iterator.py\", line 90, in genFunctWrapper\n",
      "    for current in genFunct(container, *genArgs, **genKwargs, logger=logger, verbose=verbose):\n",
      "  File \"<ipython-input-16-2fbc26184d0b>\", line 9, in genFunct\n",
      "    assert vector is not None\n",
      "AssertionError\n",
      "\n",
      "Exception type: <class 'AssertionError'>\n",
      "Exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hayj/Workspace/Python/Utils/MachineLearning/machinelearning/iterator.py\", line 90, in genFunctWrapper\n",
      "    for current in genFunct(container, *genArgs, **genKwargs, logger=logger, verbose=verbose):\n",
      "  File \"<ipython-input-16-2fbc26184d0b>\", line 9, in genFunct\n",
      "    assert vector is not None\n",
      "AssertionError\n",
      "\n",
      "Exception type: <class 'AssertionError'>\n",
      "Exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hayj/Workspace/Python/Utils/MachineLearning/machinelearning/iterator.py\", line 90, in genFunctWrapper\n",
      "    for current in genFunct(container, *genArgs, **genKwargs, logger=logger, verbose=verbose):\n",
      "  File \"<ipython-input-16-2fbc26184d0b>\", line 9, in genFunct\n",
      "    assert vector is not None\n",
      "AssertionError\n",
      "\n",
      "Exception type: <class 'AssertionError'>\n",
      "Exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hayj/Workspace/Python/Utils/MachineLearning/machinelearning/iterator.py\", line 90, in genFunctWrapper\n",
      "    for current in genFunct(container, *genArgs, **genKwargs, logger=logger, verbose=verbose):\n",
      "  File \"<ipython-input-16-2fbc26184d0b>\", line 9, in genFunct\n",
      "    assert vector is not None\n",
      "AssertionError\n",
      "Exception type: <class 'AssertionError'>\n",
      "Exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hayj/Workspace/Python/Utils/MachineLearning/machinelearning/iterator.py\", line 90, in genFunctWrapper\n",
      "    for current in genFunct(container, *genArgs, **genKwargs, logger=logger, verbose=verbose):\n",
      "  File \"<ipython-input-16-2fbc26184d0b>\", line 9, in genFunct\n",
      "    assert vector is not None\n",
      "AssertionError\n",
      "\n",
      "\n",
      "Exception type: <class 'AssertionError'>\n",
      "Exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hayj/Workspace/Python/Utils/MachineLearning/machinelearning/iterator.py\", line 90, in genFunctWrapper\n",
      "    for current in genFunct(container, *genArgs, **genKwargs, logger=logger, verbose=verbose):\n",
      "  File \"<ipython-input-16-2fbc26184d0b>\", line 9, in genFunct\n",
      "    assert vector is not None\n",
      "AssertionError\n",
      "\n",
      "Exception type: <class 'AssertionError'>\n",
      "Exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hayj/Workspace/Python/Utils/MachineLearning/machinelearning/iterator.py\", line 90, in genFunctWrapper\n",
      "    for current in genFunct(container, *genArgs, **genKwargs, logger=logger, verbose=verbose):\n",
      "  File \"<ipython-input-16-2fbc26184d0b>\", line 9, in genFunct\n",
      "    assert vector is not None\n",
      "AssertionError\n",
      "\n",
      "Exception type: <class 'AssertionError'>\n",
      "Exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hayj/Workspace/Python/Utils/MachineLearning/machinelearning/iterator.py\", line 90, in genFunctWrapper\n",
      "    for current in genFunct(container, *genArgs, **genKwargs, logger=logger, verbose=verbose):\n",
      "  File \"<ipython-input-16-2fbc26184d0b>\", line 9, in genFunct\n",
      "    assert vector is not None\n",
      "AssertionError\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ab8d86044de3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murlsVectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmli\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0murlsVectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Python/Utils/MachineLearning/machinelearning/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmainLoopCount\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxMainLoopCount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                     \u001b[0;31m# logError(\"The main loop of \" + str(self.__class__.__name__) + \" had no result more than \" + str(self.maxMainLoopCount) + \" times. Maybe du to a large skip in subprocesses. We will wait \" + str(self.mainLoopWait) + \" second(s).\", self)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainLoopWait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m                 \u001b[0;31m# We inc the index:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "urlsVectors = dict()\n",
    "for url, vector in mli:\n",
    "    urlsVectors[url] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bp(urlsVectors, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.tic(\"Data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the doc!\n",
    "rankings = usersRankingsByHistoryDistance\\\n",
    "(\n",
    "    trainUsers,\n",
    "    candidates,\n",
    "    config['historyRef'],\n",
    "    urlsVectors,\n",
    "    distanceMetric=config['distance'],\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bp(rankings, logger, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.tic(\"Rankings done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding rankings to the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the doc!\n",
    "addRanking(modelName, rankings, config, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.tic(\"Rankings stored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDuration = tt.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TEST:\n",
    "    notif(modelName + '-' + objectToHash(config)[:5] + \" done in \" + secondsToHumanReadableDuration(totalDuration) + \" on \" + getHostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    (user, password, host) = getMongoAuth(user='hayj')\n",
    "    cache = SerializableDict\\\n",
    "    (\n",
    "        \"twinews-dbert-94bef_ep32\",\n",
    "        user=user, host=host, password=password,\n",
    "        useMongodb=True, logger=logger,\n",
    "    )\n",
    "    urlCache = SerializableDict\\\n",
    "    (\n",
    "        \"twinews-dbert-94bef_ep32-url\",\n",
    "        user=user, host=host, password=password,\n",
    "        useMongodb=True, logger=logger,\n",
    "    )\n",
    "    pbar = ProgressBar(len(newsCollection), logger=logger, printRatio=0.01)\n",
    "    for row in newsCollection.find({}, projection={'detokText': True, 'url': True}):\n",
    "        url = row['url']\n",
    "        text = row['detokText']\n",
    "        theHash = objectToHash(text)\n",
    "        vector = cache[theHash]\n",
    "        urlCache[url] = vector\n",
    "        pbar.tic()\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
